{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuueS/bpBKvgxI5u/jSXXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7ece8f65cdb46dd8d87ee3634031862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08e0134927014dc29e1afea7ebd83993",
              "IPY_MODEL_7fac169a93dc4363a0be906a380ba489",
              "IPY_MODEL_ee281f989eaa49bea6eeaa8061301621"
            ],
            "layout": "IPY_MODEL_f071d724afd540ccb0178a451387b75b"
          }
        },
        "08e0134927014dc29e1afea7ebd83993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68eceea098ee45ae8f5f0082eb619d1b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6e326fe27d4bf7b5f55dae6a6cbe67",
            "value": "100%"
          }
        },
        "7fac169a93dc4363a0be906a380ba489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b743878dafe24989a539fb355dcb8086",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82ffab5931a6487d9f031643422360a9",
            "value": 9912422
          }
        },
        "ee281f989eaa49bea6eeaa8061301621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a896da5da11744a2aabe9fe3ebdd3ac0",
            "placeholder": "​",
            "style": "IPY_MODEL_73706884454b430d93b1b177e14fe246",
            "value": " 9912422/9912422 [00:00&lt;00:00, 92636790.21it/s]"
          }
        },
        "f071d724afd540ccb0178a451387b75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68eceea098ee45ae8f5f0082eb619d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6e326fe27d4bf7b5f55dae6a6cbe67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b743878dafe24989a539fb355dcb8086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ffab5931a6487d9f031643422360a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a896da5da11744a2aabe9fe3ebdd3ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73706884454b430d93b1b177e14fe246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f056ba9d84a4a98a4379d3d0cf28915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6a90c35ad1142c4bb68d32d7aec8a33",
              "IPY_MODEL_fb658d72afb2460499f3e37f68d8f733",
              "IPY_MODEL_afb8206968894faf995ff90fcd50eff6"
            ],
            "layout": "IPY_MODEL_a333138c0d4d4dab8c22866a4f1a68ee"
          }
        },
        "a6a90c35ad1142c4bb68d32d7aec8a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df067e5e32e14031ae8638e1ccf6150f",
            "placeholder": "​",
            "style": "IPY_MODEL_58fecf3d50754d08a675d0dbc6e96489",
            "value": "100%"
          }
        },
        "fb658d72afb2460499f3e37f68d8f733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d5c293463f4cfa9b26847378d80397",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b753208681d40d1bd16304735496c82",
            "value": 28881
          }
        },
        "afb8206968894faf995ff90fcd50eff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccb1b8555954e0d86202ebcb10d8ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_2b9b032c913c4d549f69e22fdc37ad0f",
            "value": " 28881/28881 [00:00&lt;00:00, 1393661.84it/s]"
          }
        },
        "a333138c0d4d4dab8c22866a4f1a68ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df067e5e32e14031ae8638e1ccf6150f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58fecf3d50754d08a675d0dbc6e96489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d5c293463f4cfa9b26847378d80397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b753208681d40d1bd16304735496c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ccb1b8555954e0d86202ebcb10d8ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9b032c913c4d549f69e22fdc37ad0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16f9e22ba3dc407183d232497294b69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d08a7a8660b246ae855b582755bacb4f",
              "IPY_MODEL_80837ec947f743b595e2d47a72fbb7f9",
              "IPY_MODEL_5adcd84d39b24851ba0fab84febfb0fc"
            ],
            "layout": "IPY_MODEL_56f77050c09347e5a773fa4005b835fd"
          }
        },
        "d08a7a8660b246ae855b582755bacb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3b5b42eea74530ad06fb821b0a240a",
            "placeholder": "​",
            "style": "IPY_MODEL_78e236c1f39e4191aee073dec97f2d7d",
            "value": "100%"
          }
        },
        "80837ec947f743b595e2d47a72fbb7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cfcfd179da345feabe67784f604ec80",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c85e9587636b4db3967855aeeccfb3ec",
            "value": 1648877
          }
        },
        "5adcd84d39b24851ba0fab84febfb0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58fd051231c14466ab9df621e38ca3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_df55d652bd2147bb8c82e97049ac36fa",
            "value": " 1648877/1648877 [00:00&lt;00:00, 27653610.29it/s]"
          }
        },
        "56f77050c09347e5a773fa4005b835fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3b5b42eea74530ad06fb821b0a240a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e236c1f39e4191aee073dec97f2d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cfcfd179da345feabe67784f604ec80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85e9587636b4db3967855aeeccfb3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58fd051231c14466ab9df621e38ca3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df55d652bd2147bb8c82e97049ac36fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f2cba337fe488c8f98fb589e1e92b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_974d4d003ec8489fa18cab8d073028a3",
              "IPY_MODEL_8d21347b38464e3fbeb25ea9123ce502",
              "IPY_MODEL_58cbae8e454547bca6caaec74f5ff8f6"
            ],
            "layout": "IPY_MODEL_6549c36410d7461eb56a33a1f61744f5"
          }
        },
        "974d4d003ec8489fa18cab8d073028a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d63800b8784911a56cd0915e238d71",
            "placeholder": "​",
            "style": "IPY_MODEL_d0792e7117354163b0fd33d2fe7192d1",
            "value": "100%"
          }
        },
        "8d21347b38464e3fbeb25ea9123ce502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dbb70241f9e459b813a265f7c1c8dd1",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a7f6853f253433b9ae5293567bb784f",
            "value": 4542
          }
        },
        "58cbae8e454547bca6caaec74f5ff8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90057aed13c44eacaa96fa7af7304f52",
            "placeholder": "​",
            "style": "IPY_MODEL_37da338f97734fdba54fe12243a5cd64",
            "value": " 4542/4542 [00:00&lt;00:00, 229599.13it/s]"
          }
        },
        "6549c36410d7461eb56a33a1f61744f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d63800b8784911a56cd0915e238d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0792e7117354163b0fd33d2fe7192d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dbb70241f9e459b813a265f7c1c8dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7f6853f253433b9ae5293567bb784f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90057aed13c44eacaa96fa7af7304f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37da338f97734fdba54fe12243a5cd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeEunSeo/Application-of-Smart-Services/blob/main/week1/week1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uKJbyDhfnF6",
        "outputId": "bee5c2f3-6ed3-486e-eee4-4808aea660cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/My Drive/code/week1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSBBw0hsf2RU",
        "outputId": "80f2c95a-857f-4bd3-8bee-202d19f511b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/code/week1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hanyoseob/youtube-cnn-001-pytorch-mnist.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ulcS2UgLsO",
        "outputId": "ff02e452-c2e5-49ee-9ef4-1e104fb9b9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'youtube-cnn-001-pytorch-mnist'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 47 (delta 14), reused 42 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), 102.03 KiB | 182.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"youtube-cnn-001-pytorch-mnist\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lM34_HIgkxw",
        "outputId": "532ff7b2-c90a-4876-97d6-31db432f5d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/code/week1/youtube-cnn-001-pytorch-mnist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c7ece8f65cdb46dd8d87ee3634031862",
            "08e0134927014dc29e1afea7ebd83993",
            "7fac169a93dc4363a0be906a380ba489",
            "ee281f989eaa49bea6eeaa8061301621",
            "f071d724afd540ccb0178a451387b75b",
            "68eceea098ee45ae8f5f0082eb619d1b",
            "ae6e326fe27d4bf7b5f55dae6a6cbe67",
            "b743878dafe24989a539fb355dcb8086",
            "82ffab5931a6487d9f031643422360a9",
            "a896da5da11744a2aabe9fe3ebdd3ac0",
            "73706884454b430d93b1b177e14fe246",
            "5f056ba9d84a4a98a4379d3d0cf28915",
            "a6a90c35ad1142c4bb68d32d7aec8a33",
            "fb658d72afb2460499f3e37f68d8f733",
            "afb8206968894faf995ff90fcd50eff6",
            "a333138c0d4d4dab8c22866a4f1a68ee",
            "df067e5e32e14031ae8638e1ccf6150f",
            "58fecf3d50754d08a675d0dbc6e96489",
            "99d5c293463f4cfa9b26847378d80397",
            "4b753208681d40d1bd16304735496c82",
            "5ccb1b8555954e0d86202ebcb10d8ce7",
            "2b9b032c913c4d549f69e22fdc37ad0f",
            "16f9e22ba3dc407183d232497294b69c",
            "d08a7a8660b246ae855b582755bacb4f",
            "80837ec947f743b595e2d47a72fbb7f9",
            "5adcd84d39b24851ba0fab84febfb0fc",
            "56f77050c09347e5a773fa4005b835fd",
            "3d3b5b42eea74530ad06fb821b0a240a",
            "78e236c1f39e4191aee073dec97f2d7d",
            "2cfcfd179da345feabe67784f604ec80",
            "c85e9587636b4db3967855aeeccfb3ec",
            "58fd051231c14466ab9df621e38ca3b8",
            "df55d652bd2147bb8c82e97049ac36fa",
            "d5f2cba337fe488c8f98fb589e1e92b6",
            "974d4d003ec8489fa18cab8d073028a3",
            "8d21347b38464e3fbeb25ea9123ce502",
            "58cbae8e454547bca6caaec74f5ff8f6",
            "6549c36410d7461eb56a33a1f61744f5",
            "57d63800b8784911a56cd0915e238d71",
            "d0792e7117354163b0fd33d2fe7192d1",
            "5dbb70241f9e459b813a265f7c1c8dd1",
            "4a7f6853f253433b9ae5293567bb784f",
            "90057aed13c44eacaa96fa7af7304f52",
            "37da338f97734fdba54fe12243a5cd64"
          ]
        },
        "id": "luVaCgvNg0Qe",
        "outputId": "0d2b2b14-8d6b-4405-c41d-915fdde719cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7ece8f65cdb46dd8d87ee3634031862"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f056ba9d84a4a98a4379d3d0cf28915"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16f9e22ba3dc407183d232497294b69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5f2cba337fe488c8f98fb589e1e92b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0629/0938 | LOSS: 0.1726 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0630/0938 | LOSS: 0.1725 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0631/0938 | LOSS: 0.1723 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0632/0938 | LOSS: 0.1724 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0633/0938 | LOSS: 0.1724 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0634/0938 | LOSS: 0.1728 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0635/0938 | LOSS: 0.1727 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0636/0938 | LOSS: 0.1726 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0637/0938 | LOSS: 0.1729 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0638/0938 | LOSS: 0.1729 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0639/0938 | LOSS: 0.1728 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0640/0938 | LOSS: 0.1728 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0641/0938 | LOSS: 0.1727 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0642/0938 | LOSS: 0.1725 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0643/0938 | LOSS: 0.1724 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0644/0938 | LOSS: 0.1723 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0645/0938 | LOSS: 0.1723 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0646/0938 | LOSS: 0.1724 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0647/0938 | LOSS: 0.1724 | ACC 0.9496\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0648/0938 | LOSS: 0.1724 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0649/0938 | LOSS: 0.1723 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0650/0938 | LOSS: 0.1722 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0651/0938 | LOSS: 0.1722 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0652/0938 | LOSS: 0.1721 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0653/0938 | LOSS: 0.1720 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0654/0938 | LOSS: 0.1719 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0655/0938 | LOSS: 0.1719 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0656/0938 | LOSS: 0.1720 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0657/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0658/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0659/0938 | LOSS: 0.1719 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0660/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0661/0938 | LOSS: 0.1720 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0662/0938 | LOSS: 0.1720 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0663/0938 | LOSS: 0.1720 | ACC 0.9497\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0664/0938 | LOSS: 0.1719 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0665/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0666/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0667/0938 | LOSS: 0.1718 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0668/0938 | LOSS: 0.1716 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0669/0938 | LOSS: 0.1715 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0670/0938 | LOSS: 0.1714 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0671/0938 | LOSS: 0.1712 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0672/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0673/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0674/0938 | LOSS: 0.1708 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0675/0938 | LOSS: 0.1707 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0676/0938 | LOSS: 0.1707 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0677/0938 | LOSS: 0.1707 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0678/0938 | LOSS: 0.1708 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0679/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0680/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0681/0938 | LOSS: 0.1708 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0682/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0683/0938 | LOSS: 0.1708 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0684/0938 | LOSS: 0.1707 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0685/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0686/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0687/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0688/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0689/0938 | LOSS: 0.1713 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0690/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0691/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0692/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0693/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0694/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0695/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0696/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0697/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0698/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0699/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0700/0938 | LOSS: 0.1707 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0701/0938 | LOSS: 0.1707 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0702/0938 | LOSS: 0.1706 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0703/0938 | LOSS: 0.1706 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0704/0938 | LOSS: 0.1706 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0705/0938 | LOSS: 0.1706 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0706/0938 | LOSS: 0.1705 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0707/0938 | LOSS: 0.1703 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0708/0938 | LOSS: 0.1703 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0709/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0710/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0711/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0712/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0713/0938 | LOSS: 0.1701 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0714/0938 | LOSS: 0.1704 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0715/0938 | LOSS: 0.1704 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0716/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0717/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0718/0938 | LOSS: 0.1704 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0719/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0720/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0721/0938 | LOSS: 0.1702 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0722/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0723/0938 | LOSS: 0.1701 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0724/0938 | LOSS: 0.1701 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0725/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0726/0938 | LOSS: 0.1702 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0727/0938 | LOSS: 0.1702 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0728/0938 | LOSS: 0.1701 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0729/0938 | LOSS: 0.1701 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0730/0938 | LOSS: 0.1701 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0731/0938 | LOSS: 0.1701 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0732/0938 | LOSS: 0.1699 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0733/0938 | LOSS: 0.1700 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0734/0938 | LOSS: 0.1704 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0735/0938 | LOSS: 0.1705 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0736/0938 | LOSS: 0.1704 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0737/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0738/0938 | LOSS: 0.1702 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0739/0938 | LOSS: 0.1703 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0740/0938 | LOSS: 0.1703 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0741/0938 | LOSS: 0.1704 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0742/0938 | LOSS: 0.1705 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0743/0938 | LOSS: 0.1705 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0744/0938 | LOSS: 0.1708 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0745/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0746/0938 | LOSS: 0.1708 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0747/0938 | LOSS: 0.1707 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0748/0938 | LOSS: 0.1708 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0749/0938 | LOSS: 0.1708 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0750/0938 | LOSS: 0.1708 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0751/0938 | LOSS: 0.1708 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0752/0938 | LOSS: 0.1710 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0753/0938 | LOSS: 0.1709 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0754/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0755/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0756/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0757/0938 | LOSS: 0.1708 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0758/0938 | LOSS: 0.1708 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0759/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0760/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0761/0938 | LOSS: 0.1712 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0762/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0763/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0764/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0765/0938 | LOSS: 0.1710 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0766/0938 | LOSS: 0.1709 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0767/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0768/0938 | LOSS: 0.1711 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0769/0938 | LOSS: 0.1711 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0770/0938 | LOSS: 0.1711 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0771/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0772/0938 | LOSS: 0.1710 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0773/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0774/0938 | LOSS: 0.1713 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0775/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0776/0938 | LOSS: 0.1712 | ACC 0.9498\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0777/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0778/0938 | LOSS: 0.1711 | ACC 0.9499\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0779/0938 | LOSS: 0.1710 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0780/0938 | LOSS: 0.1710 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0781/0938 | LOSS: 0.1709 | ACC 0.9500\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0782/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0783/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0784/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0785/0938 | LOSS: 0.1707 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0786/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0787/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0788/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0789/0938 | LOSS: 0.1708 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0790/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0791/0938 | LOSS: 0.1705 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0792/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0793/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0794/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0795/0938 | LOSS: 0.1704 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0796/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0797/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0798/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0799/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0800/0938 | LOSS: 0.1708 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0801/0938 | LOSS: 0.1709 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0802/0938 | LOSS: 0.1708 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0803/0938 | LOSS: 0.1708 | ACC 0.9501\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0804/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0805/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0806/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0807/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0808/0938 | LOSS: 0.1705 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0809/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0810/0938 | LOSS: 0.1705 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0811/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0812/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0813/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0814/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0815/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0816/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0817/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0818/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0819/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0820/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0821/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0822/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0823/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0824/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0825/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0826/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0827/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0828/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0829/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0830/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0831/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0832/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0833/0938 | LOSS: 0.1708 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0834/0938 | LOSS: 0.1708 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0835/0938 | LOSS: 0.1708 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0836/0938 | LOSS: 0.1709 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0837/0938 | LOSS: 0.1708 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0838/0938 | LOSS: 0.1707 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0839/0938 | LOSS: 0.1707 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0840/0938 | LOSS: 0.1707 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0841/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0842/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0843/0938 | LOSS: 0.1707 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0844/0938 | LOSS: 0.1706 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0845/0938 | LOSS: 0.1705 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0846/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0847/0938 | LOSS: 0.1704 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0848/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0849/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0850/0938 | LOSS: 0.1703 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0851/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0852/0938 | LOSS: 0.1702 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0853/0938 | LOSS: 0.1703 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0854/0938 | LOSS: 0.1702 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0855/0938 | LOSS: 0.1701 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0856/0938 | LOSS: 0.1702 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0857/0938 | LOSS: 0.1702 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0858/0938 | LOSS: 0.1702 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0859/0938 | LOSS: 0.1701 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0860/0938 | LOSS: 0.1701 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0861/0938 | LOSS: 0.1700 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0862/0938 | LOSS: 0.1700 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0863/0938 | LOSS: 0.1700 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0864/0938 | LOSS: 0.1700 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0865/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0866/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0867/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0868/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0869/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0870/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0871/0938 | LOSS: 0.1697 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0872/0938 | LOSS: 0.1696 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0873/0938 | LOSS: 0.1695 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0874/0938 | LOSS: 0.1693 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0875/0938 | LOSS: 0.1693 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0876/0938 | LOSS: 0.1693 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0877/0938 | LOSS: 0.1696 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0878/0938 | LOSS: 0.1695 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0879/0938 | LOSS: 0.1695 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0880/0938 | LOSS: 0.1695 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0881/0938 | LOSS: 0.1694 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0882/0938 | LOSS: 0.1694 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0883/0938 | LOSS: 0.1694 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0884/0938 | LOSS: 0.1695 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0885/0938 | LOSS: 0.1696 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0886/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0887/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0888/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0889/0938 | LOSS: 0.1702 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0890/0938 | LOSS: 0.1702 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0891/0938 | LOSS: 0.1702 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0892/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0893/0938 | LOSS: 0.1701 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0894/0938 | LOSS: 0.1701 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0895/0938 | LOSS: 0.1700 | ACC 0.9502\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0896/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0897/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0898/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0899/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0900/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0901/0938 | LOSS: 0.1699 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0902/0938 | LOSS: 0.1698 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0903/0938 | LOSS: 0.1698 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0904/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0905/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0906/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0907/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0908/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0909/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0910/0938 | LOSS: 0.1700 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0911/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0912/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0913/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0914/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0915/0938 | LOSS: 0.1700 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0916/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0917/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0918/0938 | LOSS: 0.1701 | ACC 0.9503\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0919/0938 | LOSS: 0.1701 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0920/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0921/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0922/0938 | LOSS: 0.1697 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0923/0938 | LOSS: 0.1697 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0924/0938 | LOSS: 0.1699 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0925/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0926/0938 | LOSS: 0.1697 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0927/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0928/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0929/0938 | LOSS: 0.1697 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0930/0938 | LOSS: 0.1696 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0931/0938 | LOSS: 0.1695 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0932/0938 | LOSS: 0.1694 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0933/0938 | LOSS: 0.1695 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0934/0938 | LOSS: 0.1694 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0935/0938 | LOSS: 0.1695 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0936/0938 | LOSS: 0.1694 | ACC 0.9504\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0937/0938 | LOSS: 0.1693 | ACC 0.9505\n",
            "TRAIN: EPOCH 0005/0010 | BATCH 0938/0938 | LOSS: 0.1691 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0001/0938 | LOSS: 0.0409 | ACC 1.0000\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0002/0938 | LOSS: 0.0583 | ACC 0.9922\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0003/0938 | LOSS: 0.0896 | ACC 0.9740\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0004/0938 | LOSS: 0.1295 | ACC 0.9531\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0005/0938 | LOSS: 0.1269 | ACC 0.9531\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0006/0938 | LOSS: 0.1238 | ACC 0.9531\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0007/0938 | LOSS: 0.1316 | ACC 0.9531\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0008/0938 | LOSS: 0.1457 | ACC 0.9531\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0009/0938 | LOSS: 0.1347 | ACC 0.9566\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0010/0938 | LOSS: 0.1403 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0011/0938 | LOSS: 0.1422 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0012/0938 | LOSS: 0.1429 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0013/0938 | LOSS: 0.1660 | ACC 0.9435\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0014/0938 | LOSS: 0.1812 | ACC 0.9397\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0015/0938 | LOSS: 0.1817 | ACC 0.9406\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0016/0938 | LOSS: 0.1722 | ACC 0.9443\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0017/0938 | LOSS: 0.1734 | ACC 0.9430\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0018/0938 | LOSS: 0.1691 | ACC 0.9444\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0019/0938 | LOSS: 0.1668 | ACC 0.9441\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0020/0938 | LOSS: 0.1682 | ACC 0.9437\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0021/0938 | LOSS: 0.1722 | ACC 0.9420\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0022/0938 | LOSS: 0.1686 | ACC 0.9432\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0023/0938 | LOSS: 0.1764 | ACC 0.9423\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0024/0938 | LOSS: 0.1802 | ACC 0.9408\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0025/0938 | LOSS: 0.1789 | ACC 0.9406\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0026/0938 | LOSS: 0.1840 | ACC 0.9405\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0027/0938 | LOSS: 0.1807 | ACC 0.9416\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0028/0938 | LOSS: 0.1802 | ACC 0.9420\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0029/0938 | LOSS: 0.1781 | ACC 0.9434\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0030/0938 | LOSS: 0.1789 | ACC 0.9437\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0031/0938 | LOSS: 0.1778 | ACC 0.9435\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0032/0938 | LOSS: 0.1755 | ACC 0.9438\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0033/0938 | LOSS: 0.1732 | ACC 0.9441\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0034/0938 | LOSS: 0.1719 | ACC 0.9435\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0035/0938 | LOSS: 0.1704 | ACC 0.9437\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0036/0938 | LOSS: 0.1711 | ACC 0.9436\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0037/0938 | LOSS: 0.1688 | ACC 0.9443\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0038/0938 | LOSS: 0.1683 | ACC 0.9453\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0039/0938 | LOSS: 0.1658 | ACC 0.9463\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0040/0938 | LOSS: 0.1657 | ACC 0.9461\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0041/0938 | LOSS: 0.1668 | ACC 0.9455\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0042/0938 | LOSS: 0.1683 | ACC 0.9449\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0043/0938 | LOSS: 0.1717 | ACC 0.9433\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0044/0938 | LOSS: 0.1719 | ACC 0.9428\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0045/0938 | LOSS: 0.1720 | ACC 0.9424\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0046/0938 | LOSS: 0.1716 | ACC 0.9426\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0047/0938 | LOSS: 0.1696 | ACC 0.9435\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0048/0938 | LOSS: 0.1685 | ACC 0.9443\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0049/0938 | LOSS: 0.1675 | ACC 0.9448\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0050/0938 | LOSS: 0.1666 | ACC 0.9450\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0051/0938 | LOSS: 0.1646 | ACC 0.9455\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0052/0938 | LOSS: 0.1690 | ACC 0.9450\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0053/0938 | LOSS: 0.1668 | ACC 0.9458\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0054/0938 | LOSS: 0.1667 | ACC 0.9459\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0055/0938 | LOSS: 0.1658 | ACC 0.9463\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0056/0938 | LOSS: 0.1649 | ACC 0.9467\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0057/0938 | LOSS: 0.1641 | ACC 0.9465\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0058/0938 | LOSS: 0.1641 | ACC 0.9464\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0059/0938 | LOSS: 0.1655 | ACC 0.9460\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0060/0938 | LOSS: 0.1649 | ACC 0.9461\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0061/0938 | LOSS: 0.1666 | ACC 0.9449\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0062/0938 | LOSS: 0.1666 | ACC 0.9448\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0063/0938 | LOSS: 0.1649 | ACC 0.9454\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0064/0938 | LOSS: 0.1655 | ACC 0.9446\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0065/0938 | LOSS: 0.1670 | ACC 0.9447\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0066/0938 | LOSS: 0.1657 | ACC 0.9451\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0067/0938 | LOSS: 0.1641 | ACC 0.9457\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0068/0938 | LOSS: 0.1635 | ACC 0.9460\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0069/0938 | LOSS: 0.1632 | ACC 0.9461\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0070/0938 | LOSS: 0.1629 | ACC 0.9460\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0071/0938 | LOSS: 0.1622 | ACC 0.9461\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0072/0938 | LOSS: 0.1612 | ACC 0.9466\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0073/0938 | LOSS: 0.1614 | ACC 0.9471\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0074/0938 | LOSS: 0.1603 | ACC 0.9476\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0075/0938 | LOSS: 0.1599 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0076/0938 | LOSS: 0.1593 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0077/0938 | LOSS: 0.1583 | ACC 0.9485\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0078/0938 | LOSS: 0.1582 | ACC 0.9487\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0079/0938 | LOSS: 0.1576 | ACC 0.9488\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0080/0938 | LOSS: 0.1600 | ACC 0.9484\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0081/0938 | LOSS: 0.1627 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0082/0938 | LOSS: 0.1620 | ACC 0.9482\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0083/0938 | LOSS: 0.1614 | ACC 0.9482\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0084/0938 | LOSS: 0.1608 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0085/0938 | LOSS: 0.1601 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0086/0938 | LOSS: 0.1596 | ACC 0.9486\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0087/0938 | LOSS: 0.1587 | ACC 0.9488\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0088/0938 | LOSS: 0.1591 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0089/0938 | LOSS: 0.1601 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0090/0938 | LOSS: 0.1606 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0091/0938 | LOSS: 0.1591 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0092/0938 | LOSS: 0.1604 | ACC 0.9484\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0093/0938 | LOSS: 0.1604 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0094/0938 | LOSS: 0.1604 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0095/0938 | LOSS: 0.1602 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0096/0938 | LOSS: 0.1592 | ACC 0.9482\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0097/0938 | LOSS: 0.1586 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0098/0938 | LOSS: 0.1611 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0099/0938 | LOSS: 0.1606 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0100/0938 | LOSS: 0.1615 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0101/0938 | LOSS: 0.1622 | ACC 0.9474\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0102/0938 | LOSS: 0.1615 | ACC 0.9478\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0103/0938 | LOSS: 0.1615 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0104/0938 | LOSS: 0.1622 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0105/0938 | LOSS: 0.1622 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0106/0938 | LOSS: 0.1634 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0107/0938 | LOSS: 0.1639 | ACC 0.9473\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0108/0938 | LOSS: 0.1644 | ACC 0.9469\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0109/0938 | LOSS: 0.1636 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0110/0938 | LOSS: 0.1633 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0111/0938 | LOSS: 0.1633 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0112/0938 | LOSS: 0.1638 | ACC 0.9473\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0113/0938 | LOSS: 0.1632 | ACC 0.9476\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0114/0938 | LOSS: 0.1622 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0115/0938 | LOSS: 0.1629 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0116/0938 | LOSS: 0.1620 | ACC 0.9483\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0117/0938 | LOSS: 0.1617 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0118/0938 | LOSS: 0.1615 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0119/0938 | LOSS: 0.1619 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0120/0938 | LOSS: 0.1611 | ACC 0.9480\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0121/0938 | LOSS: 0.1618 | ACC 0.9478\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0122/0938 | LOSS: 0.1620 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0123/0938 | LOSS: 0.1621 | ACC 0.9474\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0124/0938 | LOSS: 0.1619 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0125/0938 | LOSS: 0.1618 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0126/0938 | LOSS: 0.1614 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0127/0938 | LOSS: 0.1614 | ACC 0.9476\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0128/0938 | LOSS: 0.1617 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0129/0938 | LOSS: 0.1613 | ACC 0.9478\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0130/0938 | LOSS: 0.1608 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0131/0938 | LOSS: 0.1610 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0132/0938 | LOSS: 0.1624 | ACC 0.9478\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0133/0938 | LOSS: 0.1627 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0134/0938 | LOSS: 0.1629 | ACC 0.9474\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0135/0938 | LOSS: 0.1631 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0136/0938 | LOSS: 0.1625 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0137/0938 | LOSS: 0.1622 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0138/0938 | LOSS: 0.1627 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0139/0938 | LOSS: 0.1631 | ACC 0.9474\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0140/0938 | LOSS: 0.1639 | ACC 0.9473\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0141/0938 | LOSS: 0.1634 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0142/0938 | LOSS: 0.1639 | ACC 0.9473\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0143/0938 | LOSS: 0.1666 | ACC 0.9469\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0144/0938 | LOSS: 0.1663 | ACC 0.9472\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0145/0938 | LOSS: 0.1660 | ACC 0.9473\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0146/0938 | LOSS: 0.1666 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0147/0938 | LOSS: 0.1665 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0148/0938 | LOSS: 0.1663 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0149/0938 | LOSS: 0.1665 | ACC 0.9474\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0150/0938 | LOSS: 0.1667 | ACC 0.9475\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0151/0938 | LOSS: 0.1669 | ACC 0.9476\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0152/0938 | LOSS: 0.1667 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0153/0938 | LOSS: 0.1667 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0154/0938 | LOSS: 0.1662 | ACC 0.9477\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0155/0938 | LOSS: 0.1663 | ACC 0.9478\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0156/0938 | LOSS: 0.1656 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0157/0938 | LOSS: 0.1660 | ACC 0.9479\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0158/0938 | LOSS: 0.1654 | ACC 0.9481\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0159/0938 | LOSS: 0.1649 | ACC 0.9482\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0160/0938 | LOSS: 0.1643 | ACC 0.9484\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0161/0938 | LOSS: 0.1643 | ACC 0.9484\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0162/0938 | LOSS: 0.1641 | ACC 0.9486\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0163/0938 | LOSS: 0.1634 | ACC 0.9489\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0164/0938 | LOSS: 0.1630 | ACC 0.9491\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0165/0938 | LOSS: 0.1626 | ACC 0.9492\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0166/0938 | LOSS: 0.1629 | ACC 0.9492\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0167/0938 | LOSS: 0.1627 | ACC 0.9492\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0168/0938 | LOSS: 0.1629 | ACC 0.9492\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0169/0938 | LOSS: 0.1634 | ACC 0.9491\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0170/0938 | LOSS: 0.1634 | ACC 0.9492\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0171/0938 | LOSS: 0.1631 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0172/0938 | LOSS: 0.1627 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0173/0938 | LOSS: 0.1626 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0174/0938 | LOSS: 0.1619 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0175/0938 | LOSS: 0.1621 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0176/0938 | LOSS: 0.1623 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0177/0938 | LOSS: 0.1621 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0178/0938 | LOSS: 0.1619 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0179/0938 | LOSS: 0.1617 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0180/0938 | LOSS: 0.1615 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0181/0938 | LOSS: 0.1617 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0182/0938 | LOSS: 0.1619 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0183/0938 | LOSS: 0.1616 | ACC 0.9493\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0184/0938 | LOSS: 0.1613 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0185/0938 | LOSS: 0.1611 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0186/0938 | LOSS: 0.1615 | ACC 0.9493\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0187/0938 | LOSS: 0.1615 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0188/0938 | LOSS: 0.1609 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0189/0938 | LOSS: 0.1609 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0190/0938 | LOSS: 0.1607 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0191/0938 | LOSS: 0.1601 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0192/0938 | LOSS: 0.1599 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0193/0938 | LOSS: 0.1599 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0194/0938 | LOSS: 0.1619 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0195/0938 | LOSS: 0.1624 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0196/0938 | LOSS: 0.1622 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0197/0938 | LOSS: 0.1620 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0198/0938 | LOSS: 0.1619 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0199/0938 | LOSS: 0.1616 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0200/0938 | LOSS: 0.1611 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0201/0938 | LOSS: 0.1614 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0202/0938 | LOSS: 0.1615 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0203/0938 | LOSS: 0.1611 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0204/0938 | LOSS: 0.1605 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0205/0938 | LOSS: 0.1602 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0206/0938 | LOSS: 0.1601 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0207/0938 | LOSS: 0.1600 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0208/0938 | LOSS: 0.1597 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0209/0938 | LOSS: 0.1596 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0210/0938 | LOSS: 0.1595 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0211/0938 | LOSS: 0.1592 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0212/0938 | LOSS: 0.1593 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0213/0938 | LOSS: 0.1593 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0214/0938 | LOSS: 0.1597 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0215/0938 | LOSS: 0.1598 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0216/0938 | LOSS: 0.1597 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0217/0938 | LOSS: 0.1595 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0218/0938 | LOSS: 0.1596 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0219/0938 | LOSS: 0.1596 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0220/0938 | LOSS: 0.1597 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0221/0938 | LOSS: 0.1596 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0222/0938 | LOSS: 0.1599 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0223/0938 | LOSS: 0.1602 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0224/0938 | LOSS: 0.1604 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0225/0938 | LOSS: 0.1600 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0226/0938 | LOSS: 0.1596 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0227/0938 | LOSS: 0.1600 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0228/0938 | LOSS: 0.1598 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0229/0938 | LOSS: 0.1593 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0230/0938 | LOSS: 0.1594 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0231/0938 | LOSS: 0.1592 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0232/0938 | LOSS: 0.1593 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0233/0938 | LOSS: 0.1593 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0234/0938 | LOSS: 0.1607 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0235/0938 | LOSS: 0.1606 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0236/0938 | LOSS: 0.1604 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0237/0938 | LOSS: 0.1602 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0238/0938 | LOSS: 0.1608 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0239/0938 | LOSS: 0.1605 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0240/0938 | LOSS: 0.1607 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0241/0938 | LOSS: 0.1605 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0242/0938 | LOSS: 0.1606 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0243/0938 | LOSS: 0.1605 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0244/0938 | LOSS: 0.1602 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0245/0938 | LOSS: 0.1602 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0246/0938 | LOSS: 0.1603 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0247/0938 | LOSS: 0.1602 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0248/0938 | LOSS: 0.1608 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0249/0938 | LOSS: 0.1608 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0250/0938 | LOSS: 0.1607 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0251/0938 | LOSS: 0.1605 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0252/0938 | LOSS: 0.1600 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0253/0938 | LOSS: 0.1606 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0254/0938 | LOSS: 0.1604 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0255/0938 | LOSS: 0.1604 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0256/0938 | LOSS: 0.1606 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0257/0938 | LOSS: 0.1606 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0258/0938 | LOSS: 0.1604 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0259/0938 | LOSS: 0.1610 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0260/0938 | LOSS: 0.1606 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0261/0938 | LOSS: 0.1607 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0262/0938 | LOSS: 0.1609 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0263/0938 | LOSS: 0.1613 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0264/0938 | LOSS: 0.1618 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0265/0938 | LOSS: 0.1615 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0266/0938 | LOSS: 0.1616 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0267/0938 | LOSS: 0.1615 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0268/0938 | LOSS: 0.1623 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0269/0938 | LOSS: 0.1622 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0270/0938 | LOSS: 0.1618 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0271/0938 | LOSS: 0.1614 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0272/0938 | LOSS: 0.1619 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0273/0938 | LOSS: 0.1622 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0274/0938 | LOSS: 0.1632 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0275/0938 | LOSS: 0.1630 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0276/0938 | LOSS: 0.1627 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0277/0938 | LOSS: 0.1626 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0278/0938 | LOSS: 0.1623 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0279/0938 | LOSS: 0.1621 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0280/0938 | LOSS: 0.1622 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0281/0938 | LOSS: 0.1618 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0282/0938 | LOSS: 0.1617 | ACC 0.9500\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0283/0938 | LOSS: 0.1615 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0284/0938 | LOSS: 0.1614 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0285/0938 | LOSS: 0.1611 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0286/0938 | LOSS: 0.1612 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0287/0938 | LOSS: 0.1609 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0288/0938 | LOSS: 0.1613 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0289/0938 | LOSS: 0.1613 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0290/0938 | LOSS: 0.1609 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0291/0938 | LOSS: 0.1608 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0292/0938 | LOSS: 0.1604 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0293/0938 | LOSS: 0.1604 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0294/0938 | LOSS: 0.1603 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0295/0938 | LOSS: 0.1602 | ACC 0.9506\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0296/0938 | LOSS: 0.1601 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0297/0938 | LOSS: 0.1602 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0298/0938 | LOSS: 0.1603 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0299/0938 | LOSS: 0.1600 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0300/0938 | LOSS: 0.1604 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0301/0938 | LOSS: 0.1605 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0302/0938 | LOSS: 0.1604 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0303/0938 | LOSS: 0.1606 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0304/0938 | LOSS: 0.1613 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0305/0938 | LOSS: 0.1611 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0306/0938 | LOSS: 0.1612 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0307/0938 | LOSS: 0.1615 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0308/0938 | LOSS: 0.1618 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0309/0938 | LOSS: 0.1623 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0310/0938 | LOSS: 0.1625 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0311/0938 | LOSS: 0.1623 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0312/0938 | LOSS: 0.1620 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0313/0938 | LOSS: 0.1618 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0314/0938 | LOSS: 0.1630 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0315/0938 | LOSS: 0.1629 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0316/0938 | LOSS: 0.1638 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0317/0938 | LOSS: 0.1640 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0318/0938 | LOSS: 0.1644 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0319/0938 | LOSS: 0.1645 | ACC 0.9494\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0320/0938 | LOSS: 0.1644 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0321/0938 | LOSS: 0.1642 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0322/0938 | LOSS: 0.1640 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0323/0938 | LOSS: 0.1644 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0324/0938 | LOSS: 0.1641 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0325/0938 | LOSS: 0.1642 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0326/0938 | LOSS: 0.1639 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0327/0938 | LOSS: 0.1638 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0328/0938 | LOSS: 0.1637 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0329/0938 | LOSS: 0.1638 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0330/0938 | LOSS: 0.1638 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0331/0938 | LOSS: 0.1638 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0332/0938 | LOSS: 0.1637 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0333/0938 | LOSS: 0.1634 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0334/0938 | LOSS: 0.1632 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0335/0938 | LOSS: 0.1632 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0336/0938 | LOSS: 0.1634 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0337/0938 | LOSS: 0.1632 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0338/0938 | LOSS: 0.1631 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0339/0938 | LOSS: 0.1629 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0340/0938 | LOSS: 0.1630 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0341/0938 | LOSS: 0.1626 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0342/0938 | LOSS: 0.1627 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0343/0938 | LOSS: 0.1633 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0344/0938 | LOSS: 0.1633 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0345/0938 | LOSS: 0.1645 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0346/0938 | LOSS: 0.1645 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0347/0938 | LOSS: 0.1644 | ACC 0.9496\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0348/0938 | LOSS: 0.1643 | ACC 0.9495\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0349/0938 | LOSS: 0.1640 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0350/0938 | LOSS: 0.1639 | ACC 0.9497\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0351/0938 | LOSS: 0.1635 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0352/0938 | LOSS: 0.1634 | ACC 0.9498\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0353/0938 | LOSS: 0.1630 | ACC 0.9499\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0354/0938 | LOSS: 0.1627 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0355/0938 | LOSS: 0.1625 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0356/0938 | LOSS: 0.1622 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0357/0938 | LOSS: 0.1626 | ACC 0.9501\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0358/0938 | LOSS: 0.1624 | ACC 0.9502\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0359/0938 | LOSS: 0.1623 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0360/0938 | LOSS: 0.1623 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0361/0938 | LOSS: 0.1621 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0362/0938 | LOSS: 0.1617 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0363/0938 | LOSS: 0.1615 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0364/0938 | LOSS: 0.1618 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0365/0938 | LOSS: 0.1620 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0366/0938 | LOSS: 0.1619 | ACC 0.9503\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0367/0938 | LOSS: 0.1617 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0368/0938 | LOSS: 0.1616 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0369/0938 | LOSS: 0.1618 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0370/0938 | LOSS: 0.1617 | ACC 0.9504\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0371/0938 | LOSS: 0.1614 | ACC 0.9505\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0372/0938 | LOSS: 0.1612 | ACC 0.9506\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0373/0938 | LOSS: 0.1614 | ACC 0.9506\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0374/0938 | LOSS: 0.1612 | ACC 0.9507\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0375/0938 | LOSS: 0.1610 | ACC 0.9507\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0376/0938 | LOSS: 0.1607 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0377/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0378/0938 | LOSS: 0.1610 | ACC 0.9506\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0379/0938 | LOSS: 0.1610 | ACC 0.9507\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0380/0938 | LOSS: 0.1610 | ACC 0.9507\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0381/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0382/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0383/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0384/0938 | LOSS: 0.1606 | ACC 0.9509\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0385/0938 | LOSS: 0.1603 | ACC 0.9510\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0386/0938 | LOSS: 0.1605 | ACC 0.9509\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0387/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0388/0938 | LOSS: 0.1606 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0389/0938 | LOSS: 0.1608 | ACC 0.9508\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0390/0938 | LOSS: 0.1606 | ACC 0.9510\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0391/0938 | LOSS: 0.1603 | ACC 0.9510\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0392/0938 | LOSS: 0.1600 | ACC 0.9512\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0393/0938 | LOSS: 0.1598 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0394/0938 | LOSS: 0.1597 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0395/0938 | LOSS: 0.1599 | ACC 0.9512\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0396/0938 | LOSS: 0.1597 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0397/0938 | LOSS: 0.1598 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0398/0938 | LOSS: 0.1599 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0399/0938 | LOSS: 0.1598 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0400/0938 | LOSS: 0.1599 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0401/0938 | LOSS: 0.1600 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0402/0938 | LOSS: 0.1598 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0403/0938 | LOSS: 0.1598 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0404/0938 | LOSS: 0.1603 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0405/0938 | LOSS: 0.1602 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0406/0938 | LOSS: 0.1599 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0407/0938 | LOSS: 0.1599 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0408/0938 | LOSS: 0.1599 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0409/0938 | LOSS: 0.1600 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0410/0938 | LOSS: 0.1597 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0411/0938 | LOSS: 0.1597 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0412/0938 | LOSS: 0.1598 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0413/0938 | LOSS: 0.1598 | ACC 0.9513\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0414/0938 | LOSS: 0.1595 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0415/0938 | LOSS: 0.1594 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0416/0938 | LOSS: 0.1591 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0417/0938 | LOSS: 0.1591 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0418/0938 | LOSS: 0.1590 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0419/0938 | LOSS: 0.1593 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0420/0938 | LOSS: 0.1592 | ACC 0.9514\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0421/0938 | LOSS: 0.1590 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0422/0938 | LOSS: 0.1591 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0423/0938 | LOSS: 0.1590 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0424/0938 | LOSS: 0.1587 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0425/0938 | LOSS: 0.1585 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0426/0938 | LOSS: 0.1588 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0427/0938 | LOSS: 0.1587 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0428/0938 | LOSS: 0.1587 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0429/0938 | LOSS: 0.1585 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0430/0938 | LOSS: 0.1585 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0431/0938 | LOSS: 0.1583 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0432/0938 | LOSS: 0.1584 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0433/0938 | LOSS: 0.1581 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0434/0938 | LOSS: 0.1583 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0435/0938 | LOSS: 0.1584 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0436/0938 | LOSS: 0.1583 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0437/0938 | LOSS: 0.1584 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0438/0938 | LOSS: 0.1583 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0439/0938 | LOSS: 0.1583 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0440/0938 | LOSS: 0.1586 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0441/0938 | LOSS: 0.1584 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0442/0938 | LOSS: 0.1586 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0443/0938 | LOSS: 0.1585 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0444/0938 | LOSS: 0.1584 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0445/0938 | LOSS: 0.1585 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0446/0938 | LOSS: 0.1587 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0447/0938 | LOSS: 0.1587 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0448/0938 | LOSS: 0.1586 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0449/0938 | LOSS: 0.1585 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0450/0938 | LOSS: 0.1583 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0451/0938 | LOSS: 0.1586 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0452/0938 | LOSS: 0.1587 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0453/0938 | LOSS: 0.1586 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0454/0938 | LOSS: 0.1586 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0455/0938 | LOSS: 0.1585 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0456/0938 | LOSS: 0.1583 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0457/0938 | LOSS: 0.1586 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0458/0938 | LOSS: 0.1587 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0459/0938 | LOSS: 0.1585 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0460/0938 | LOSS: 0.1591 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0461/0938 | LOSS: 0.1590 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0462/0938 | LOSS: 0.1590 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0463/0938 | LOSS: 0.1592 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0464/0938 | LOSS: 0.1593 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0465/0938 | LOSS: 0.1595 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0466/0938 | LOSS: 0.1596 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0467/0938 | LOSS: 0.1599 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0468/0938 | LOSS: 0.1596 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0469/0938 | LOSS: 0.1594 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0470/0938 | LOSS: 0.1595 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0471/0938 | LOSS: 0.1594 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0472/0938 | LOSS: 0.1593 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0473/0938 | LOSS: 0.1593 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0474/0938 | LOSS: 0.1592 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0475/0938 | LOSS: 0.1591 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0476/0938 | LOSS: 0.1592 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0477/0938 | LOSS: 0.1591 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0478/0938 | LOSS: 0.1592 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0479/0938 | LOSS: 0.1590 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0480/0938 | LOSS: 0.1589 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0481/0938 | LOSS: 0.1588 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0482/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0483/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0484/0938 | LOSS: 0.1591 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0485/0938 | LOSS: 0.1594 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0486/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0487/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0488/0938 | LOSS: 0.1595 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0489/0938 | LOSS: 0.1594 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0490/0938 | LOSS: 0.1597 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0491/0938 | LOSS: 0.1596 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0492/0938 | LOSS: 0.1596 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0493/0938 | LOSS: 0.1596 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0494/0938 | LOSS: 0.1594 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0495/0938 | LOSS: 0.1594 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0496/0938 | LOSS: 0.1593 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0497/0938 | LOSS: 0.1594 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0498/0938 | LOSS: 0.1594 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0499/0938 | LOSS: 0.1594 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0500/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0501/0938 | LOSS: 0.1590 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0502/0938 | LOSS: 0.1589 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0503/0938 | LOSS: 0.1591 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0504/0938 | LOSS: 0.1592 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0505/0938 | LOSS: 0.1595 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0506/0938 | LOSS: 0.1593 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0507/0938 | LOSS: 0.1599 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0508/0938 | LOSS: 0.1603 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0509/0938 | LOSS: 0.1603 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0510/0938 | LOSS: 0.1603 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0511/0938 | LOSS: 0.1602 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0512/0938 | LOSS: 0.1606 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0513/0938 | LOSS: 0.1605 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0514/0938 | LOSS: 0.1608 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0515/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0516/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0517/0938 | LOSS: 0.1605 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0518/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0519/0938 | LOSS: 0.1605 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0520/0938 | LOSS: 0.1604 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0521/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0522/0938 | LOSS: 0.1605 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0523/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0524/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0525/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0526/0938 | LOSS: 0.1606 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0527/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0528/0938 | LOSS: 0.1605 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0529/0938 | LOSS: 0.1605 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0530/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0531/0938 | LOSS: 0.1608 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0532/0938 | LOSS: 0.1606 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0533/0938 | LOSS: 0.1606 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0534/0938 | LOSS: 0.1607 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0535/0938 | LOSS: 0.1606 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0536/0938 | LOSS: 0.1606 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0537/0938 | LOSS: 0.1606 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0538/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0539/0938 | LOSS: 0.1608 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0540/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0541/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0542/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0543/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0544/0938 | LOSS: 0.1607 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0545/0938 | LOSS: 0.1607 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0546/0938 | LOSS: 0.1606 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0547/0938 | LOSS: 0.1606 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0548/0938 | LOSS: 0.1606 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0549/0938 | LOSS: 0.1605 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0550/0938 | LOSS: 0.1606 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0551/0938 | LOSS: 0.1605 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0552/0938 | LOSS: 0.1608 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0553/0938 | LOSS: 0.1606 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0554/0938 | LOSS: 0.1605 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0555/0938 | LOSS: 0.1604 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0556/0938 | LOSS: 0.1603 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0557/0938 | LOSS: 0.1609 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0558/0938 | LOSS: 0.1611 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0559/0938 | LOSS: 0.1609 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0560/0938 | LOSS: 0.1609 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0561/0938 | LOSS: 0.1613 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0562/0938 | LOSS: 0.1613 | ACC 0.9515\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0563/0938 | LOSS: 0.1612 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0564/0938 | LOSS: 0.1611 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0565/0938 | LOSS: 0.1611 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0566/0938 | LOSS: 0.1611 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0567/0938 | LOSS: 0.1610 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0568/0938 | LOSS: 0.1609 | ACC 0.9516\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0569/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0570/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0571/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0572/0938 | LOSS: 0.1604 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0573/0938 | LOSS: 0.1605 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0574/0938 | LOSS: 0.1607 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0575/0938 | LOSS: 0.1607 | ACC 0.9518\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0576/0938 | LOSS: 0.1606 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0577/0938 | LOSS: 0.1604 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0578/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0579/0938 | LOSS: 0.1602 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0580/0938 | LOSS: 0.1602 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0581/0938 | LOSS: 0.1600 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0582/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0583/0938 | LOSS: 0.1599 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0584/0938 | LOSS: 0.1602 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0585/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0586/0938 | LOSS: 0.1603 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0587/0938 | LOSS: 0.1602 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0588/0938 | LOSS: 0.1601 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0589/0938 | LOSS: 0.1601 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0590/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0591/0938 | LOSS: 0.1601 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0592/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0593/0938 | LOSS: 0.1601 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0594/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0595/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0596/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0597/0938 | LOSS: 0.1598 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0598/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0599/0938 | LOSS: 0.1600 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0600/0938 | LOSS: 0.1600 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0601/0938 | LOSS: 0.1604 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0602/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0603/0938 | LOSS: 0.1602 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0604/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0605/0938 | LOSS: 0.1605 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0606/0938 | LOSS: 0.1604 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0607/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0608/0938 | LOSS: 0.1603 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0609/0938 | LOSS: 0.1606 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0610/0938 | LOSS: 0.1605 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0611/0938 | LOSS: 0.1605 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0612/0938 | LOSS: 0.1605 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0613/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0614/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0615/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0616/0938 | LOSS: 0.1607 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0617/0938 | LOSS: 0.1607 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0618/0938 | LOSS: 0.1607 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0619/0938 | LOSS: 0.1609 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0620/0938 | LOSS: 0.1608 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0621/0938 | LOSS: 0.1607 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0622/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0623/0938 | LOSS: 0.1609 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0624/0938 | LOSS: 0.1609 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0625/0938 | LOSS: 0.1610 | ACC 0.9519\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0626/0938 | LOSS: 0.1610 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0627/0938 | LOSS: 0.1609 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0628/0938 | LOSS: 0.1608 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0629/0938 | LOSS: 0.1607 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0630/0938 | LOSS: 0.1607 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0631/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0632/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0633/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0634/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0635/0938 | LOSS: 0.1607 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0636/0938 | LOSS: 0.1607 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0637/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0638/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0639/0938 | LOSS: 0.1603 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0640/0938 | LOSS: 0.1604 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0641/0938 | LOSS: 0.1604 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0642/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0643/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0644/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0645/0938 | LOSS: 0.1606 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0646/0938 | LOSS: 0.1605 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0647/0938 | LOSS: 0.1608 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0648/0938 | LOSS: 0.1608 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0649/0938 | LOSS: 0.1607 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0650/0938 | LOSS: 0.1605 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0651/0938 | LOSS: 0.1603 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0652/0938 | LOSS: 0.1604 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0653/0938 | LOSS: 0.1603 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0654/0938 | LOSS: 0.1604 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0655/0938 | LOSS: 0.1604 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0656/0938 | LOSS: 0.1605 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0657/0938 | LOSS: 0.1604 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0658/0938 | LOSS: 0.1602 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0659/0938 | LOSS: 0.1603 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0660/0938 | LOSS: 0.1601 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0661/0938 | LOSS: 0.1601 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0662/0938 | LOSS: 0.1601 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0663/0938 | LOSS: 0.1601 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0664/0938 | LOSS: 0.1601 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0665/0938 | LOSS: 0.1599 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0666/0938 | LOSS: 0.1599 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0667/0938 | LOSS: 0.1606 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0668/0938 | LOSS: 0.1606 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0669/0938 | LOSS: 0.1606 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0670/0938 | LOSS: 0.1608 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0671/0938 | LOSS: 0.1608 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0672/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0673/0938 | LOSS: 0.1608 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0674/0938 | LOSS: 0.1608 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0675/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0676/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0677/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0678/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0679/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0680/0938 | LOSS: 0.1605 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0681/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0682/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0683/0938 | LOSS: 0.1607 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0684/0938 | LOSS: 0.1606 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0685/0938 | LOSS: 0.1605 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0686/0938 | LOSS: 0.1605 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0687/0938 | LOSS: 0.1605 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0688/0938 | LOSS: 0.1611 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0689/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0690/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0691/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0692/0938 | LOSS: 0.1611 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0693/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0694/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0695/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0696/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0697/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0698/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0699/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0700/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0701/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0702/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0703/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0704/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0705/0938 | LOSS: 0.1606 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0706/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0707/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0708/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0709/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0710/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0711/0938 | LOSS: 0.1603 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0712/0938 | LOSS: 0.1607 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0713/0938 | LOSS: 0.1607 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0714/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0715/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0716/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0717/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0718/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0719/0938 | LOSS: 0.1610 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0720/0938 | LOSS: 0.1609 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0721/0938 | LOSS: 0.1609 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0722/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0723/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0724/0938 | LOSS: 0.1608 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0725/0938 | LOSS: 0.1606 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0726/0938 | LOSS: 0.1607 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0727/0938 | LOSS: 0.1606 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0728/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0729/0938 | LOSS: 0.1609 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0730/0938 | LOSS: 0.1609 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0731/0938 | LOSS: 0.1612 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0732/0938 | LOSS: 0.1615 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0733/0938 | LOSS: 0.1615 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0734/0938 | LOSS: 0.1614 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0735/0938 | LOSS: 0.1614 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0736/0938 | LOSS: 0.1613 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0737/0938 | LOSS: 0.1613 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0738/0938 | LOSS: 0.1614 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0739/0938 | LOSS: 0.1613 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0740/0938 | LOSS: 0.1615 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0741/0938 | LOSS: 0.1618 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0742/0938 | LOSS: 0.1619 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0743/0938 | LOSS: 0.1618 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0744/0938 | LOSS: 0.1618 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0745/0938 | LOSS: 0.1618 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0746/0938 | LOSS: 0.1622 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0747/0938 | LOSS: 0.1622 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0748/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0749/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0750/0938 | LOSS: 0.1623 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0751/0938 | LOSS: 0.1623 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0752/0938 | LOSS: 0.1622 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0753/0938 | LOSS: 0.1622 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0754/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0755/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0756/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0757/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0758/0938 | LOSS: 0.1618 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0759/0938 | LOSS: 0.1618 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0760/0938 | LOSS: 0.1618 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0761/0938 | LOSS: 0.1618 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0762/0938 | LOSS: 0.1620 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0763/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0764/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0765/0938 | LOSS: 0.1618 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0766/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0767/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0768/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0769/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0770/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0771/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0772/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0773/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0774/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0775/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0776/0938 | LOSS: 0.1618 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0777/0938 | LOSS: 0.1618 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0778/0938 | LOSS: 0.1618 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0779/0938 | LOSS: 0.1619 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0780/0938 | LOSS: 0.1618 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0781/0938 | LOSS: 0.1617 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0782/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0783/0938 | LOSS: 0.1618 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0784/0938 | LOSS: 0.1619 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0785/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0786/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0787/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0788/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0789/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0790/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0791/0938 | LOSS: 0.1623 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0792/0938 | LOSS: 0.1623 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0793/0938 | LOSS: 0.1623 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0794/0938 | LOSS: 0.1624 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0795/0938 | LOSS: 0.1624 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0796/0938 | LOSS: 0.1625 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0797/0938 | LOSS: 0.1625 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0798/0938 | LOSS: 0.1626 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0799/0938 | LOSS: 0.1626 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0800/0938 | LOSS: 0.1626 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0801/0938 | LOSS: 0.1627 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0802/0938 | LOSS: 0.1626 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0803/0938 | LOSS: 0.1625 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0804/0938 | LOSS: 0.1625 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0805/0938 | LOSS: 0.1624 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0806/0938 | LOSS: 0.1625 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0807/0938 | LOSS: 0.1625 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0808/0938 | LOSS: 0.1625 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0809/0938 | LOSS: 0.1624 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0810/0938 | LOSS: 0.1626 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0811/0938 | LOSS: 0.1625 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0812/0938 | LOSS: 0.1624 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0813/0938 | LOSS: 0.1623 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0814/0938 | LOSS: 0.1624 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0815/0938 | LOSS: 0.1622 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0816/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0817/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0818/0938 | LOSS: 0.1622 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0819/0938 | LOSS: 0.1622 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0820/0938 | LOSS: 0.1621 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0821/0938 | LOSS: 0.1620 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0822/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0823/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0824/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0825/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0826/0938 | LOSS: 0.1622 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0827/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0828/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0829/0938 | LOSS: 0.1624 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0830/0938 | LOSS: 0.1624 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0831/0938 | LOSS: 0.1623 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0832/0938 | LOSS: 0.1622 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0833/0938 | LOSS: 0.1621 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0834/0938 | LOSS: 0.1624 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0835/0938 | LOSS: 0.1624 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0836/0938 | LOSS: 0.1625 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0837/0938 | LOSS: 0.1624 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0838/0938 | LOSS: 0.1624 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0839/0938 | LOSS: 0.1625 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0840/0938 | LOSS: 0.1625 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0841/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0842/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0843/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0844/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0845/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0846/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0847/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0848/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0849/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0850/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0851/0938 | LOSS: 0.1626 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0852/0938 | LOSS: 0.1628 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0853/0938 | LOSS: 0.1628 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0854/0938 | LOSS: 0.1631 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0855/0938 | LOSS: 0.1632 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0856/0938 | LOSS: 0.1631 | ACC 0.9520\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0857/0938 | LOSS: 0.1631 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0858/0938 | LOSS: 0.1630 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0859/0938 | LOSS: 0.1629 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0860/0938 | LOSS: 0.1629 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0861/0938 | LOSS: 0.1628 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0862/0938 | LOSS: 0.1632 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0863/0938 | LOSS: 0.1632 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0864/0938 | LOSS: 0.1633 | ACC 0.9521\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0865/0938 | LOSS: 0.1632 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0866/0938 | LOSS: 0.1633 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0867/0938 | LOSS: 0.1633 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0868/0938 | LOSS: 0.1632 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0869/0938 | LOSS: 0.1631 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0870/0938 | LOSS: 0.1630 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0871/0938 | LOSS: 0.1630 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0872/0938 | LOSS: 0.1630 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0873/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0874/0938 | LOSS: 0.1629 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0875/0938 | LOSS: 0.1630 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0876/0938 | LOSS: 0.1630 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0877/0938 | LOSS: 0.1631 | ACC 0.9522\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0878/0938 | LOSS: 0.1630 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0879/0938 | LOSS: 0.1630 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0880/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0881/0938 | LOSS: 0.1628 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0882/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0883/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0884/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0885/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0886/0938 | LOSS: 0.1628 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0887/0938 | LOSS: 0.1628 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0888/0938 | LOSS: 0.1628 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0889/0938 | LOSS: 0.1630 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0890/0938 | LOSS: 0.1629 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0891/0938 | LOSS: 0.1628 | ACC 0.9523\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0892/0938 | LOSS: 0.1627 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0893/0938 | LOSS: 0.1627 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0894/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0895/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0896/0938 | LOSS: 0.1627 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0897/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0898/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0899/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0900/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0901/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0902/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0903/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0904/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0905/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0906/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0907/0938 | LOSS: 0.1625 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0908/0938 | LOSS: 0.1624 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0909/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0910/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0911/0938 | LOSS: 0.1622 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0912/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0913/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0914/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0915/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0916/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0917/0938 | LOSS: 0.1624 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0918/0938 | LOSS: 0.1622 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0919/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0920/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0921/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0922/0938 | LOSS: 0.1622 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0923/0938 | LOSS: 0.1621 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0924/0938 | LOSS: 0.1621 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0925/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0926/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0927/0938 | LOSS: 0.1619 | ACC 0.9526\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0928/0938 | LOSS: 0.1619 | ACC 0.9526\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0929/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0930/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0931/0938 | LOSS: 0.1622 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0932/0938 | LOSS: 0.1621 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0933/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0934/0938 | LOSS: 0.1619 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0935/0938 | LOSS: 0.1619 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0936/0938 | LOSS: 0.1620 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0937/0938 | LOSS: 0.1619 | ACC 0.9525\n",
            "TRAIN: EPOCH 0006/0010 | BATCH 0938/0938 | LOSS: 0.1618 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0001/0938 | LOSS: 0.0646 | ACC 0.9688\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0002/0938 | LOSS: 0.1005 | ACC 0.9609\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0003/0938 | LOSS: 0.0858 | ACC 0.9688\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0004/0938 | LOSS: 0.1226 | ACC 0.9570\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0005/0938 | LOSS: 0.1654 | ACC 0.9469\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0006/0938 | LOSS: 0.1696 | ACC 0.9505\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0007/0938 | LOSS: 0.1567 | ACC 0.9554\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0008/0938 | LOSS: 0.1458 | ACC 0.9570\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0009/0938 | LOSS: 0.1495 | ACC 0.9549\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0010/0938 | LOSS: 0.1458 | ACC 0.9563\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0011/0938 | LOSS: 0.1463 | ACC 0.9560\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0012/0938 | LOSS: 0.1410 | ACC 0.9583\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0013/0938 | LOSS: 0.1367 | ACC 0.9591\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0014/0938 | LOSS: 0.1514 | ACC 0.9542\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0015/0938 | LOSS: 0.1507 | ACC 0.9552\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0016/0938 | LOSS: 0.1600 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0017/0938 | LOSS: 0.1688 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0018/0938 | LOSS: 0.1687 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0019/0938 | LOSS: 0.1666 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0020/0938 | LOSS: 0.1743 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0021/0938 | LOSS: 0.1693 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0022/0938 | LOSS: 0.1744 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0023/0938 | LOSS: 0.1725 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0024/0938 | LOSS: 0.1738 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0025/0938 | LOSS: 0.1702 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0026/0938 | LOSS: 0.1741 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0027/0938 | LOSS: 0.1773 | ACC 0.9502\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0028/0938 | LOSS: 0.1755 | ACC 0.9503\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0029/0938 | LOSS: 0.1804 | ACC 0.9494\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0030/0938 | LOSS: 0.1782 | ACC 0.9495\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0031/0938 | LOSS: 0.1823 | ACC 0.9491\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0032/0938 | LOSS: 0.1852 | ACC 0.9478\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0033/0938 | LOSS: 0.1811 | ACC 0.9493\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0034/0938 | LOSS: 0.1788 | ACC 0.9494\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0035/0938 | LOSS: 0.1767 | ACC 0.9500\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0036/0938 | LOSS: 0.1772 | ACC 0.9501\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0037/0938 | LOSS: 0.1749 | ACC 0.9506\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0038/0938 | LOSS: 0.1772 | ACC 0.9498\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0039/0938 | LOSS: 0.1772 | ACC 0.9495\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0040/0938 | LOSS: 0.1770 | ACC 0.9492\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0041/0938 | LOSS: 0.1749 | ACC 0.9497\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0042/0938 | LOSS: 0.1739 | ACC 0.9498\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0043/0938 | LOSS: 0.1745 | ACC 0.9499\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0044/0938 | LOSS: 0.1714 | ACC 0.9510\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0045/0938 | LOSS: 0.1699 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0046/0938 | LOSS: 0.1728 | ACC 0.9507\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0047/0938 | LOSS: 0.1727 | ACC 0.9508\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0048/0938 | LOSS: 0.1714 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0049/0938 | LOSS: 0.1703 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0050/0938 | LOSS: 0.1686 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0051/0938 | LOSS: 0.1679 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0052/0938 | LOSS: 0.1687 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0053/0938 | LOSS: 0.1686 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0054/0938 | LOSS: 0.1677 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0055/0938 | LOSS: 0.1662 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0056/0938 | LOSS: 0.1640 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0057/0938 | LOSS: 0.1629 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0058/0938 | LOSS: 0.1621 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0059/0938 | LOSS: 0.1629 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0060/0938 | LOSS: 0.1665 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0061/0938 | LOSS: 0.1666 | ACC 0.9508\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0062/0938 | LOSS: 0.1692 | ACC 0.9504\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0063/0938 | LOSS: 0.1700 | ACC 0.9501\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0064/0938 | LOSS: 0.1698 | ACC 0.9504\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0065/0938 | LOSS: 0.1700 | ACC 0.9505\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0066/0938 | LOSS: 0.1683 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0067/0938 | LOSS: 0.1678 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0068/0938 | LOSS: 0.1707 | ACC 0.9508\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0069/0938 | LOSS: 0.1703 | ACC 0.9509\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0070/0938 | LOSS: 0.1696 | ACC 0.9513\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0071/0938 | LOSS: 0.1694 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0072/0938 | LOSS: 0.1684 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0073/0938 | LOSS: 0.1680 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0074/0938 | LOSS: 0.1674 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0075/0938 | LOSS: 0.1663 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0076/0938 | LOSS: 0.1656 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0077/0938 | LOSS: 0.1648 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0078/0938 | LOSS: 0.1644 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0079/0938 | LOSS: 0.1664 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0080/0938 | LOSS: 0.1653 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0081/0938 | LOSS: 0.1659 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0082/0938 | LOSS: 0.1672 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0083/0938 | LOSS: 0.1674 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0084/0938 | LOSS: 0.1668 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0085/0938 | LOSS: 0.1662 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0086/0938 | LOSS: 0.1652 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0087/0938 | LOSS: 0.1653 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0088/0938 | LOSS: 0.1647 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0089/0938 | LOSS: 0.1633 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0090/0938 | LOSS: 0.1621 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0091/0938 | LOSS: 0.1611 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0092/0938 | LOSS: 0.1608 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0093/0938 | LOSS: 0.1600 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0094/0938 | LOSS: 0.1601 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0095/0938 | LOSS: 0.1594 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0096/0938 | LOSS: 0.1615 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0097/0938 | LOSS: 0.1613 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0098/0938 | LOSS: 0.1641 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0099/0938 | LOSS: 0.1662 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0100/0938 | LOSS: 0.1650 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0101/0938 | LOSS: 0.1668 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0102/0938 | LOSS: 0.1660 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0103/0938 | LOSS: 0.1658 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0104/0938 | LOSS: 0.1660 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0105/0938 | LOSS: 0.1672 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0106/0938 | LOSS: 0.1670 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0107/0938 | LOSS: 0.1663 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0108/0938 | LOSS: 0.1662 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0109/0938 | LOSS: 0.1656 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0110/0938 | LOSS: 0.1646 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0111/0938 | LOSS: 0.1642 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0112/0938 | LOSS: 0.1650 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0113/0938 | LOSS: 0.1649 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0114/0938 | LOSS: 0.1642 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0115/0938 | LOSS: 0.1642 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0116/0938 | LOSS: 0.1636 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0117/0938 | LOSS: 0.1629 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0118/0938 | LOSS: 0.1626 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0119/0938 | LOSS: 0.1630 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0120/0938 | LOSS: 0.1624 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0121/0938 | LOSS: 0.1629 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0122/0938 | LOSS: 0.1631 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0123/0938 | LOSS: 0.1638 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0124/0938 | LOSS: 0.1641 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0125/0938 | LOSS: 0.1639 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0126/0938 | LOSS: 0.1635 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0127/0938 | LOSS: 0.1635 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0128/0938 | LOSS: 0.1645 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0129/0938 | LOSS: 0.1640 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0130/0938 | LOSS: 0.1635 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0131/0938 | LOSS: 0.1637 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0132/0938 | LOSS: 0.1636 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0133/0938 | LOSS: 0.1635 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0134/0938 | LOSS: 0.1631 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0135/0938 | LOSS: 0.1633 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0136/0938 | LOSS: 0.1631 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0137/0938 | LOSS: 0.1638 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0138/0938 | LOSS: 0.1632 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0139/0938 | LOSS: 0.1629 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0140/0938 | LOSS: 0.1626 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0141/0938 | LOSS: 0.1625 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0142/0938 | LOSS: 0.1618 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0143/0938 | LOSS: 0.1612 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0144/0938 | LOSS: 0.1608 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0145/0938 | LOSS: 0.1607 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0146/0938 | LOSS: 0.1605 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0147/0938 | LOSS: 0.1608 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0148/0938 | LOSS: 0.1612 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0149/0938 | LOSS: 0.1608 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0150/0938 | LOSS: 0.1606 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0151/0938 | LOSS: 0.1600 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0152/0938 | LOSS: 0.1599 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0153/0938 | LOSS: 0.1597 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0154/0938 | LOSS: 0.1599 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0155/0938 | LOSS: 0.1601 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0156/0938 | LOSS: 0.1601 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0157/0938 | LOSS: 0.1598 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0158/0938 | LOSS: 0.1637 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0159/0938 | LOSS: 0.1635 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0160/0938 | LOSS: 0.1643 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0161/0938 | LOSS: 0.1646 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0162/0938 | LOSS: 0.1641 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0163/0938 | LOSS: 0.1636 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0164/0938 | LOSS: 0.1633 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0165/0938 | LOSS: 0.1631 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0166/0938 | LOSS: 0.1641 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0167/0938 | LOSS: 0.1635 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0168/0938 | LOSS: 0.1634 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0169/0938 | LOSS: 0.1644 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0170/0938 | LOSS: 0.1652 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0171/0938 | LOSS: 0.1646 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0172/0938 | LOSS: 0.1644 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0173/0938 | LOSS: 0.1639 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0174/0938 | LOSS: 0.1647 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0175/0938 | LOSS: 0.1642 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0176/0938 | LOSS: 0.1638 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0177/0938 | LOSS: 0.1652 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0178/0938 | LOSS: 0.1655 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0179/0938 | LOSS: 0.1656 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0180/0938 | LOSS: 0.1653 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0181/0938 | LOSS: 0.1649 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0182/0938 | LOSS: 0.1644 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0183/0938 | LOSS: 0.1637 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0184/0938 | LOSS: 0.1637 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0185/0938 | LOSS: 0.1633 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0186/0938 | LOSS: 0.1641 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0187/0938 | LOSS: 0.1639 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0188/0938 | LOSS: 0.1637 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0189/0938 | LOSS: 0.1645 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0190/0938 | LOSS: 0.1641 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0191/0938 | LOSS: 0.1639 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0192/0938 | LOSS: 0.1635 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0193/0938 | LOSS: 0.1634 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0194/0938 | LOSS: 0.1631 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0195/0938 | LOSS: 0.1636 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0196/0938 | LOSS: 0.1630 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0197/0938 | LOSS: 0.1629 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0198/0938 | LOSS: 0.1633 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0199/0938 | LOSS: 0.1635 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0200/0938 | LOSS: 0.1631 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0201/0938 | LOSS: 0.1627 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0202/0938 | LOSS: 0.1632 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0203/0938 | LOSS: 0.1629 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0204/0938 | LOSS: 0.1633 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0205/0938 | LOSS: 0.1640 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0206/0938 | LOSS: 0.1635 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0207/0938 | LOSS: 0.1630 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0208/0938 | LOSS: 0.1631 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0209/0938 | LOSS: 0.1641 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0210/0938 | LOSS: 0.1638 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0211/0938 | LOSS: 0.1638 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0212/0938 | LOSS: 0.1634 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0213/0938 | LOSS: 0.1630 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0214/0938 | LOSS: 0.1635 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0215/0938 | LOSS: 0.1631 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0216/0938 | LOSS: 0.1630 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0217/0938 | LOSS: 0.1638 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0218/0938 | LOSS: 0.1632 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0219/0938 | LOSS: 0.1628 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0220/0938 | LOSS: 0.1628 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0221/0938 | LOSS: 0.1629 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0222/0938 | LOSS: 0.1628 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0223/0938 | LOSS: 0.1632 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0224/0938 | LOSS: 0.1629 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0225/0938 | LOSS: 0.1630 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0226/0938 | LOSS: 0.1627 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0227/0938 | LOSS: 0.1631 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0228/0938 | LOSS: 0.1625 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0229/0938 | LOSS: 0.1624 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0230/0938 | LOSS: 0.1629 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0231/0938 | LOSS: 0.1632 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0232/0938 | LOSS: 0.1636 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0233/0938 | LOSS: 0.1631 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0234/0938 | LOSS: 0.1634 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0235/0938 | LOSS: 0.1631 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0236/0938 | LOSS: 0.1630 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0237/0938 | LOSS: 0.1627 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0238/0938 | LOSS: 0.1626 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0239/0938 | LOSS: 0.1626 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0240/0938 | LOSS: 0.1625 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0241/0938 | LOSS: 0.1624 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0242/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0243/0938 | LOSS: 0.1626 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0244/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0245/0938 | LOSS: 0.1621 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0246/0938 | LOSS: 0.1621 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0247/0938 | LOSS: 0.1626 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0248/0938 | LOSS: 0.1625 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0249/0938 | LOSS: 0.1621 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0250/0938 | LOSS: 0.1623 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0251/0938 | LOSS: 0.1624 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0252/0938 | LOSS: 0.1619 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0253/0938 | LOSS: 0.1616 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0254/0938 | LOSS: 0.1613 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0255/0938 | LOSS: 0.1611 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0256/0938 | LOSS: 0.1608 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0257/0938 | LOSS: 0.1606 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0258/0938 | LOSS: 0.1605 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0259/0938 | LOSS: 0.1602 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0260/0938 | LOSS: 0.1601 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0261/0938 | LOSS: 0.1605 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0262/0938 | LOSS: 0.1602 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0263/0938 | LOSS: 0.1600 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0264/0938 | LOSS: 0.1598 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0265/0938 | LOSS: 0.1595 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0266/0938 | LOSS: 0.1594 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0267/0938 | LOSS: 0.1591 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0268/0938 | LOSS: 0.1595 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0269/0938 | LOSS: 0.1597 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0270/0938 | LOSS: 0.1600 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0271/0938 | LOSS: 0.1599 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0272/0938 | LOSS: 0.1598 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0273/0938 | LOSS: 0.1603 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0274/0938 | LOSS: 0.1602 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0275/0938 | LOSS: 0.1606 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0276/0938 | LOSS: 0.1606 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0277/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0278/0938 | LOSS: 0.1604 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0279/0938 | LOSS: 0.1602 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0280/0938 | LOSS: 0.1600 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0281/0938 | LOSS: 0.1602 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0282/0938 | LOSS: 0.1602 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0283/0938 | LOSS: 0.1601 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0284/0938 | LOSS: 0.1606 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0285/0938 | LOSS: 0.1604 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0286/0938 | LOSS: 0.1601 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0287/0938 | LOSS: 0.1605 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0288/0938 | LOSS: 0.1607 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0289/0938 | LOSS: 0.1604 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0290/0938 | LOSS: 0.1605 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0291/0938 | LOSS: 0.1603 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0292/0938 | LOSS: 0.1602 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0293/0938 | LOSS: 0.1601 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0294/0938 | LOSS: 0.1597 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0295/0938 | LOSS: 0.1600 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0296/0938 | LOSS: 0.1596 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0297/0938 | LOSS: 0.1594 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0298/0938 | LOSS: 0.1595 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0299/0938 | LOSS: 0.1599 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0300/0938 | LOSS: 0.1598 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0301/0938 | LOSS: 0.1598 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0302/0938 | LOSS: 0.1597 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0303/0938 | LOSS: 0.1602 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0304/0938 | LOSS: 0.1599 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0305/0938 | LOSS: 0.1602 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0306/0938 | LOSS: 0.1611 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0307/0938 | LOSS: 0.1612 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0308/0938 | LOSS: 0.1612 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0309/0938 | LOSS: 0.1614 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0310/0938 | LOSS: 0.1612 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0311/0938 | LOSS: 0.1616 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0312/0938 | LOSS: 0.1613 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0313/0938 | LOSS: 0.1612 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0314/0938 | LOSS: 0.1613 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0315/0938 | LOSS: 0.1615 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0316/0938 | LOSS: 0.1612 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0317/0938 | LOSS: 0.1616 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0318/0938 | LOSS: 0.1614 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0319/0938 | LOSS: 0.1612 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0320/0938 | LOSS: 0.1611 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0321/0938 | LOSS: 0.1610 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0322/0938 | LOSS: 0.1611 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0323/0938 | LOSS: 0.1608 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0324/0938 | LOSS: 0.1608 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0325/0938 | LOSS: 0.1608 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0326/0938 | LOSS: 0.1611 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0327/0938 | LOSS: 0.1612 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0328/0938 | LOSS: 0.1610 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0329/0938 | LOSS: 0.1615 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0330/0938 | LOSS: 0.1613 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0331/0938 | LOSS: 0.1612 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0332/0938 | LOSS: 0.1616 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0333/0938 | LOSS: 0.1613 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0334/0938 | LOSS: 0.1615 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0335/0938 | LOSS: 0.1615 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0336/0938 | LOSS: 0.1614 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0337/0938 | LOSS: 0.1614 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0338/0938 | LOSS: 0.1614 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0339/0938 | LOSS: 0.1613 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0340/0938 | LOSS: 0.1617 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0341/0938 | LOSS: 0.1620 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0342/0938 | LOSS: 0.1618 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0343/0938 | LOSS: 0.1620 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0344/0938 | LOSS: 0.1622 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0345/0938 | LOSS: 0.1623 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0346/0938 | LOSS: 0.1630 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0347/0938 | LOSS: 0.1632 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0348/0938 | LOSS: 0.1637 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0349/0938 | LOSS: 0.1643 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0350/0938 | LOSS: 0.1642 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0351/0938 | LOSS: 0.1642 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0352/0938 | LOSS: 0.1643 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0353/0938 | LOSS: 0.1643 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0354/0938 | LOSS: 0.1641 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0355/0938 | LOSS: 0.1648 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0356/0938 | LOSS: 0.1647 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0357/0938 | LOSS: 0.1646 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0358/0938 | LOSS: 0.1643 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0359/0938 | LOSS: 0.1644 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0360/0938 | LOSS: 0.1643 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0361/0938 | LOSS: 0.1646 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0362/0938 | LOSS: 0.1649 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0363/0938 | LOSS: 0.1648 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0364/0938 | LOSS: 0.1646 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0365/0938 | LOSS: 0.1647 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0366/0938 | LOSS: 0.1646 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0367/0938 | LOSS: 0.1647 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0368/0938 | LOSS: 0.1647 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0369/0938 | LOSS: 0.1649 | ACC 0.9513\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0370/0938 | LOSS: 0.1651 | ACC 0.9513\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0371/0938 | LOSS: 0.1651 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0372/0938 | LOSS: 0.1652 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0373/0938 | LOSS: 0.1654 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0374/0938 | LOSS: 0.1655 | ACC 0.9510\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0375/0938 | LOSS: 0.1659 | ACC 0.9508\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0376/0938 | LOSS: 0.1657 | ACC 0.9509\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0377/0938 | LOSS: 0.1654 | ACC 0.9510\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0378/0938 | LOSS: 0.1654 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0379/0938 | LOSS: 0.1652 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0380/0938 | LOSS: 0.1652 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0381/0938 | LOSS: 0.1650 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0382/0938 | LOSS: 0.1650 | ACC 0.9510\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0383/0938 | LOSS: 0.1648 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0384/0938 | LOSS: 0.1649 | ACC 0.9511\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0385/0938 | LOSS: 0.1648 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0386/0938 | LOSS: 0.1646 | ACC 0.9512\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0387/0938 | LOSS: 0.1650 | ACC 0.9513\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0388/0938 | LOSS: 0.1648 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0389/0938 | LOSS: 0.1647 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0390/0938 | LOSS: 0.1646 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0391/0938 | LOSS: 0.1645 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0392/0938 | LOSS: 0.1642 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0393/0938 | LOSS: 0.1640 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0394/0938 | LOSS: 0.1641 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0395/0938 | LOSS: 0.1643 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0396/0938 | LOSS: 0.1641 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0397/0938 | LOSS: 0.1642 | ACC 0.9513\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0398/0938 | LOSS: 0.1640 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0399/0938 | LOSS: 0.1639 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0400/0938 | LOSS: 0.1640 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0401/0938 | LOSS: 0.1640 | ACC 0.9514\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0402/0938 | LOSS: 0.1639 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0403/0938 | LOSS: 0.1641 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0404/0938 | LOSS: 0.1642 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0405/0938 | LOSS: 0.1640 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0406/0938 | LOSS: 0.1640 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0407/0938 | LOSS: 0.1640 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0408/0938 | LOSS: 0.1642 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0409/0938 | LOSS: 0.1643 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0410/0938 | LOSS: 0.1643 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0411/0938 | LOSS: 0.1641 | ACC 0.9515\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0412/0938 | LOSS: 0.1640 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0413/0938 | LOSS: 0.1637 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0414/0938 | LOSS: 0.1635 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0415/0938 | LOSS: 0.1639 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0416/0938 | LOSS: 0.1636 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0417/0938 | LOSS: 0.1644 | ACC 0.9516\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0418/0938 | LOSS: 0.1643 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0419/0938 | LOSS: 0.1640 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0420/0938 | LOSS: 0.1639 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0421/0938 | LOSS: 0.1636 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0422/0938 | LOSS: 0.1637 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0423/0938 | LOSS: 0.1639 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0424/0938 | LOSS: 0.1636 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0425/0938 | LOSS: 0.1639 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0426/0938 | LOSS: 0.1638 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0427/0938 | LOSS: 0.1636 | ACC 0.9517\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0428/0938 | LOSS: 0.1633 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0429/0938 | LOSS: 0.1630 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0430/0938 | LOSS: 0.1630 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0431/0938 | LOSS: 0.1629 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0432/0938 | LOSS: 0.1630 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0433/0938 | LOSS: 0.1630 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0434/0938 | LOSS: 0.1629 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0435/0938 | LOSS: 0.1629 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0436/0938 | LOSS: 0.1632 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0437/0938 | LOSS: 0.1631 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0438/0938 | LOSS: 0.1632 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0439/0938 | LOSS: 0.1632 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0440/0938 | LOSS: 0.1631 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0441/0938 | LOSS: 0.1632 | ACC 0.9518\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0442/0938 | LOSS: 0.1629 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0443/0938 | LOSS: 0.1627 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0444/0938 | LOSS: 0.1627 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0445/0938 | LOSS: 0.1626 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0446/0938 | LOSS: 0.1625 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0447/0938 | LOSS: 0.1625 | ACC 0.9519\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0448/0938 | LOSS: 0.1623 | ACC 0.9520\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0449/0938 | LOSS: 0.1622 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0450/0938 | LOSS: 0.1620 | ACC 0.9521\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0451/0938 | LOSS: 0.1618 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0452/0938 | LOSS: 0.1616 | ACC 0.9522\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0453/0938 | LOSS: 0.1615 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0454/0938 | LOSS: 0.1612 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0455/0938 | LOSS: 0.1611 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0456/0938 | LOSS: 0.1615 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0457/0938 | LOSS: 0.1613 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0458/0938 | LOSS: 0.1611 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0459/0938 | LOSS: 0.1614 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0460/0938 | LOSS: 0.1611 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0461/0938 | LOSS: 0.1610 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0462/0938 | LOSS: 0.1610 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0463/0938 | LOSS: 0.1611 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0464/0938 | LOSS: 0.1612 | ACC 0.9523\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0465/0938 | LOSS: 0.1609 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0466/0938 | LOSS: 0.1607 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0467/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0468/0938 | LOSS: 0.1607 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0469/0938 | LOSS: 0.1606 | ACC 0.9524\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0470/0938 | LOSS: 0.1605 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0471/0938 | LOSS: 0.1603 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0472/0938 | LOSS: 0.1600 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0473/0938 | LOSS: 0.1599 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0474/0938 | LOSS: 0.1599 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0475/0938 | LOSS: 0.1596 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0476/0938 | LOSS: 0.1596 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0477/0938 | LOSS: 0.1600 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0478/0938 | LOSS: 0.1599 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0479/0938 | LOSS: 0.1600 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0480/0938 | LOSS: 0.1600 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0481/0938 | LOSS: 0.1598 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0482/0938 | LOSS: 0.1596 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0483/0938 | LOSS: 0.1596 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0484/0938 | LOSS: 0.1596 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0485/0938 | LOSS: 0.1595 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0486/0938 | LOSS: 0.1596 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0487/0938 | LOSS: 0.1593 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0488/0938 | LOSS: 0.1593 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0489/0938 | LOSS: 0.1592 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0490/0938 | LOSS: 0.1592 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0491/0938 | LOSS: 0.1590 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0492/0938 | LOSS: 0.1589 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0493/0938 | LOSS: 0.1588 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0494/0938 | LOSS: 0.1588 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0495/0938 | LOSS: 0.1590 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0496/0938 | LOSS: 0.1593 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0497/0938 | LOSS: 0.1591 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0498/0938 | LOSS: 0.1592 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0499/0938 | LOSS: 0.1592 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0500/0938 | LOSS: 0.1594 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0501/0938 | LOSS: 0.1591 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0502/0938 | LOSS: 0.1591 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0503/0938 | LOSS: 0.1590 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0504/0938 | LOSS: 0.1590 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0505/0938 | LOSS: 0.1589 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0506/0938 | LOSS: 0.1590 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0507/0938 | LOSS: 0.1592 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0508/0938 | LOSS: 0.1591 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0509/0938 | LOSS: 0.1591 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0510/0938 | LOSS: 0.1590 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0511/0938 | LOSS: 0.1589 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0512/0938 | LOSS: 0.1590 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0513/0938 | LOSS: 0.1591 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0514/0938 | LOSS: 0.1592 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0515/0938 | LOSS: 0.1591 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0516/0938 | LOSS: 0.1593 | ACC 0.9525\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0517/0938 | LOSS: 0.1592 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0518/0938 | LOSS: 0.1590 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0519/0938 | LOSS: 0.1588 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0520/0938 | LOSS: 0.1588 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0521/0938 | LOSS: 0.1590 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0522/0938 | LOSS: 0.1588 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0523/0938 | LOSS: 0.1587 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0524/0938 | LOSS: 0.1585 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0525/0938 | LOSS: 0.1584 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0526/0938 | LOSS: 0.1585 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0527/0938 | LOSS: 0.1583 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0528/0938 | LOSS: 0.1583 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0529/0938 | LOSS: 0.1581 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0530/0938 | LOSS: 0.1581 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0531/0938 | LOSS: 0.1580 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0532/0938 | LOSS: 0.1578 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0533/0938 | LOSS: 0.1578 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0534/0938 | LOSS: 0.1576 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0535/0938 | LOSS: 0.1574 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0536/0938 | LOSS: 0.1574 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0537/0938 | LOSS: 0.1575 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0538/0938 | LOSS: 0.1573 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0539/0938 | LOSS: 0.1574 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0540/0938 | LOSS: 0.1574 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0541/0938 | LOSS: 0.1571 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0542/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0543/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0544/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0545/0938 | LOSS: 0.1571 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0546/0938 | LOSS: 0.1569 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0547/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0548/0938 | LOSS: 0.1572 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0549/0938 | LOSS: 0.1573 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0550/0938 | LOSS: 0.1573 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0551/0938 | LOSS: 0.1573 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0552/0938 | LOSS: 0.1573 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0553/0938 | LOSS: 0.1572 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0554/0938 | LOSS: 0.1573 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0555/0938 | LOSS: 0.1572 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0556/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0557/0938 | LOSS: 0.1568 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0558/0938 | LOSS: 0.1570 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0559/0938 | LOSS: 0.1572 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0560/0938 | LOSS: 0.1572 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0561/0938 | LOSS: 0.1570 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0562/0938 | LOSS: 0.1569 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0563/0938 | LOSS: 0.1568 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0564/0938 | LOSS: 0.1569 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0565/0938 | LOSS: 0.1569 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0566/0938 | LOSS: 0.1571 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0567/0938 | LOSS: 0.1571 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0568/0938 | LOSS: 0.1570 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0569/0938 | LOSS: 0.1567 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0570/0938 | LOSS: 0.1565 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0571/0938 | LOSS: 0.1568 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0572/0938 | LOSS: 0.1568 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0573/0938 | LOSS: 0.1570 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0574/0938 | LOSS: 0.1568 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0575/0938 | LOSS: 0.1567 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0576/0938 | LOSS: 0.1567 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0577/0938 | LOSS: 0.1568 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0578/0938 | LOSS: 0.1568 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0579/0938 | LOSS: 0.1567 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0580/0938 | LOSS: 0.1566 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0581/0938 | LOSS: 0.1565 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0582/0938 | LOSS: 0.1566 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0583/0938 | LOSS: 0.1565 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0584/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0585/0938 | LOSS: 0.1566 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0586/0938 | LOSS: 0.1565 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0587/0938 | LOSS: 0.1565 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0588/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0589/0938 | LOSS: 0.1563 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0590/0938 | LOSS: 0.1563 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0591/0938 | LOSS: 0.1565 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0592/0938 | LOSS: 0.1563 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0593/0938 | LOSS: 0.1567 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0594/0938 | LOSS: 0.1566 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0595/0938 | LOSS: 0.1566 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0596/0938 | LOSS: 0.1566 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0597/0938 | LOSS: 0.1567 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0598/0938 | LOSS: 0.1568 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0599/0938 | LOSS: 0.1567 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0600/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0601/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0602/0938 | LOSS: 0.1572 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0603/0938 | LOSS: 0.1573 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0604/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0605/0938 | LOSS: 0.1574 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0606/0938 | LOSS: 0.1574 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0607/0938 | LOSS: 0.1572 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0608/0938 | LOSS: 0.1572 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0609/0938 | LOSS: 0.1574 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0610/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0611/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0612/0938 | LOSS: 0.1579 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0613/0938 | LOSS: 0.1578 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0614/0938 | LOSS: 0.1581 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0615/0938 | LOSS: 0.1579 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0616/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0617/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0618/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0619/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0620/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0621/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0622/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0623/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0624/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0625/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0626/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0627/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0628/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0629/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0630/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0631/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0632/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0633/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0634/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0635/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0636/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0637/0938 | LOSS: 0.1578 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0638/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0639/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0640/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0641/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0642/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0643/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0644/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0645/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0646/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0647/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0648/0938 | LOSS: 0.1578 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0649/0938 | LOSS: 0.1578 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0650/0938 | LOSS: 0.1578 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0651/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0652/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0653/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0654/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0655/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0656/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0657/0938 | LOSS: 0.1577 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0658/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0659/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0660/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0661/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0662/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0663/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0664/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0665/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0666/0938 | LOSS: 0.1575 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0667/0938 | LOSS: 0.1575 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0668/0938 | LOSS: 0.1575 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0669/0938 | LOSS: 0.1579 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0670/0938 | LOSS: 0.1579 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0671/0938 | LOSS: 0.1577 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0672/0938 | LOSS: 0.1577 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0673/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0674/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0675/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0676/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0677/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0678/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0679/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0680/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0681/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0682/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0683/0938 | LOSS: 0.1574 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0684/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0685/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0686/0938 | LOSS: 0.1576 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0687/0938 | LOSS: 0.1577 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0688/0938 | LOSS: 0.1576 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0689/0938 | LOSS: 0.1576 | ACC 0.9526\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0690/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0691/0938 | LOSS: 0.1576 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0692/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0693/0938 | LOSS: 0.1573 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0694/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0695/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0696/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0697/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0698/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0699/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0700/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0701/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0702/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0703/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0704/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0705/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0706/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0707/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0708/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0709/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0710/0938 | LOSS: 0.1575 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0711/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0712/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0713/0938 | LOSS: 0.1573 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0714/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0715/0938 | LOSS: 0.1572 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0716/0938 | LOSS: 0.1572 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0717/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0718/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0719/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0720/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0721/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0722/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0723/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0724/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0725/0938 | LOSS: 0.1570 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0726/0938 | LOSS: 0.1570 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0727/0938 | LOSS: 0.1569 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0728/0938 | LOSS: 0.1567 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0729/0938 | LOSS: 0.1568 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0730/0938 | LOSS: 0.1568 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0731/0938 | LOSS: 0.1567 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0732/0938 | LOSS: 0.1568 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0733/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0734/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0735/0938 | LOSS: 0.1570 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0736/0938 | LOSS: 0.1572 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0737/0938 | LOSS: 0.1572 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0738/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0739/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0740/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0741/0938 | LOSS: 0.1571 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0742/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0743/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0744/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0745/0938 | LOSS: 0.1572 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0746/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0747/0938 | LOSS: 0.1573 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0748/0938 | LOSS: 0.1571 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0749/0938 | LOSS: 0.1573 | ACC 0.9527\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0750/0938 | LOSS: 0.1573 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0751/0938 | LOSS: 0.1572 | ACC 0.9528\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0752/0938 | LOSS: 0.1571 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0753/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0754/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0755/0938 | LOSS: 0.1570 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0756/0938 | LOSS: 0.1569 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0757/0938 | LOSS: 0.1568 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0758/0938 | LOSS: 0.1568 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0759/0938 | LOSS: 0.1568 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0760/0938 | LOSS: 0.1568 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0761/0938 | LOSS: 0.1567 | ACC 0.9529\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0762/0938 | LOSS: 0.1565 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0763/0938 | LOSS: 0.1565 | ACC 0.9530\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0764/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0765/0938 | LOSS: 0.1563 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0766/0938 | LOSS: 0.1562 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0767/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0768/0938 | LOSS: 0.1561 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0769/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0770/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0771/0938 | LOSS: 0.1561 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0772/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0773/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0774/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0775/0938 | LOSS: 0.1563 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0776/0938 | LOSS: 0.1563 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0777/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0778/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0779/0938 | LOSS: 0.1560 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0780/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0781/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0782/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0783/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0784/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0785/0938 | LOSS: 0.1559 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0786/0938 | LOSS: 0.1559 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0787/0938 | LOSS: 0.1560 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0788/0938 | LOSS: 0.1559 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0789/0938 | LOSS: 0.1560 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0790/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0791/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0792/0938 | LOSS: 0.1562 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0793/0938 | LOSS: 0.1564 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0794/0938 | LOSS: 0.1565 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0795/0938 | LOSS: 0.1565 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0796/0938 | LOSS: 0.1565 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0797/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0798/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0799/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0800/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0801/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0802/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0803/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0804/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0805/0938 | LOSS: 0.1560 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0806/0938 | LOSS: 0.1559 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0807/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0808/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0809/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0810/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0811/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0812/0938 | LOSS: 0.1563 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0813/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0814/0938 | LOSS: 0.1562 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0815/0938 | LOSS: 0.1561 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0816/0938 | LOSS: 0.1561 | ACC 0.9531\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0817/0938 | LOSS: 0.1560 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0818/0938 | LOSS: 0.1559 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0819/0938 | LOSS: 0.1559 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0820/0938 | LOSS: 0.1557 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0821/0938 | LOSS: 0.1557 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0822/0938 | LOSS: 0.1556 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0823/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0824/0938 | LOSS: 0.1557 | ACC 0.9532\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0825/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0826/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0827/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0828/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0829/0938 | LOSS: 0.1556 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0830/0938 | LOSS: 0.1554 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0831/0938 | LOSS: 0.1553 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0832/0938 | LOSS: 0.1553 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0833/0938 | LOSS: 0.1553 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0834/0938 | LOSS: 0.1554 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0835/0938 | LOSS: 0.1555 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0836/0938 | LOSS: 0.1554 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0837/0938 | LOSS: 0.1553 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0838/0938 | LOSS: 0.1553 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0839/0938 | LOSS: 0.1552 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0840/0938 | LOSS: 0.1553 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0841/0938 | LOSS: 0.1552 | ACC 0.9533\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0842/0938 | LOSS: 0.1551 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0843/0938 | LOSS: 0.1551 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0844/0938 | LOSS: 0.1550 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0845/0938 | LOSS: 0.1549 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0846/0938 | LOSS: 0.1549 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0847/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0848/0938 | LOSS: 0.1548 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0849/0938 | LOSS: 0.1548 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0850/0938 | LOSS: 0.1548 | ACC 0.9534\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0851/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0852/0938 | LOSS: 0.1546 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0853/0938 | LOSS: 0.1548 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0854/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0855/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0856/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0857/0938 | LOSS: 0.1546 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0858/0938 | LOSS: 0.1547 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0859/0938 | LOSS: 0.1545 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0860/0938 | LOSS: 0.1545 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0861/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0862/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0863/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0864/0938 | LOSS: 0.1544 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0865/0938 | LOSS: 0.1542 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0866/0938 | LOSS: 0.1542 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0867/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0868/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0869/0938 | LOSS: 0.1542 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0870/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0871/0938 | LOSS: 0.1543 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0872/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0873/0938 | LOSS: 0.1542 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0874/0938 | LOSS: 0.1542 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0875/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0876/0938 | LOSS: 0.1543 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0877/0938 | LOSS: 0.1544 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0878/0938 | LOSS: 0.1543 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0879/0938 | LOSS: 0.1544 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0880/0938 | LOSS: 0.1544 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0881/0938 | LOSS: 0.1544 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0882/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0883/0938 | LOSS: 0.1546 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0884/0938 | LOSS: 0.1545 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0885/0938 | LOSS: 0.1546 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0886/0938 | LOSS: 0.1545 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0887/0938 | LOSS: 0.1545 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0888/0938 | LOSS: 0.1545 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0889/0938 | LOSS: 0.1544 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0890/0938 | LOSS: 0.1543 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0891/0938 | LOSS: 0.1544 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0892/0938 | LOSS: 0.1545 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0893/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0894/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0895/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0896/0938 | LOSS: 0.1550 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0897/0938 | LOSS: 0.1549 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0898/0938 | LOSS: 0.1548 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0899/0938 | LOSS: 0.1548 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0900/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0901/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0902/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0903/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0904/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0905/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0906/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0907/0938 | LOSS: 0.1546 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0908/0938 | LOSS: 0.1547 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0909/0938 | LOSS: 0.1548 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0910/0938 | LOSS: 0.1552 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0911/0938 | LOSS: 0.1552 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0912/0938 | LOSS: 0.1552 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0913/0938 | LOSS: 0.1551 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0914/0938 | LOSS: 0.1552 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0915/0938 | LOSS: 0.1553 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0916/0938 | LOSS: 0.1552 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0917/0938 | LOSS: 0.1553 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0918/0938 | LOSS: 0.1555 | ACC 0.9535\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0919/0938 | LOSS: 0.1555 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0920/0938 | LOSS: 0.1554 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0921/0938 | LOSS: 0.1553 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0922/0938 | LOSS: 0.1553 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0923/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0924/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0925/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0926/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0927/0938 | LOSS: 0.1552 | ACC 0.9536\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0928/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0929/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0930/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0931/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0932/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0933/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0934/0938 | LOSS: 0.1550 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0935/0938 | LOSS: 0.1550 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0936/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0937/0938 | LOSS: 0.1551 | ACC 0.9537\n",
            "TRAIN: EPOCH 0007/0010 | BATCH 0938/0938 | LOSS: 0.1552 | ACC 0.9537\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0001/0938 | LOSS: 0.1816 | ACC 0.9531\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0002/0938 | LOSS: 0.1582 | ACC 0.9531\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0003/0938 | LOSS: 0.1414 | ACC 0.9635\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0004/0938 | LOSS: 0.1431 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0005/0938 | LOSS: 0.1502 | ACC 0.9625\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0006/0938 | LOSS: 0.1452 | ACC 0.9635\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0007/0938 | LOSS: 0.1414 | ACC 0.9598\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0008/0938 | LOSS: 0.1455 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0009/0938 | LOSS: 0.1378 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0010/0938 | LOSS: 0.1410 | ACC 0.9547\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0011/0938 | LOSS: 0.1377 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0012/0938 | LOSS: 0.1303 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0013/0938 | LOSS: 0.1277 | ACC 0.9591\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0014/0938 | LOSS: 0.1292 | ACC 0.9598\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0015/0938 | LOSS: 0.1278 | ACC 0.9604\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0016/0938 | LOSS: 0.1292 | ACC 0.9590\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0017/0938 | LOSS: 0.1274 | ACC 0.9596\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0018/0938 | LOSS: 0.1272 | ACC 0.9592\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0019/0938 | LOSS: 0.1281 | ACC 0.9597\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0020/0938 | LOSS: 0.1274 | ACC 0.9586\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0021/0938 | LOSS: 0.1281 | ACC 0.9591\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0022/0938 | LOSS: 0.1280 | ACC 0.9588\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0023/0938 | LOSS: 0.1275 | ACC 0.9586\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0024/0938 | LOSS: 0.1254 | ACC 0.9590\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0025/0938 | LOSS: 0.1263 | ACC 0.9587\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0026/0938 | LOSS: 0.1259 | ACC 0.9591\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0027/0938 | LOSS: 0.1294 | ACC 0.9589\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0028/0938 | LOSS: 0.1270 | ACC 0.9598\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0029/0938 | LOSS: 0.1295 | ACC 0.9585\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0030/0938 | LOSS: 0.1291 | ACC 0.9589\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0031/0938 | LOSS: 0.1299 | ACC 0.9587\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0032/0938 | LOSS: 0.1283 | ACC 0.9595\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0033/0938 | LOSS: 0.1304 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0034/0938 | LOSS: 0.1296 | ACC 0.9586\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0035/0938 | LOSS: 0.1314 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0036/0938 | LOSS: 0.1314 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0037/0938 | LOSS: 0.1299 | ACC 0.9590\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0038/0938 | LOSS: 0.1328 | ACC 0.9589\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0039/0938 | LOSS: 0.1383 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0040/0938 | LOSS: 0.1431 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0041/0938 | LOSS: 0.1447 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0042/0938 | LOSS: 0.1470 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0043/0938 | LOSS: 0.1455 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0044/0938 | LOSS: 0.1483 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0045/0938 | LOSS: 0.1520 | ACC 0.9556\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0046/0938 | LOSS: 0.1514 | ACC 0.9552\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0047/0938 | LOSS: 0.1520 | ACC 0.9551\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0048/0938 | LOSS: 0.1506 | ACC 0.9557\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0049/0938 | LOSS: 0.1499 | ACC 0.9550\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0050/0938 | LOSS: 0.1496 | ACC 0.9550\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0051/0938 | LOSS: 0.1489 | ACC 0.9553\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0052/0938 | LOSS: 0.1487 | ACC 0.9555\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0053/0938 | LOSS: 0.1467 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0054/0938 | LOSS: 0.1456 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0055/0938 | LOSS: 0.1459 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0056/0938 | LOSS: 0.1449 | ACC 0.9559\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0057/0938 | LOSS: 0.1458 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0058/0938 | LOSS: 0.1464 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0059/0938 | LOSS: 0.1452 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0060/0938 | LOSS: 0.1458 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0061/0938 | LOSS: 0.1442 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0062/0938 | LOSS: 0.1434 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0063/0938 | LOSS: 0.1423 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0064/0938 | LOSS: 0.1432 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0065/0938 | LOSS: 0.1426 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0066/0938 | LOSS: 0.1431 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0067/0938 | LOSS: 0.1425 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0068/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0069/0938 | LOSS: 0.1445 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0070/0938 | LOSS: 0.1439 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0071/0938 | LOSS: 0.1436 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0072/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0073/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0074/0938 | LOSS: 0.1452 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0075/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0076/0938 | LOSS: 0.1450 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0077/0938 | LOSS: 0.1444 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0078/0938 | LOSS: 0.1433 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0079/0938 | LOSS: 0.1458 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0080/0938 | LOSS: 0.1450 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0081/0938 | LOSS: 0.1447 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0082/0938 | LOSS: 0.1452 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0083/0938 | LOSS: 0.1447 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0084/0938 | LOSS: 0.1447 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0085/0938 | LOSS: 0.1433 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0086/0938 | LOSS: 0.1420 | ACC 0.9586\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0087/0938 | LOSS: 0.1413 | ACC 0.9587\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0088/0938 | LOSS: 0.1408 | ACC 0.9588\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0089/0938 | LOSS: 0.1397 | ACC 0.9591\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0090/0938 | LOSS: 0.1393 | ACC 0.9589\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0091/0938 | LOSS: 0.1389 | ACC 0.9590\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0092/0938 | LOSS: 0.1383 | ACC 0.9591\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0093/0938 | LOSS: 0.1408 | ACC 0.9585\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0094/0938 | LOSS: 0.1410 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0095/0938 | LOSS: 0.1429 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0096/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0097/0938 | LOSS: 0.1426 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0098/0938 | LOSS: 0.1428 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0099/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0100/0938 | LOSS: 0.1426 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0101/0938 | LOSS: 0.1435 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0102/0938 | LOSS: 0.1445 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0103/0938 | LOSS: 0.1461 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0104/0938 | LOSS: 0.1469 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0105/0938 | LOSS: 0.1468 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0106/0938 | LOSS: 0.1468 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0107/0938 | LOSS: 0.1467 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0108/0938 | LOSS: 0.1466 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0109/0938 | LOSS: 0.1474 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0110/0938 | LOSS: 0.1470 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0111/0938 | LOSS: 0.1469 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0112/0938 | LOSS: 0.1469 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0113/0938 | LOSS: 0.1471 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0114/0938 | LOSS: 0.1484 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0115/0938 | LOSS: 0.1483 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0116/0938 | LOSS: 0.1483 | ACC 0.9558\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0117/0938 | LOSS: 0.1477 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0118/0938 | LOSS: 0.1475 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0119/0938 | LOSS: 0.1479 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0120/0938 | LOSS: 0.1478 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0121/0938 | LOSS: 0.1480 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0122/0938 | LOSS: 0.1472 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0123/0938 | LOSS: 0.1473 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0124/0938 | LOSS: 0.1465 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0125/0938 | LOSS: 0.1464 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0126/0938 | LOSS: 0.1463 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0127/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0128/0938 | LOSS: 0.1459 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0129/0938 | LOSS: 0.1455 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0130/0938 | LOSS: 0.1459 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0131/0938 | LOSS: 0.1468 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0132/0938 | LOSS: 0.1468 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0133/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0134/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0135/0938 | LOSS: 0.1467 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0136/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0137/0938 | LOSS: 0.1459 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0138/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0139/0938 | LOSS: 0.1459 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0140/0938 | LOSS: 0.1452 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0141/0938 | LOSS: 0.1460 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0142/0938 | LOSS: 0.1456 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0143/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0144/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0145/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0146/0938 | LOSS: 0.1462 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0147/0938 | LOSS: 0.1457 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0148/0938 | LOSS: 0.1462 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0149/0938 | LOSS: 0.1467 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0150/0938 | LOSS: 0.1463 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0151/0938 | LOSS: 0.1456 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0152/0938 | LOSS: 0.1473 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0153/0938 | LOSS: 0.1475 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0154/0938 | LOSS: 0.1472 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0155/0938 | LOSS: 0.1468 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0156/0938 | LOSS: 0.1466 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0157/0938 | LOSS: 0.1465 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0158/0938 | LOSS: 0.1459 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0159/0938 | LOSS: 0.1467 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0160/0938 | LOSS: 0.1466 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0161/0938 | LOSS: 0.1470 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0162/0938 | LOSS: 0.1469 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0163/0938 | LOSS: 0.1468 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0164/0938 | LOSS: 0.1463 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0165/0938 | LOSS: 0.1459 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0166/0938 | LOSS: 0.1455 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0167/0938 | LOSS: 0.1452 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0168/0938 | LOSS: 0.1456 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0169/0938 | LOSS: 0.1452 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0170/0938 | LOSS: 0.1447 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0171/0938 | LOSS: 0.1464 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0172/0938 | LOSS: 0.1466 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0173/0938 | LOSS: 0.1472 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0174/0938 | LOSS: 0.1474 | ACC 0.9559\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0175/0938 | LOSS: 0.1477 | ACC 0.9558\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0176/0938 | LOSS: 0.1484 | ACC 0.9556\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0177/0938 | LOSS: 0.1482 | ACC 0.9557\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0178/0938 | LOSS: 0.1478 | ACC 0.9558\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0179/0938 | LOSS: 0.1472 | ACC 0.9559\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0180/0938 | LOSS: 0.1466 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0181/0938 | LOSS: 0.1465 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0182/0938 | LOSS: 0.1462 | ACC 0.9560\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0183/0938 | LOSS: 0.1458 | ACC 0.9561\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0184/0938 | LOSS: 0.1457 | ACC 0.9562\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0185/0938 | LOSS: 0.1451 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0186/0938 | LOSS: 0.1447 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0187/0938 | LOSS: 0.1443 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0188/0938 | LOSS: 0.1439 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0189/0938 | LOSS: 0.1439 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0190/0938 | LOSS: 0.1439 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0191/0938 | LOSS: 0.1434 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0192/0938 | LOSS: 0.1431 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0193/0938 | LOSS: 0.1435 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0194/0938 | LOSS: 0.1429 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0195/0938 | LOSS: 0.1427 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0196/0938 | LOSS: 0.1424 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0197/0938 | LOSS: 0.1425 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0198/0938 | LOSS: 0.1421 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0199/0938 | LOSS: 0.1422 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0200/0938 | LOSS: 0.1421 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0201/0938 | LOSS: 0.1429 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0202/0938 | LOSS: 0.1433 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0203/0938 | LOSS: 0.1430 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0204/0938 | LOSS: 0.1433 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0205/0938 | LOSS: 0.1440 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0206/0938 | LOSS: 0.1435 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0207/0938 | LOSS: 0.1435 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0208/0938 | LOSS: 0.1457 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0209/0938 | LOSS: 0.1457 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0210/0938 | LOSS: 0.1459 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0211/0938 | LOSS: 0.1457 | ACC 0.9563\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0212/0938 | LOSS: 0.1453 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0213/0938 | LOSS: 0.1453 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0214/0938 | LOSS: 0.1450 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0215/0938 | LOSS: 0.1453 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0216/0938 | LOSS: 0.1448 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0217/0938 | LOSS: 0.1445 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0218/0938 | LOSS: 0.1445 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0219/0938 | LOSS: 0.1444 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0220/0938 | LOSS: 0.1441 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0221/0938 | LOSS: 0.1440 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0222/0938 | LOSS: 0.1438 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0223/0938 | LOSS: 0.1434 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0224/0938 | LOSS: 0.1436 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0225/0938 | LOSS: 0.1435 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0226/0938 | LOSS: 0.1431 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0227/0938 | LOSS: 0.1430 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0228/0938 | LOSS: 0.1431 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0229/0938 | LOSS: 0.1428 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0230/0938 | LOSS: 0.1426 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0231/0938 | LOSS: 0.1425 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0232/0938 | LOSS: 0.1423 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0233/0938 | LOSS: 0.1423 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0234/0938 | LOSS: 0.1422 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0235/0938 | LOSS: 0.1421 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0236/0938 | LOSS: 0.1417 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0237/0938 | LOSS: 0.1415 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0238/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0239/0938 | LOSS: 0.1425 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0240/0938 | LOSS: 0.1434 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0241/0938 | LOSS: 0.1431 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0242/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0243/0938 | LOSS: 0.1427 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0244/0938 | LOSS: 0.1431 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0245/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0246/0938 | LOSS: 0.1429 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0247/0938 | LOSS: 0.1430 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0248/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0249/0938 | LOSS: 0.1432 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0250/0938 | LOSS: 0.1432 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0251/0938 | LOSS: 0.1432 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0252/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0253/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0254/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0255/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0256/0938 | LOSS: 0.1432 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0257/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0258/0938 | LOSS: 0.1426 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0259/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0260/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0261/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0262/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0263/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0264/0938 | LOSS: 0.1427 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0265/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0266/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0267/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0268/0938 | LOSS: 0.1428 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0269/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0270/0938 | LOSS: 0.1428 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0271/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0272/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0273/0938 | LOSS: 0.1426 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0274/0938 | LOSS: 0.1426 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0275/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0276/0938 | LOSS: 0.1430 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0277/0938 | LOSS: 0.1428 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0278/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0279/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0280/0938 | LOSS: 0.1431 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0281/0938 | LOSS: 0.1428 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0282/0938 | LOSS: 0.1430 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0283/0938 | LOSS: 0.1428 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0284/0938 | LOSS: 0.1431 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0285/0938 | LOSS: 0.1431 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0286/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0287/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0288/0938 | LOSS: 0.1427 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0289/0938 | LOSS: 0.1428 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0290/0938 | LOSS: 0.1427 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0291/0938 | LOSS: 0.1427 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0292/0938 | LOSS: 0.1426 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0293/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0294/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0295/0938 | LOSS: 0.1422 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0296/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0297/0938 | LOSS: 0.1423 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0298/0938 | LOSS: 0.1421 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0299/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0300/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0301/0938 | LOSS: 0.1414 | ACC 0.9584\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0302/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0303/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0304/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0305/0938 | LOSS: 0.1413 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0306/0938 | LOSS: 0.1411 | ACC 0.9582\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0307/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0308/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0309/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0310/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0311/0938 | LOSS: 0.1426 | ACC 0.9577\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0312/0938 | LOSS: 0.1428 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0313/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0314/0938 | LOSS: 0.1425 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0315/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0316/0938 | LOSS: 0.1427 | ACC 0.9578\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0317/0938 | LOSS: 0.1434 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0318/0938 | LOSS: 0.1434 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0319/0938 | LOSS: 0.1432 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0320/0938 | LOSS: 0.1431 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0321/0938 | LOSS: 0.1430 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0322/0938 | LOSS: 0.1434 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0323/0938 | LOSS: 0.1438 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0324/0938 | LOSS: 0.1438 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0325/0938 | LOSS: 0.1438 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0326/0938 | LOSS: 0.1437 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0327/0938 | LOSS: 0.1438 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0328/0938 | LOSS: 0.1436 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0329/0938 | LOSS: 0.1435 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0330/0938 | LOSS: 0.1436 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0331/0938 | LOSS: 0.1436 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0332/0938 | LOSS: 0.1441 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0333/0938 | LOSS: 0.1444 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0334/0938 | LOSS: 0.1444 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0335/0938 | LOSS: 0.1440 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0336/0938 | LOSS: 0.1444 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0337/0938 | LOSS: 0.1445 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0338/0938 | LOSS: 0.1444 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0339/0938 | LOSS: 0.1443 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0340/0938 | LOSS: 0.1441 | ACC 0.9576\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0341/0938 | LOSS: 0.1442 | ACC 0.9575\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0342/0938 | LOSS: 0.1448 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0343/0938 | LOSS: 0.1451 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0344/0938 | LOSS: 0.1452 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0345/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0346/0938 | LOSS: 0.1454 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0347/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0348/0938 | LOSS: 0.1455 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0349/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0350/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0351/0938 | LOSS: 0.1453 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0352/0938 | LOSS: 0.1457 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0353/0938 | LOSS: 0.1457 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0354/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0355/0938 | LOSS: 0.1457 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0356/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0357/0938 | LOSS: 0.1454 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0358/0938 | LOSS: 0.1456 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0359/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0360/0938 | LOSS: 0.1452 | ACC 0.9574\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0361/0938 | LOSS: 0.1453 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0362/0938 | LOSS: 0.1453 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0363/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0364/0938 | LOSS: 0.1459 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0365/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0366/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0367/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0368/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0369/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0370/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0371/0938 | LOSS: 0.1462 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0372/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0373/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0374/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0375/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0376/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0377/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0378/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0379/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0380/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0381/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0382/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0383/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0384/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0385/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0386/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0387/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0388/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0389/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0390/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0391/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0392/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0393/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0394/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0395/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0396/0938 | LOSS: 0.1465 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0397/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0398/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0399/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0400/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0401/0938 | LOSS: 0.1460 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0402/0938 | LOSS: 0.1458 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0403/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0404/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0405/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0406/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0407/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0408/0938 | LOSS: 0.1454 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0409/0938 | LOSS: 0.1458 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0410/0938 | LOSS: 0.1460 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0411/0938 | LOSS: 0.1459 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0412/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0413/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0414/0938 | LOSS: 0.1458 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0415/0938 | LOSS: 0.1457 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0416/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0417/0938 | LOSS: 0.1461 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0418/0938 | LOSS: 0.1459 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0419/0938 | LOSS: 0.1459 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0420/0938 | LOSS: 0.1458 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0421/0938 | LOSS: 0.1456 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0422/0938 | LOSS: 0.1457 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0423/0938 | LOSS: 0.1462 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0424/0938 | LOSS: 0.1461 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0425/0938 | LOSS: 0.1459 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0426/0938 | LOSS: 0.1460 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0427/0938 | LOSS: 0.1459 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0428/0938 | LOSS: 0.1459 | ACC 0.9573\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0429/0938 | LOSS: 0.1461 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0430/0938 | LOSS: 0.1462 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0431/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0432/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0433/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0434/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0435/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0436/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0437/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0438/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0439/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0440/0938 | LOSS: 0.1467 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0441/0938 | LOSS: 0.1472 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0442/0938 | LOSS: 0.1472 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0443/0938 | LOSS: 0.1471 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0444/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0445/0938 | LOSS: 0.1471 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0446/0938 | LOSS: 0.1469 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0447/0938 | LOSS: 0.1470 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0448/0938 | LOSS: 0.1469 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0449/0938 | LOSS: 0.1466 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0450/0938 | LOSS: 0.1468 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0451/0938 | LOSS: 0.1472 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0452/0938 | LOSS: 0.1471 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0453/0938 | LOSS: 0.1470 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0454/0938 | LOSS: 0.1472 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0455/0938 | LOSS: 0.1471 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0456/0938 | LOSS: 0.1470 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0457/0938 | LOSS: 0.1468 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0458/0938 | LOSS: 0.1468 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0459/0938 | LOSS: 0.1468 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0460/0938 | LOSS: 0.1468 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0461/0938 | LOSS: 0.1473 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0462/0938 | LOSS: 0.1471 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0463/0938 | LOSS: 0.1471 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0464/0938 | LOSS: 0.1470 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0465/0938 | LOSS: 0.1470 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0466/0938 | LOSS: 0.1473 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0467/0938 | LOSS: 0.1472 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0468/0938 | LOSS: 0.1471 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0469/0938 | LOSS: 0.1472 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0470/0938 | LOSS: 0.1471 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0471/0938 | LOSS: 0.1469 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0472/0938 | LOSS: 0.1468 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0473/0938 | LOSS: 0.1466 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0474/0938 | LOSS: 0.1465 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0475/0938 | LOSS: 0.1464 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0476/0938 | LOSS: 0.1462 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0477/0938 | LOSS: 0.1462 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0478/0938 | LOSS: 0.1461 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0479/0938 | LOSS: 0.1462 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0480/0938 | LOSS: 0.1462 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0481/0938 | LOSS: 0.1465 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0482/0938 | LOSS: 0.1467 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0483/0938 | LOSS: 0.1469 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0484/0938 | LOSS: 0.1475 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0485/0938 | LOSS: 0.1474 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0486/0938 | LOSS: 0.1476 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0487/0938 | LOSS: 0.1475 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0488/0938 | LOSS: 0.1474 | ACC 0.9564\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0489/0938 | LOSS: 0.1472 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0490/0938 | LOSS: 0.1473 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0491/0938 | LOSS: 0.1473 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0492/0938 | LOSS: 0.1475 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0493/0938 | LOSS: 0.1474 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0494/0938 | LOSS: 0.1475 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0495/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0496/0938 | LOSS: 0.1471 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0497/0938 | LOSS: 0.1474 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0498/0938 | LOSS: 0.1471 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0499/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0500/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0501/0938 | LOSS: 0.1471 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0502/0938 | LOSS: 0.1470 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0503/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0504/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0505/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0506/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0507/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0508/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0509/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0510/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0511/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0512/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0513/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0514/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0515/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0516/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0517/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0518/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0519/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0520/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0521/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0522/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0523/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0524/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0525/0938 | LOSS: 0.1459 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0526/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0527/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0528/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0529/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0530/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0531/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0532/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0533/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0534/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0535/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0536/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0537/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0538/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0539/0938 | LOSS: 0.1460 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0540/0938 | LOSS: 0.1462 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0541/0938 | LOSS: 0.1463 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0542/0938 | LOSS: 0.1463 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0543/0938 | LOSS: 0.1463 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0544/0938 | LOSS: 0.1464 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0545/0938 | LOSS: 0.1462 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0546/0938 | LOSS: 0.1461 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0547/0938 | LOSS: 0.1460 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0548/0938 | LOSS: 0.1459 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0549/0938 | LOSS: 0.1459 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0550/0938 | LOSS: 0.1458 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0551/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0552/0938 | LOSS: 0.1465 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0553/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0554/0938 | LOSS: 0.1467 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0555/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0556/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0557/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0558/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0559/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0560/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0561/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0562/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0563/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0564/0938 | LOSS: 0.1465 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0565/0938 | LOSS: 0.1465 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0566/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0567/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0568/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0569/0938 | LOSS: 0.1466 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0570/0938 | LOSS: 0.1466 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0571/0938 | LOSS: 0.1467 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0572/0938 | LOSS: 0.1469 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0573/0938 | LOSS: 0.1471 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0574/0938 | LOSS: 0.1470 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0575/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0576/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0577/0938 | LOSS: 0.1472 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0578/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0579/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0580/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0581/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0582/0938 | LOSS: 0.1473 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0583/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0584/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0585/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0586/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0587/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0588/0938 | LOSS: 0.1470 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0589/0938 | LOSS: 0.1469 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0590/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0591/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0592/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0593/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0594/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0595/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0596/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0597/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0598/0938 | LOSS: 0.1474 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0599/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0600/0938 | LOSS: 0.1472 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0601/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0602/0938 | LOSS: 0.1475 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0603/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0604/0938 | LOSS: 0.1480 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0605/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0606/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0607/0938 | LOSS: 0.1479 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0608/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0609/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0610/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0611/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0612/0938 | LOSS: 0.1475 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0613/0938 | LOSS: 0.1474 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0614/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0615/0938 | LOSS: 0.1474 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0616/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0617/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0618/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0619/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0620/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0621/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0622/0938 | LOSS: 0.1475 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0623/0938 | LOSS: 0.1474 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0624/0938 | LOSS: 0.1475 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0625/0938 | LOSS: 0.1474 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0626/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0627/0938 | LOSS: 0.1471 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0628/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0629/0938 | LOSS: 0.1473 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0630/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0631/0938 | LOSS: 0.1470 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0632/0938 | LOSS: 0.1470 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0633/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0634/0938 | LOSS: 0.1468 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0635/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0636/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0637/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0638/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0639/0938 | LOSS: 0.1471 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0640/0938 | LOSS: 0.1470 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0641/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0642/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0643/0938 | LOSS: 0.1468 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0644/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0645/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0646/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0647/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0648/0938 | LOSS: 0.1466 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0649/0938 | LOSS: 0.1465 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0650/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0651/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0652/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0653/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0654/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0655/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0656/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0657/0938 | LOSS: 0.1472 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0658/0938 | LOSS: 0.1471 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0659/0938 | LOSS: 0.1471 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0660/0938 | LOSS: 0.1470 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0661/0938 | LOSS: 0.1470 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0662/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0663/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0664/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0665/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0666/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0667/0938 | LOSS: 0.1468 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0668/0938 | LOSS: 0.1466 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0669/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0670/0938 | LOSS: 0.1466 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0671/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0672/0938 | LOSS: 0.1467 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0673/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0674/0938 | LOSS: 0.1469 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0675/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0676/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0677/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0678/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0679/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0680/0938 | LOSS: 0.1468 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0681/0938 | LOSS: 0.1467 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0682/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0683/0938 | LOSS: 0.1469 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0684/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0685/0938 | LOSS: 0.1467 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0686/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0687/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0688/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0689/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0690/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0691/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0692/0938 | LOSS: 0.1463 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0693/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0694/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0695/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0696/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0697/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0698/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0699/0938 | LOSS: 0.1460 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0700/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0701/0938 | LOSS: 0.1458 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0702/0938 | LOSS: 0.1460 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0703/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0704/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0705/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0706/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0707/0938 | LOSS: 0.1459 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0708/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0709/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0710/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0711/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0712/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0713/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0714/0938 | LOSS: 0.1460 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0715/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0716/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0717/0938 | LOSS: 0.1461 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0718/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0719/0938 | LOSS: 0.1460 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0720/0938 | LOSS: 0.1462 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0721/0938 | LOSS: 0.1461 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0722/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0723/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0724/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0725/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0726/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0727/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0728/0938 | LOSS: 0.1466 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0729/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0730/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0731/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0732/0938 | LOSS: 0.1464 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0733/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0734/0938 | LOSS: 0.1462 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0735/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0736/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0737/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0738/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0739/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0740/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0741/0938 | LOSS: 0.1462 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0742/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0743/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0744/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0745/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0746/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0747/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0748/0938 | LOSS: 0.1465 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0749/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0750/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0751/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0752/0938 | LOSS: 0.1462 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0753/0938 | LOSS: 0.1463 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0754/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0755/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0756/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0757/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0758/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0759/0938 | LOSS: 0.1461 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0760/0938 | LOSS: 0.1460 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0761/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0762/0938 | LOSS: 0.1461 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0763/0938 | LOSS: 0.1460 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0764/0938 | LOSS: 0.1460 | ACC 0.9572\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0765/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0766/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0767/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0768/0938 | LOSS: 0.1463 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0769/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0770/0938 | LOSS: 0.1462 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0771/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0772/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0773/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0774/0938 | LOSS: 0.1463 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0775/0938 | LOSS: 0.1464 | ACC 0.9571\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0776/0938 | LOSS: 0.1464 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0777/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0778/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0779/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0780/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0781/0938 | LOSS: 0.1465 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0782/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0783/0938 | LOSS: 0.1466 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0784/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0785/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0786/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0787/0938 | LOSS: 0.1467 | ACC 0.9570\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0788/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0789/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0790/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0791/0938 | LOSS: 0.1469 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0792/0938 | LOSS: 0.1470 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0793/0938 | LOSS: 0.1470 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0794/0938 | LOSS: 0.1470 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0795/0938 | LOSS: 0.1469 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0796/0938 | LOSS: 0.1469 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0797/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0798/0938 | LOSS: 0.1468 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0799/0938 | LOSS: 0.1469 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0800/0938 | LOSS: 0.1471 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0801/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0802/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0803/0938 | LOSS: 0.1473 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0804/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0805/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0806/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0807/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0808/0938 | LOSS: 0.1471 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0809/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0810/0938 | LOSS: 0.1473 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0811/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0812/0938 | LOSS: 0.1471 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0813/0938 | LOSS: 0.1470 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0814/0938 | LOSS: 0.1471 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0815/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0816/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0817/0938 | LOSS: 0.1473 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0818/0938 | LOSS: 0.1472 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0819/0938 | LOSS: 0.1471 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0820/0938 | LOSS: 0.1472 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0821/0938 | LOSS: 0.1471 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0822/0938 | LOSS: 0.1472 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0823/0938 | LOSS: 0.1473 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0824/0938 | LOSS: 0.1474 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0825/0938 | LOSS: 0.1473 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0826/0938 | LOSS: 0.1475 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0827/0938 | LOSS: 0.1475 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0828/0938 | LOSS: 0.1474 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0829/0938 | LOSS: 0.1474 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0830/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0831/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0832/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0833/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0834/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0835/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0836/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0837/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0838/0938 | LOSS: 0.1476 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0839/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0840/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0841/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0842/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0843/0938 | LOSS: 0.1475 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0844/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0845/0938 | LOSS: 0.1476 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0846/0938 | LOSS: 0.1475 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0847/0938 | LOSS: 0.1475 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0848/0938 | LOSS: 0.1475 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0849/0938 | LOSS: 0.1475 | ACC 0.9569\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0850/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0851/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0852/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0853/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0854/0938 | LOSS: 0.1477 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0855/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0856/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0857/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0858/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0859/0938 | LOSS: 0.1479 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0860/0938 | LOSS: 0.1479 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0861/0938 | LOSS: 0.1479 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0862/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0863/0938 | LOSS: 0.1481 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0864/0938 | LOSS: 0.1481 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0865/0938 | LOSS: 0.1479 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0866/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0867/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0868/0938 | LOSS: 0.1478 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0869/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0870/0938 | LOSS: 0.1477 | ACC 0.9568\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0871/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0872/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0873/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0874/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0875/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0876/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0877/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0878/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0879/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0880/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0881/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0882/0938 | LOSS: 0.1480 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0883/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0884/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0885/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0886/0938 | LOSS: 0.1479 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0887/0938 | LOSS: 0.1481 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0888/0938 | LOSS: 0.1482 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0889/0938 | LOSS: 0.1482 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0890/0938 | LOSS: 0.1483 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0891/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0892/0938 | LOSS: 0.1481 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0893/0938 | LOSS: 0.1481 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0894/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0895/0938 | LOSS: 0.1483 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0896/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0897/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0898/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0899/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0900/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0901/0938 | LOSS: 0.1480 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0902/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0903/0938 | LOSS: 0.1479 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0904/0938 | LOSS: 0.1478 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0905/0938 | LOSS: 0.1478 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0906/0938 | LOSS: 0.1477 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0907/0938 | LOSS: 0.1478 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0908/0938 | LOSS: 0.1479 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0909/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0910/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0911/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0912/0938 | LOSS: 0.1483 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0913/0938 | LOSS: 0.1483 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0914/0938 | LOSS: 0.1482 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0915/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0916/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0917/0938 | LOSS: 0.1481 | ACC 0.9565\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0918/0938 | LOSS: 0.1481 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0919/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0920/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0921/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0922/0938 | LOSS: 0.1479 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0923/0938 | LOSS: 0.1478 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0924/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0925/0938 | LOSS: 0.1477 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0926/0938 | LOSS: 0.1476 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0927/0938 | LOSS: 0.1476 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0928/0938 | LOSS: 0.1475 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0929/0938 | LOSS: 0.1477 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0930/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0931/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0932/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0933/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0934/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0935/0938 | LOSS: 0.1478 | ACC 0.9567\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0936/0938 | LOSS: 0.1481 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0937/0938 | LOSS: 0.1480 | ACC 0.9566\n",
            "TRAIN: EPOCH 0008/0010 | BATCH 0938/0938 | LOSS: 0.1479 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0001/0938 | LOSS: 0.0993 | ACC 0.9688\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0002/0938 | LOSS: 0.1117 | ACC 0.9609\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0003/0938 | LOSS: 0.2578 | ACC 0.9479\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0004/0938 | LOSS: 0.2651 | ACC 0.9375\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0005/0938 | LOSS: 0.2407 | ACC 0.9375\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0006/0938 | LOSS: 0.2270 | ACC 0.9375\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0007/0938 | LOSS: 0.2433 | ACC 0.9375\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0008/0938 | LOSS: 0.2342 | ACC 0.9395\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0009/0938 | LOSS: 0.2206 | ACC 0.9410\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0010/0938 | LOSS: 0.2121 | ACC 0.9422\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0011/0938 | LOSS: 0.2050 | ACC 0.9418\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0012/0938 | LOSS: 0.2100 | ACC 0.9440\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0013/0938 | LOSS: 0.2094 | ACC 0.9411\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0014/0938 | LOSS: 0.2003 | ACC 0.9442\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0015/0938 | LOSS: 0.1925 | ACC 0.9448\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0016/0938 | LOSS: 0.1893 | ACC 0.9453\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0017/0938 | LOSS: 0.1850 | ACC 0.9458\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0018/0938 | LOSS: 0.1822 | ACC 0.9453\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0019/0938 | LOSS: 0.1787 | ACC 0.9465\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0020/0938 | LOSS: 0.1791 | ACC 0.9461\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0021/0938 | LOSS: 0.1762 | ACC 0.9449\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0022/0938 | LOSS: 0.1711 | ACC 0.9467\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0023/0938 | LOSS: 0.1681 | ACC 0.9484\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0024/0938 | LOSS: 0.1669 | ACC 0.9492\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0025/0938 | LOSS: 0.1631 | ACC 0.9513\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0026/0938 | LOSS: 0.1611 | ACC 0.9519\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0027/0938 | LOSS: 0.1633 | ACC 0.9508\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0028/0938 | LOSS: 0.1666 | ACC 0.9498\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0029/0938 | LOSS: 0.1658 | ACC 0.9499\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0030/0938 | LOSS: 0.1624 | ACC 0.9510\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0031/0938 | LOSS: 0.1628 | ACC 0.9511\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0032/0938 | LOSS: 0.1607 | ACC 0.9517\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0033/0938 | LOSS: 0.1574 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0034/0938 | LOSS: 0.1559 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0035/0938 | LOSS: 0.1539 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0036/0938 | LOSS: 0.1519 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0037/0938 | LOSS: 0.1511 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0038/0938 | LOSS: 0.1504 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0039/0938 | LOSS: 0.1525 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0040/0938 | LOSS: 0.1512 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0041/0938 | LOSS: 0.1491 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0042/0938 | LOSS: 0.1462 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0043/0938 | LOSS: 0.1479 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0044/0938 | LOSS: 0.1471 | ACC 0.9563\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0045/0938 | LOSS: 0.1474 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0046/0938 | LOSS: 0.1478 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0047/0938 | LOSS: 0.1487 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0048/0938 | LOSS: 0.1464 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0049/0938 | LOSS: 0.1474 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0050/0938 | LOSS: 0.1462 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0051/0938 | LOSS: 0.1459 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0052/0938 | LOSS: 0.1470 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0053/0938 | LOSS: 0.1467 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0054/0938 | LOSS: 0.1459 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0055/0938 | LOSS: 0.1459 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0056/0938 | LOSS: 0.1464 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0057/0938 | LOSS: 0.1461 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0058/0938 | LOSS: 0.1466 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0059/0938 | LOSS: 0.1468 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0060/0938 | LOSS: 0.1491 | ACC 0.9552\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0061/0938 | LOSS: 0.1482 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0062/0938 | LOSS: 0.1481 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0063/0938 | LOSS: 0.1477 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0064/0938 | LOSS: 0.1467 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0065/0938 | LOSS: 0.1453 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0066/0938 | LOSS: 0.1455 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0067/0938 | LOSS: 0.1466 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0068/0938 | LOSS: 0.1458 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0069/0938 | LOSS: 0.1463 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0070/0938 | LOSS: 0.1495 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0071/0938 | LOSS: 0.1486 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0072/0938 | LOSS: 0.1477 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0073/0938 | LOSS: 0.1475 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0074/0938 | LOSS: 0.1463 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0075/0938 | LOSS: 0.1460 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0076/0938 | LOSS: 0.1466 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0077/0938 | LOSS: 0.1488 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0078/0938 | LOSS: 0.1479 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0079/0938 | LOSS: 0.1475 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0080/0938 | LOSS: 0.1473 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0081/0938 | LOSS: 0.1474 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0082/0938 | LOSS: 0.1466 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0083/0938 | LOSS: 0.1464 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0084/0938 | LOSS: 0.1459 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0085/0938 | LOSS: 0.1461 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0086/0938 | LOSS: 0.1450 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0087/0938 | LOSS: 0.1452 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0088/0938 | LOSS: 0.1452 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0089/0938 | LOSS: 0.1446 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0090/0938 | LOSS: 0.1447 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0091/0938 | LOSS: 0.1458 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0092/0938 | LOSS: 0.1453 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0093/0938 | LOSS: 0.1442 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0094/0938 | LOSS: 0.1450 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0095/0938 | LOSS: 0.1458 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0096/0938 | LOSS: 0.1472 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0097/0938 | LOSS: 0.1498 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0098/0938 | LOSS: 0.1504 | ACC 0.9533\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0099/0938 | LOSS: 0.1498 | ACC 0.9533\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0100/0938 | LOSS: 0.1494 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0101/0938 | LOSS: 0.1495 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0102/0938 | LOSS: 0.1490 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0103/0938 | LOSS: 0.1493 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0104/0938 | LOSS: 0.1487 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0105/0938 | LOSS: 0.1479 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0106/0938 | LOSS: 0.1476 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0107/0938 | LOSS: 0.1468 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0108/0938 | LOSS: 0.1464 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0109/0938 | LOSS: 0.1456 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0110/0938 | LOSS: 0.1466 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0111/0938 | LOSS: 0.1466 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0112/0938 | LOSS: 0.1466 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0113/0938 | LOSS: 0.1466 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0114/0938 | LOSS: 0.1463 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0115/0938 | LOSS: 0.1456 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0116/0938 | LOSS: 0.1460 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0117/0938 | LOSS: 0.1457 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0118/0938 | LOSS: 0.1461 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0119/0938 | LOSS: 0.1455 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0120/0938 | LOSS: 0.1450 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0121/0938 | LOSS: 0.1448 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0122/0938 | LOSS: 0.1453 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0123/0938 | LOSS: 0.1449 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0124/0938 | LOSS: 0.1462 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0125/0938 | LOSS: 0.1470 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0126/0938 | LOSS: 0.1474 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0127/0938 | LOSS: 0.1475 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0128/0938 | LOSS: 0.1486 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0129/0938 | LOSS: 0.1492 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0130/0938 | LOSS: 0.1488 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0131/0938 | LOSS: 0.1489 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0132/0938 | LOSS: 0.1489 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0133/0938 | LOSS: 0.1484 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0134/0938 | LOSS: 0.1478 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0135/0938 | LOSS: 0.1484 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0136/0938 | LOSS: 0.1478 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0137/0938 | LOSS: 0.1472 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0138/0938 | LOSS: 0.1466 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0139/0938 | LOSS: 0.1461 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0140/0938 | LOSS: 0.1456 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0141/0938 | LOSS: 0.1461 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0142/0938 | LOSS: 0.1467 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0143/0938 | LOSS: 0.1464 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0144/0938 | LOSS: 0.1462 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0145/0938 | LOSS: 0.1460 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0146/0938 | LOSS: 0.1476 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0147/0938 | LOSS: 0.1474 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0148/0938 | LOSS: 0.1480 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0149/0938 | LOSS: 0.1486 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0150/0938 | LOSS: 0.1489 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0151/0938 | LOSS: 0.1501 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0152/0938 | LOSS: 0.1498 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0153/0938 | LOSS: 0.1493 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0154/0938 | LOSS: 0.1490 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0155/0938 | LOSS: 0.1486 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0156/0938 | LOSS: 0.1486 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0157/0938 | LOSS: 0.1481 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0158/0938 | LOSS: 0.1481 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0159/0938 | LOSS: 0.1482 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0160/0938 | LOSS: 0.1484 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0161/0938 | LOSS: 0.1485 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0162/0938 | LOSS: 0.1482 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0163/0938 | LOSS: 0.1489 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0164/0938 | LOSS: 0.1483 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0165/0938 | LOSS: 0.1482 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0166/0938 | LOSS: 0.1485 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0167/0938 | LOSS: 0.1480 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0168/0938 | LOSS: 0.1479 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0169/0938 | LOSS: 0.1476 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0170/0938 | LOSS: 0.1473 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0171/0938 | LOSS: 0.1490 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0172/0938 | LOSS: 0.1488 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0173/0938 | LOSS: 0.1483 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0174/0938 | LOSS: 0.1488 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0175/0938 | LOSS: 0.1485 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0176/0938 | LOSS: 0.1485 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0177/0938 | LOSS: 0.1487 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0178/0938 | LOSS: 0.1492 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0179/0938 | LOSS: 0.1502 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0180/0938 | LOSS: 0.1502 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0181/0938 | LOSS: 0.1505 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0182/0938 | LOSS: 0.1502 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0183/0938 | LOSS: 0.1500 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0184/0938 | LOSS: 0.1505 | ACC 0.9533\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0185/0938 | LOSS: 0.1502 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0186/0938 | LOSS: 0.1508 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0187/0938 | LOSS: 0.1506 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0188/0938 | LOSS: 0.1509 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0189/0938 | LOSS: 0.1514 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0190/0938 | LOSS: 0.1513 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0191/0938 | LOSS: 0.1514 | ACC 0.9528\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0192/0938 | LOSS: 0.1510 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0193/0938 | LOSS: 0.1515 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0194/0938 | LOSS: 0.1516 | ACC 0.9526\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0195/0938 | LOSS: 0.1517 | ACC 0.9526\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0196/0938 | LOSS: 0.1512 | ACC 0.9528\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0197/0938 | LOSS: 0.1517 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0198/0938 | LOSS: 0.1518 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0199/0938 | LOSS: 0.1516 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0200/0938 | LOSS: 0.1512 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0201/0938 | LOSS: 0.1517 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0202/0938 | LOSS: 0.1515 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0203/0938 | LOSS: 0.1515 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0204/0938 | LOSS: 0.1517 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0205/0938 | LOSS: 0.1514 | ACC 0.9533\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0206/0938 | LOSS: 0.1511 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0207/0938 | LOSS: 0.1510 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0208/0938 | LOSS: 0.1514 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0209/0938 | LOSS: 0.1518 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0210/0938 | LOSS: 0.1515 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0211/0938 | LOSS: 0.1516 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0212/0938 | LOSS: 0.1517 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0213/0938 | LOSS: 0.1515 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0214/0938 | LOSS: 0.1510 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0215/0938 | LOSS: 0.1516 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0216/0938 | LOSS: 0.1522 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0217/0938 | LOSS: 0.1517 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0218/0938 | LOSS: 0.1520 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0219/0938 | LOSS: 0.1518 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0220/0938 | LOSS: 0.1522 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0221/0938 | LOSS: 0.1528 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0222/0938 | LOSS: 0.1529 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0223/0938 | LOSS: 0.1530 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0224/0938 | LOSS: 0.1533 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0225/0938 | LOSS: 0.1532 | ACC 0.9528\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0226/0938 | LOSS: 0.1533 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0227/0938 | LOSS: 0.1536 | ACC 0.9526\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0228/0938 | LOSS: 0.1533 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0229/0938 | LOSS: 0.1531 | ACC 0.9527\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0230/0938 | LOSS: 0.1532 | ACC 0.9528\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0231/0938 | LOSS: 0.1530 | ACC 0.9529\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0232/0938 | LOSS: 0.1528 | ACC 0.9530\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0233/0938 | LOSS: 0.1526 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0234/0938 | LOSS: 0.1527 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0235/0938 | LOSS: 0.1523 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0236/0938 | LOSS: 0.1523 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0237/0938 | LOSS: 0.1520 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0238/0938 | LOSS: 0.1525 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0239/0938 | LOSS: 0.1524 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0240/0938 | LOSS: 0.1523 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0241/0938 | LOSS: 0.1524 | ACC 0.9531\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0242/0938 | LOSS: 0.1530 | ACC 0.9532\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0243/0938 | LOSS: 0.1532 | ACC 0.9533\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0244/0938 | LOSS: 0.1527 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0245/0938 | LOSS: 0.1523 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0246/0938 | LOSS: 0.1530 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0247/0938 | LOSS: 0.1528 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0248/0938 | LOSS: 0.1531 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0249/0938 | LOSS: 0.1533 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0250/0938 | LOSS: 0.1530 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0251/0938 | LOSS: 0.1530 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0252/0938 | LOSS: 0.1529 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0253/0938 | LOSS: 0.1525 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0254/0938 | LOSS: 0.1527 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0255/0938 | LOSS: 0.1528 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0256/0938 | LOSS: 0.1528 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0257/0938 | LOSS: 0.1524 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0258/0938 | LOSS: 0.1522 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0259/0938 | LOSS: 0.1525 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0260/0938 | LOSS: 0.1527 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0261/0938 | LOSS: 0.1526 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0262/0938 | LOSS: 0.1521 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0263/0938 | LOSS: 0.1521 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0264/0938 | LOSS: 0.1518 | ACC 0.9535\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0265/0938 | LOSS: 0.1517 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0266/0938 | LOSS: 0.1519 | ACC 0.9534\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0267/0938 | LOSS: 0.1513 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0268/0938 | LOSS: 0.1512 | ACC 0.9536\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0269/0938 | LOSS: 0.1513 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0270/0938 | LOSS: 0.1510 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0271/0938 | LOSS: 0.1508 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0272/0938 | LOSS: 0.1510 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0273/0938 | LOSS: 0.1508 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0274/0938 | LOSS: 0.1506 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0275/0938 | LOSS: 0.1506 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0276/0938 | LOSS: 0.1505 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0277/0938 | LOSS: 0.1506 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0278/0938 | LOSS: 0.1501 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0279/0938 | LOSS: 0.1499 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0280/0938 | LOSS: 0.1502 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0281/0938 | LOSS: 0.1504 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0282/0938 | LOSS: 0.1505 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0283/0938 | LOSS: 0.1506 | ACC 0.9537\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0284/0938 | LOSS: 0.1503 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0285/0938 | LOSS: 0.1501 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0286/0938 | LOSS: 0.1500 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0287/0938 | LOSS: 0.1497 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0288/0938 | LOSS: 0.1497 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0289/0938 | LOSS: 0.1497 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0290/0938 | LOSS: 0.1500 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0291/0938 | LOSS: 0.1499 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0292/0938 | LOSS: 0.1498 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0293/0938 | LOSS: 0.1495 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0294/0938 | LOSS: 0.1494 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0295/0938 | LOSS: 0.1491 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0296/0938 | LOSS: 0.1493 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0297/0938 | LOSS: 0.1492 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0298/0938 | LOSS: 0.1491 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0299/0938 | LOSS: 0.1498 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0300/0938 | LOSS: 0.1496 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0301/0938 | LOSS: 0.1500 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0302/0938 | LOSS: 0.1497 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0303/0938 | LOSS: 0.1493 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0304/0938 | LOSS: 0.1495 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0305/0938 | LOSS: 0.1492 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0306/0938 | LOSS: 0.1500 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0307/0938 | LOSS: 0.1503 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0308/0938 | LOSS: 0.1503 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0309/0938 | LOSS: 0.1499 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0310/0938 | LOSS: 0.1500 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0311/0938 | LOSS: 0.1499 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0312/0938 | LOSS: 0.1497 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0313/0938 | LOSS: 0.1496 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0314/0938 | LOSS: 0.1496 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0315/0938 | LOSS: 0.1495 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0316/0938 | LOSS: 0.1503 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0317/0938 | LOSS: 0.1499 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0318/0938 | LOSS: 0.1500 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0319/0938 | LOSS: 0.1499 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0320/0938 | LOSS: 0.1498 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0321/0938 | LOSS: 0.1499 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0322/0938 | LOSS: 0.1498 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0323/0938 | LOSS: 0.1497 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0324/0938 | LOSS: 0.1498 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0325/0938 | LOSS: 0.1497 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0326/0938 | LOSS: 0.1497 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0327/0938 | LOSS: 0.1494 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0328/0938 | LOSS: 0.1498 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0329/0938 | LOSS: 0.1496 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0330/0938 | LOSS: 0.1499 | ACC 0.9538\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0331/0938 | LOSS: 0.1498 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0332/0938 | LOSS: 0.1497 | ACC 0.9539\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0333/0938 | LOSS: 0.1494 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0334/0938 | LOSS: 0.1495 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0335/0938 | LOSS: 0.1496 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0336/0938 | LOSS: 0.1494 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0337/0938 | LOSS: 0.1491 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0338/0938 | LOSS: 0.1500 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0339/0938 | LOSS: 0.1501 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0340/0938 | LOSS: 0.1501 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0341/0938 | LOSS: 0.1500 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0342/0938 | LOSS: 0.1498 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0343/0938 | LOSS: 0.1497 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0344/0938 | LOSS: 0.1494 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0345/0938 | LOSS: 0.1495 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0346/0938 | LOSS: 0.1500 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0347/0938 | LOSS: 0.1500 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0348/0938 | LOSS: 0.1497 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0349/0938 | LOSS: 0.1495 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0350/0938 | LOSS: 0.1496 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0351/0938 | LOSS: 0.1495 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0352/0938 | LOSS: 0.1499 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0353/0938 | LOSS: 0.1509 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0354/0938 | LOSS: 0.1509 | ACC 0.9541\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0355/0938 | LOSS: 0.1510 | ACC 0.9540\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0356/0938 | LOSS: 0.1507 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0357/0938 | LOSS: 0.1507 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0358/0938 | LOSS: 0.1504 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0359/0938 | LOSS: 0.1502 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0360/0938 | LOSS: 0.1500 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0361/0938 | LOSS: 0.1498 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0362/0938 | LOSS: 0.1496 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0363/0938 | LOSS: 0.1501 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0364/0938 | LOSS: 0.1500 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0365/0938 | LOSS: 0.1504 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0366/0938 | LOSS: 0.1502 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0367/0938 | LOSS: 0.1501 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0368/0938 | LOSS: 0.1501 | ACC 0.9542\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0369/0938 | LOSS: 0.1506 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0370/0938 | LOSS: 0.1506 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0371/0938 | LOSS: 0.1504 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0372/0938 | LOSS: 0.1505 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0373/0938 | LOSS: 0.1502 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0374/0938 | LOSS: 0.1499 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0375/0938 | LOSS: 0.1502 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0376/0938 | LOSS: 0.1502 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0377/0938 | LOSS: 0.1500 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0378/0938 | LOSS: 0.1499 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0379/0938 | LOSS: 0.1498 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0380/0938 | LOSS: 0.1497 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0381/0938 | LOSS: 0.1495 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0382/0938 | LOSS: 0.1495 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0383/0938 | LOSS: 0.1496 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0384/0938 | LOSS: 0.1498 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0385/0938 | LOSS: 0.1503 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0386/0938 | LOSS: 0.1502 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0387/0938 | LOSS: 0.1500 | ACC 0.9543\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0388/0938 | LOSS: 0.1498 | ACC 0.9544\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0389/0938 | LOSS: 0.1497 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0390/0938 | LOSS: 0.1496 | ACC 0.9545\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0391/0938 | LOSS: 0.1494 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0392/0938 | LOSS: 0.1492 | ACC 0.9546\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0393/0938 | LOSS: 0.1494 | ACC 0.9547\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0394/0938 | LOSS: 0.1491 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0395/0938 | LOSS: 0.1491 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0396/0938 | LOSS: 0.1488 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0397/0938 | LOSS: 0.1491 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0398/0938 | LOSS: 0.1489 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0399/0938 | LOSS: 0.1490 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0400/0938 | LOSS: 0.1487 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0401/0938 | LOSS: 0.1488 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0402/0938 | LOSS: 0.1491 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0403/0938 | LOSS: 0.1488 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0404/0938 | LOSS: 0.1485 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0405/0938 | LOSS: 0.1484 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0406/0938 | LOSS: 0.1489 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0407/0938 | LOSS: 0.1488 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0408/0938 | LOSS: 0.1490 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0409/0938 | LOSS: 0.1494 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0410/0938 | LOSS: 0.1492 | ACC 0.9548\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0411/0938 | LOSS: 0.1489 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0412/0938 | LOSS: 0.1488 | ACC 0.9549\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0413/0938 | LOSS: 0.1486 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0414/0938 | LOSS: 0.1483 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0415/0938 | LOSS: 0.1486 | ACC 0.9550\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0416/0938 | LOSS: 0.1485 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0417/0938 | LOSS: 0.1483 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0418/0938 | LOSS: 0.1484 | ACC 0.9551\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0419/0938 | LOSS: 0.1483 | ACC 0.9552\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0420/0938 | LOSS: 0.1482 | ACC 0.9552\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0421/0938 | LOSS: 0.1481 | ACC 0.9552\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0422/0938 | LOSS: 0.1481 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0423/0938 | LOSS: 0.1486 | ACC 0.9552\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0424/0938 | LOSS: 0.1484 | ACC 0.9553\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0425/0938 | LOSS: 0.1482 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0426/0938 | LOSS: 0.1481 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0427/0938 | LOSS: 0.1483 | ACC 0.9554\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0428/0938 | LOSS: 0.1481 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0429/0938 | LOSS: 0.1478 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0430/0938 | LOSS: 0.1479 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0431/0938 | LOSS: 0.1478 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0432/0938 | LOSS: 0.1479 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0433/0938 | LOSS: 0.1478 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0434/0938 | LOSS: 0.1480 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0435/0938 | LOSS: 0.1477 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0436/0938 | LOSS: 0.1476 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0437/0938 | LOSS: 0.1474 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0438/0938 | LOSS: 0.1477 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0439/0938 | LOSS: 0.1480 | ACC 0.9555\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0440/0938 | LOSS: 0.1479 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0441/0938 | LOSS: 0.1476 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0442/0938 | LOSS: 0.1476 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0443/0938 | LOSS: 0.1474 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0444/0938 | LOSS: 0.1473 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0445/0938 | LOSS: 0.1473 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0446/0938 | LOSS: 0.1475 | ACC 0.9556\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0447/0938 | LOSS: 0.1473 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0448/0938 | LOSS: 0.1471 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0449/0938 | LOSS: 0.1470 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0450/0938 | LOSS: 0.1469 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0451/0938 | LOSS: 0.1468 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0452/0938 | LOSS: 0.1465 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0453/0938 | LOSS: 0.1465 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0454/0938 | LOSS: 0.1467 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0455/0938 | LOSS: 0.1465 | ACC 0.9557\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0456/0938 | LOSS: 0.1465 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0457/0938 | LOSS: 0.1463 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0458/0938 | LOSS: 0.1462 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0459/0938 | LOSS: 0.1462 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0460/0938 | LOSS: 0.1461 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0461/0938 | LOSS: 0.1460 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0462/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0463/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0464/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0465/0938 | LOSS: 0.1461 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0466/0938 | LOSS: 0.1460 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0467/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0468/0938 | LOSS: 0.1460 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0469/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0470/0938 | LOSS: 0.1457 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0471/0938 | LOSS: 0.1456 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0472/0938 | LOSS: 0.1454 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0473/0938 | LOSS: 0.1458 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0474/0938 | LOSS: 0.1458 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0475/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0476/0938 | LOSS: 0.1458 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0477/0938 | LOSS: 0.1460 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0478/0938 | LOSS: 0.1459 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0479/0938 | LOSS: 0.1458 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0480/0938 | LOSS: 0.1457 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0481/0938 | LOSS: 0.1455 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0482/0938 | LOSS: 0.1453 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0483/0938 | LOSS: 0.1453 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0484/0938 | LOSS: 0.1452 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0485/0938 | LOSS: 0.1451 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0486/0938 | LOSS: 0.1452 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0487/0938 | LOSS: 0.1450 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0488/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0489/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0490/0938 | LOSS: 0.1449 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0491/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0492/0938 | LOSS: 0.1451 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0493/0938 | LOSS: 0.1450 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0494/0938 | LOSS: 0.1453 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0495/0938 | LOSS: 0.1452 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0496/0938 | LOSS: 0.1450 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0497/0938 | LOSS: 0.1455 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0498/0938 | LOSS: 0.1454 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0499/0938 | LOSS: 0.1454 | ACC 0.9558\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0500/0938 | LOSS: 0.1452 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0501/0938 | LOSS: 0.1451 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0502/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0503/0938 | LOSS: 0.1456 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0504/0938 | LOSS: 0.1455 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0505/0938 | LOSS: 0.1455 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0506/0938 | LOSS: 0.1454 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0507/0938 | LOSS: 0.1453 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0508/0938 | LOSS: 0.1452 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0509/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0510/0938 | LOSS: 0.1451 | ACC 0.9559\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0511/0938 | LOSS: 0.1450 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0512/0938 | LOSS: 0.1448 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0513/0938 | LOSS: 0.1448 | ACC 0.9560\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0514/0938 | LOSS: 0.1448 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0515/0938 | LOSS: 0.1447 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0516/0938 | LOSS: 0.1446 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0517/0938 | LOSS: 0.1449 | ACC 0.9561\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0518/0938 | LOSS: 0.1447 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0519/0938 | LOSS: 0.1447 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0520/0938 | LOSS: 0.1448 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0521/0938 | LOSS: 0.1447 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0522/0938 | LOSS: 0.1446 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0523/0938 | LOSS: 0.1446 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0524/0938 | LOSS: 0.1445 | ACC 0.9563\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0525/0938 | LOSS: 0.1446 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0526/0938 | LOSS: 0.1445 | ACC 0.9562\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0527/0938 | LOSS: 0.1444 | ACC 0.9563\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0528/0938 | LOSS: 0.1443 | ACC 0.9564\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0529/0938 | LOSS: 0.1442 | ACC 0.9564\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0530/0938 | LOSS: 0.1441 | ACC 0.9564\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0531/0938 | LOSS: 0.1440 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0532/0938 | LOSS: 0.1439 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0533/0938 | LOSS: 0.1439 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0534/0938 | LOSS: 0.1438 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0535/0938 | LOSS: 0.1436 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0536/0938 | LOSS: 0.1434 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0537/0938 | LOSS: 0.1433 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0538/0938 | LOSS: 0.1431 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0539/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0540/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0541/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0542/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0543/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0544/0938 | LOSS: 0.1429 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0545/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0546/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0547/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0548/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0549/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0550/0938 | LOSS: 0.1431 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0551/0938 | LOSS: 0.1434 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0552/0938 | LOSS: 0.1434 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0553/0938 | LOSS: 0.1437 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0554/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0555/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0556/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0557/0938 | LOSS: 0.1439 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0558/0938 | LOSS: 0.1439 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0559/0938 | LOSS: 0.1440 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0560/0938 | LOSS: 0.1445 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0561/0938 | LOSS: 0.1444 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0562/0938 | LOSS: 0.1444 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0563/0938 | LOSS: 0.1443 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0564/0938 | LOSS: 0.1442 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0565/0938 | LOSS: 0.1441 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0566/0938 | LOSS: 0.1439 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0567/0938 | LOSS: 0.1440 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0568/0938 | LOSS: 0.1439 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0569/0938 | LOSS: 0.1440 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0570/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0571/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0572/0938 | LOSS: 0.1438 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0573/0938 | LOSS: 0.1437 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0574/0938 | LOSS: 0.1438 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0575/0938 | LOSS: 0.1438 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0576/0938 | LOSS: 0.1437 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0577/0938 | LOSS: 0.1435 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0578/0938 | LOSS: 0.1434 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0579/0938 | LOSS: 0.1433 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0580/0938 | LOSS: 0.1434 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0581/0938 | LOSS: 0.1435 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0582/0938 | LOSS: 0.1437 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0583/0938 | LOSS: 0.1436 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0584/0938 | LOSS: 0.1438 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0585/0938 | LOSS: 0.1436 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0586/0938 | LOSS: 0.1436 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0587/0938 | LOSS: 0.1435 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0588/0938 | LOSS: 0.1436 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0589/0938 | LOSS: 0.1434 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0590/0938 | LOSS: 0.1433 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0591/0938 | LOSS: 0.1431 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0592/0938 | LOSS: 0.1430 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0593/0938 | LOSS: 0.1429 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0594/0938 | LOSS: 0.1433 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0595/0938 | LOSS: 0.1432 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0596/0938 | LOSS: 0.1435 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0597/0938 | LOSS: 0.1436 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0598/0938 | LOSS: 0.1436 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0599/0938 | LOSS: 0.1435 | ACC 0.9565\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0600/0938 | LOSS: 0.1435 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0601/0938 | LOSS: 0.1434 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0602/0938 | LOSS: 0.1433 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0603/0938 | LOSS: 0.1431 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0604/0938 | LOSS: 0.1431 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0605/0938 | LOSS: 0.1433 | ACC 0.9566\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0606/0938 | LOSS: 0.1432 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0607/0938 | LOSS: 0.1432 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0608/0938 | LOSS: 0.1432 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0609/0938 | LOSS: 0.1432 | ACC 0.9567\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0610/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0611/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0612/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0613/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0614/0938 | LOSS: 0.1426 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0615/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0616/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0617/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0618/0938 | LOSS: 0.1429 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0619/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0620/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0621/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0622/0938 | LOSS: 0.1429 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0623/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0624/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0625/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0626/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0627/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0628/0938 | LOSS: 0.1426 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0629/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0630/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0631/0938 | LOSS: 0.1430 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0632/0938 | LOSS: 0.1429 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0633/0938 | LOSS: 0.1429 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0634/0938 | LOSS: 0.1429 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0635/0938 | LOSS: 0.1431 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0636/0938 | LOSS: 0.1430 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0637/0938 | LOSS: 0.1430 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0638/0938 | LOSS: 0.1429 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0639/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0640/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0641/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0642/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0643/0938 | LOSS: 0.1426 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0644/0938 | LOSS: 0.1429 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0645/0938 | LOSS: 0.1428 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0646/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0647/0938 | LOSS: 0.1428 | ACC 0.9568\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0648/0938 | LOSS: 0.1427 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0649/0938 | LOSS: 0.1426 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0650/0938 | LOSS: 0.1425 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0651/0938 | LOSS: 0.1425 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0652/0938 | LOSS: 0.1423 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0653/0938 | LOSS: 0.1423 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0654/0938 | LOSS: 0.1423 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0655/0938 | LOSS: 0.1422 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0656/0938 | LOSS: 0.1422 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0657/0938 | LOSS: 0.1423 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0658/0938 | LOSS: 0.1422 | ACC 0.9569\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0659/0938 | LOSS: 0.1421 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0660/0938 | LOSS: 0.1420 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0661/0938 | LOSS: 0.1420 | ACC 0.9570\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0662/0938 | LOSS: 0.1419 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0663/0938 | LOSS: 0.1419 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0664/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0665/0938 | LOSS: 0.1419 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0666/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0667/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0668/0938 | LOSS: 0.1416 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0669/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0670/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0671/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0672/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0673/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0674/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0675/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0676/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0677/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0678/0938 | LOSS: 0.1411 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0679/0938 | LOSS: 0.1411 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0680/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0681/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0682/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0683/0938 | LOSS: 0.1411 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0684/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0685/0938 | LOSS: 0.1409 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0686/0938 | LOSS: 0.1409 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0687/0938 | LOSS: 0.1409 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0688/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0689/0938 | LOSS: 0.1409 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0690/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0691/0938 | LOSS: 0.1406 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0692/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0693/0938 | LOSS: 0.1406 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0694/0938 | LOSS: 0.1405 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0695/0938 | LOSS: 0.1404 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0696/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0697/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0698/0938 | LOSS: 0.1411 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0699/0938 | LOSS: 0.1409 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0700/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0701/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0702/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0703/0938 | LOSS: 0.1412 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0704/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0705/0938 | LOSS: 0.1411 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0706/0938 | LOSS: 0.1412 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0707/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0708/0938 | LOSS: 0.1416 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0709/0938 | LOSS: 0.1417 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0710/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0711/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0712/0938 | LOSS: 0.1413 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0713/0938 | LOSS: 0.1414 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0714/0938 | LOSS: 0.1416 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0715/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0716/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0717/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0718/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0719/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0720/0938 | LOSS: 0.1416 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0721/0938 | LOSS: 0.1417 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0722/0938 | LOSS: 0.1416 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0723/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0724/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0725/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0726/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0727/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0728/0938 | LOSS: 0.1414 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0729/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0730/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0731/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0732/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0733/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0734/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0735/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0736/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0737/0938 | LOSS: 0.1418 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0738/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0739/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0740/0938 | LOSS: 0.1416 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0741/0938 | LOSS: 0.1418 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0742/0938 | LOSS: 0.1419 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0743/0938 | LOSS: 0.1419 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0744/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0745/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0746/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0747/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0748/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0749/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0750/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0751/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0752/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0753/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0754/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0755/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0756/0938 | LOSS: 0.1418 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0757/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0758/0938 | LOSS: 0.1417 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0759/0938 | LOSS: 0.1416 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0760/0938 | LOSS: 0.1416 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0761/0938 | LOSS: 0.1415 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0762/0938 | LOSS: 0.1414 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0763/0938 | LOSS: 0.1412 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0764/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0765/0938 | LOSS: 0.1412 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0766/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0767/0938 | LOSS: 0.1414 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0768/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0769/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0770/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0771/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0772/0938 | LOSS: 0.1414 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0773/0938 | LOSS: 0.1416 | ACC 0.9571\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0774/0938 | LOSS: 0.1415 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0775/0938 | LOSS: 0.1414 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0776/0938 | LOSS: 0.1413 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0777/0938 | LOSS: 0.1412 | ACC 0.9572\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0778/0938 | LOSS: 0.1411 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0779/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0780/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0781/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0782/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0783/0938 | LOSS: 0.1411 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0784/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0785/0938 | LOSS: 0.1410 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0786/0938 | LOSS: 0.1408 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0787/0938 | LOSS: 0.1407 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0788/0938 | LOSS: 0.1408 | ACC 0.9573\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0789/0938 | LOSS: 0.1407 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0790/0938 | LOSS: 0.1407 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0791/0938 | LOSS: 0.1407 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0792/0938 | LOSS: 0.1406 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0793/0938 | LOSS: 0.1405 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0794/0938 | LOSS: 0.1404 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0795/0938 | LOSS: 0.1403 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0796/0938 | LOSS: 0.1403 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0797/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0798/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0799/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0800/0938 | LOSS: 0.1403 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0801/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0802/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0803/0938 | LOSS: 0.1402 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0804/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0805/0938 | LOSS: 0.1400 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0806/0938 | LOSS: 0.1403 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0807/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0808/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0809/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0810/0938 | LOSS: 0.1400 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0811/0938 | LOSS: 0.1399 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0812/0938 | LOSS: 0.1399 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0813/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0814/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0815/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0816/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0817/0938 | LOSS: 0.1404 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0818/0938 | LOSS: 0.1403 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0819/0938 | LOSS: 0.1404 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0820/0938 | LOSS: 0.1405 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0821/0938 | LOSS: 0.1404 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0822/0938 | LOSS: 0.1403 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0823/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0824/0938 | LOSS: 0.1401 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0825/0938 | LOSS: 0.1404 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0826/0938 | LOSS: 0.1405 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0827/0938 | LOSS: 0.1406 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0828/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0829/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0830/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0831/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0832/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0833/0938 | LOSS: 0.1406 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0834/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0835/0938 | LOSS: 0.1406 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0836/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0837/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0838/0938 | LOSS: 0.1404 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0839/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0840/0938 | LOSS: 0.1409 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0841/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0842/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0843/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0844/0938 | LOSS: 0.1408 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0845/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0846/0938 | LOSS: 0.1407 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0847/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0848/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0849/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0850/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0851/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0852/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0853/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0854/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0855/0938 | LOSS: 0.1408 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0856/0938 | LOSS: 0.1410 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0857/0938 | LOSS: 0.1410 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0858/0938 | LOSS: 0.1414 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0859/0938 | LOSS: 0.1414 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0860/0938 | LOSS: 0.1414 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0861/0938 | LOSS: 0.1414 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0862/0938 | LOSS: 0.1414 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0863/0938 | LOSS: 0.1413 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0864/0938 | LOSS: 0.1412 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0865/0938 | LOSS: 0.1411 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0866/0938 | LOSS: 0.1411 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0867/0938 | LOSS: 0.1411 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0868/0938 | LOSS: 0.1412 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0869/0938 | LOSS: 0.1411 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0870/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0871/0938 | LOSS: 0.1411 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0872/0938 | LOSS: 0.1410 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0873/0938 | LOSS: 0.1410 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0874/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0875/0938 | LOSS: 0.1411 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0876/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0877/0938 | LOSS: 0.1411 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0878/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0879/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0880/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0881/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0882/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0883/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0884/0938 | LOSS: 0.1410 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0885/0938 | LOSS: 0.1410 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0886/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0887/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0888/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0889/0938 | LOSS: 0.1413 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0890/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0891/0938 | LOSS: 0.1415 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0892/0938 | LOSS: 0.1414 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0893/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0894/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0895/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0896/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0897/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0898/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0899/0938 | LOSS: 0.1410 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0900/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0901/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0902/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0903/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0904/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0905/0938 | LOSS: 0.1414 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0906/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0907/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0908/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0909/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0910/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0911/0938 | LOSS: 0.1414 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0912/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0913/0938 | LOSS: 0.1415 | ACC 0.9577\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0914/0938 | LOSS: 0.1416 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0915/0938 | LOSS: 0.1417 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0916/0938 | LOSS: 0.1418 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0917/0938 | LOSS: 0.1417 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0918/0938 | LOSS: 0.1418 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0919/0938 | LOSS: 0.1418 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0920/0938 | LOSS: 0.1418 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0921/0938 | LOSS: 0.1418 | ACC 0.9576\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0922/0938 | LOSS: 0.1419 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0923/0938 | LOSS: 0.1418 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0924/0938 | LOSS: 0.1419 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0925/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0926/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0927/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0928/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0929/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0930/0938 | LOSS: 0.1421 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0931/0938 | LOSS: 0.1422 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0932/0938 | LOSS: 0.1421 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0933/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0934/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0935/0938 | LOSS: 0.1420 | ACC 0.9575\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0936/0938 | LOSS: 0.1421 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0937/0938 | LOSS: 0.1422 | ACC 0.9574\n",
            "TRAIN: EPOCH 0009/0010 | BATCH 0938/0938 | LOSS: 0.1422 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0001/0938 | LOSS: 0.0303 | ACC 1.0000\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0002/0938 | LOSS: 0.0434 | ACC 1.0000\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0003/0938 | LOSS: 0.0585 | ACC 0.9896\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0004/0938 | LOSS: 0.0621 | ACC 0.9883\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0005/0938 | LOSS: 0.0709 | ACC 0.9812\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0006/0938 | LOSS: 0.0693 | ACC 0.9818\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0007/0938 | LOSS: 0.0824 | ACC 0.9754\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0008/0938 | LOSS: 0.0747 | ACC 0.9785\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0009/0938 | LOSS: 0.0865 | ACC 0.9757\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0010/0938 | LOSS: 0.0873 | ACC 0.9750\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0011/0938 | LOSS: 0.0904 | ACC 0.9744\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0012/0938 | LOSS: 0.0975 | ACC 0.9688\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0013/0938 | LOSS: 0.1040 | ACC 0.9651\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0014/0938 | LOSS: 0.1000 | ACC 0.9676\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0015/0938 | LOSS: 0.1072 | ACC 0.9667\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0016/0938 | LOSS: 0.1075 | ACC 0.9658\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0017/0938 | LOSS: 0.1107 | ACC 0.9660\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0018/0938 | LOSS: 0.1097 | ACC 0.9661\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0019/0938 | LOSS: 0.1132 | ACC 0.9638\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0020/0938 | LOSS: 0.1119 | ACC 0.9648\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0021/0938 | LOSS: 0.1100 | ACC 0.9650\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0022/0938 | LOSS: 0.1151 | ACC 0.9652\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0023/0938 | LOSS: 0.1129 | ACC 0.9660\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0024/0938 | LOSS: 0.1155 | ACC 0.9668\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0025/0938 | LOSS: 0.1171 | ACC 0.9663\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0026/0938 | LOSS: 0.1150 | ACC 0.9669\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0027/0938 | LOSS: 0.1165 | ACC 0.9670\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0028/0938 | LOSS: 0.1217 | ACC 0.9654\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0029/0938 | LOSS: 0.1236 | ACC 0.9634\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0030/0938 | LOSS: 0.1203 | ACC 0.9641\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0031/0938 | LOSS: 0.1236 | ACC 0.9637\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0032/0938 | LOSS: 0.1292 | ACC 0.9614\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0033/0938 | LOSS: 0.1314 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0034/0938 | LOSS: 0.1350 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0035/0938 | LOSS: 0.1335 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0036/0938 | LOSS: 0.1319 | ACC 0.9588\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0037/0938 | LOSS: 0.1299 | ACC 0.9599\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0038/0938 | LOSS: 0.1321 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0039/0938 | LOSS: 0.1308 | ACC 0.9603\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0040/0938 | LOSS: 0.1300 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0041/0938 | LOSS: 0.1290 | ACC 0.9611\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0042/0938 | LOSS: 0.1273 | ACC 0.9617\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0043/0938 | LOSS: 0.1261 | ACC 0.9618\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0044/0938 | LOSS: 0.1239 | ACC 0.9627\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0045/0938 | LOSS: 0.1264 | ACC 0.9625\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0046/0938 | LOSS: 0.1255 | ACC 0.9630\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0047/0938 | LOSS: 0.1249 | ACC 0.9631\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0048/0938 | LOSS: 0.1266 | ACC 0.9622\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0049/0938 | LOSS: 0.1281 | ACC 0.9624\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0050/0938 | LOSS: 0.1291 | ACC 0.9619\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0051/0938 | LOSS: 0.1280 | ACC 0.9623\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0052/0938 | LOSS: 0.1275 | ACC 0.9621\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0053/0938 | LOSS: 0.1269 | ACC 0.9626\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0054/0938 | LOSS: 0.1272 | ACC 0.9627\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0055/0938 | LOSS: 0.1261 | ACC 0.9628\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0056/0938 | LOSS: 0.1261 | ACC 0.9626\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0057/0938 | LOSS: 0.1245 | ACC 0.9633\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0058/0938 | LOSS: 0.1244 | ACC 0.9634\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0059/0938 | LOSS: 0.1236 | ACC 0.9637\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0060/0938 | LOSS: 0.1229 | ACC 0.9638\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0061/0938 | LOSS: 0.1224 | ACC 0.9639\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0062/0938 | LOSS: 0.1300 | ACC 0.9622\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0063/0938 | LOSS: 0.1296 | ACC 0.9623\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0064/0938 | LOSS: 0.1306 | ACC 0.9614\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0065/0938 | LOSS: 0.1309 | ACC 0.9615\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0066/0938 | LOSS: 0.1314 | ACC 0.9612\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0067/0938 | LOSS: 0.1340 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0068/0938 | LOSS: 0.1356 | ACC 0.9598\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0069/0938 | LOSS: 0.1357 | ACC 0.9599\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0070/0938 | LOSS: 0.1340 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0071/0938 | LOSS: 0.1362 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0072/0938 | LOSS: 0.1361 | ACC 0.9599\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0073/0938 | LOSS: 0.1353 | ACC 0.9600\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0074/0938 | LOSS: 0.1351 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0075/0938 | LOSS: 0.1340 | ACC 0.9602\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0076/0938 | LOSS: 0.1349 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0077/0938 | LOSS: 0.1353 | ACC 0.9598\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0078/0938 | LOSS: 0.1344 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0079/0938 | LOSS: 0.1344 | ACC 0.9600\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0080/0938 | LOSS: 0.1366 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0081/0938 | LOSS: 0.1377 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0082/0938 | LOSS: 0.1365 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0083/0938 | LOSS: 0.1364 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0084/0938 | LOSS: 0.1361 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0085/0938 | LOSS: 0.1352 | ACC 0.9608\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0086/0938 | LOSS: 0.1355 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0087/0938 | LOSS: 0.1347 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0088/0938 | LOSS: 0.1352 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0089/0938 | LOSS: 0.1343 | ACC 0.9610\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0090/0938 | LOSS: 0.1348 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0091/0938 | LOSS: 0.1345 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0092/0938 | LOSS: 0.1359 | ACC 0.9608\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0093/0938 | LOSS: 0.1348 | ACC 0.9612\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0094/0938 | LOSS: 0.1358 | ACC 0.9608\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0095/0938 | LOSS: 0.1350 | ACC 0.9610\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0096/0938 | LOSS: 0.1351 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0097/0938 | LOSS: 0.1344 | ACC 0.9610\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0098/0938 | LOSS: 0.1342 | ACC 0.9613\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0099/0938 | LOSS: 0.1339 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0100/0938 | LOSS: 0.1338 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0101/0938 | LOSS: 0.1337 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0102/0938 | LOSS: 0.1345 | ACC 0.9602\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0103/0938 | LOSS: 0.1337 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0104/0938 | LOSS: 0.1329 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0105/0938 | LOSS: 0.1336 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0106/0938 | LOSS: 0.1331 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0107/0938 | LOSS: 0.1331 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0108/0938 | LOSS: 0.1345 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0109/0938 | LOSS: 0.1343 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0110/0938 | LOSS: 0.1344 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0111/0938 | LOSS: 0.1351 | ACC 0.9602\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0112/0938 | LOSS: 0.1351 | ACC 0.9604\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0113/0938 | LOSS: 0.1354 | ACC 0.9603\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0114/0938 | LOSS: 0.1346 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0115/0938 | LOSS: 0.1342 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0116/0938 | LOSS: 0.1339 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0117/0938 | LOSS: 0.1336 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0118/0938 | LOSS: 0.1336 | ACC 0.9608\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0119/0938 | LOSS: 0.1328 | ACC 0.9610\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0120/0938 | LOSS: 0.1323 | ACC 0.9612\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0121/0938 | LOSS: 0.1328 | ACC 0.9613\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0122/0938 | LOSS: 0.1330 | ACC 0.9613\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0123/0938 | LOSS: 0.1333 | ACC 0.9614\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0124/0938 | LOSS: 0.1334 | ACC 0.9611\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0125/0938 | LOSS: 0.1341 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0126/0938 | LOSS: 0.1368 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0127/0938 | LOSS: 0.1361 | ACC 0.9611\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0128/0938 | LOSS: 0.1358 | ACC 0.9613\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0129/0938 | LOSS: 0.1362 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0130/0938 | LOSS: 0.1360 | ACC 0.9608\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0131/0938 | LOSS: 0.1361 | ACC 0.9609\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0132/0938 | LOSS: 0.1368 | ACC 0.9607\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0133/0938 | LOSS: 0.1365 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0134/0938 | LOSS: 0.1368 | ACC 0.9606\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0135/0938 | LOSS: 0.1374 | ACC 0.9603\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0136/0938 | LOSS: 0.1372 | ACC 0.9605\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0137/0938 | LOSS: 0.1373 | ACC 0.9602\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0138/0938 | LOSS: 0.1370 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0139/0938 | LOSS: 0.1378 | ACC 0.9601\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0140/0938 | LOSS: 0.1385 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0141/0938 | LOSS: 0.1388 | ACC 0.9598\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0142/0938 | LOSS: 0.1392 | ACC 0.9596\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0143/0938 | LOSS: 0.1389 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0144/0938 | LOSS: 0.1392 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0145/0938 | LOSS: 0.1396 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0146/0938 | LOSS: 0.1397 | ACC 0.9598\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0147/0938 | LOSS: 0.1401 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0148/0938 | LOSS: 0.1403 | ACC 0.9596\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0149/0938 | LOSS: 0.1398 | ACC 0.9597\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0150/0938 | LOSS: 0.1403 | ACC 0.9596\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0151/0938 | LOSS: 0.1404 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0152/0938 | LOSS: 0.1398 | ACC 0.9596\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0153/0938 | LOSS: 0.1396 | ACC 0.9598\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0154/0938 | LOSS: 0.1396 | ACC 0.9596\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0155/0938 | LOSS: 0.1403 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0156/0938 | LOSS: 0.1415 | ACC 0.9590\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0157/0938 | LOSS: 0.1417 | ACC 0.9589\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0158/0938 | LOSS: 0.1423 | ACC 0.9588\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0159/0938 | LOSS: 0.1421 | ACC 0.9587\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0160/0938 | LOSS: 0.1416 | ACC 0.9589\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0161/0938 | LOSS: 0.1411 | ACC 0.9590\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0162/0938 | LOSS: 0.1408 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0163/0938 | LOSS: 0.1402 | ACC 0.9595\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0164/0938 | LOSS: 0.1406 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0165/0938 | LOSS: 0.1405 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0166/0938 | LOSS: 0.1402 | ACC 0.9591\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0167/0938 | LOSS: 0.1402 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0168/0938 | LOSS: 0.1400 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0169/0938 | LOSS: 0.1399 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0170/0938 | LOSS: 0.1395 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0171/0938 | LOSS: 0.1395 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0172/0938 | LOSS: 0.1401 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0173/0938 | LOSS: 0.1401 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0174/0938 | LOSS: 0.1396 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0175/0938 | LOSS: 0.1400 | ACC 0.9594\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0176/0938 | LOSS: 0.1400 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0177/0938 | LOSS: 0.1395 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0178/0938 | LOSS: 0.1396 | ACC 0.9592\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0179/0938 | LOSS: 0.1394 | ACC 0.9591\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0180/0938 | LOSS: 0.1390 | ACC 0.9593\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0181/0938 | LOSS: 0.1391 | ACC 0.9590\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0182/0938 | LOSS: 0.1393 | ACC 0.9590\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0183/0938 | LOSS: 0.1391 | ACC 0.9590\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0184/0938 | LOSS: 0.1403 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0185/0938 | LOSS: 0.1406 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0186/0938 | LOSS: 0.1405 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0187/0938 | LOSS: 0.1403 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0188/0938 | LOSS: 0.1399 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0189/0938 | LOSS: 0.1401 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0190/0938 | LOSS: 0.1401 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0191/0938 | LOSS: 0.1399 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0192/0938 | LOSS: 0.1399 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0193/0938 | LOSS: 0.1399 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0194/0938 | LOSS: 0.1398 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0195/0938 | LOSS: 0.1403 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0196/0938 | LOSS: 0.1410 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0197/0938 | LOSS: 0.1405 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0198/0938 | LOSS: 0.1404 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0199/0938 | LOSS: 0.1407 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0200/0938 | LOSS: 0.1413 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0201/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0202/0938 | LOSS: 0.1416 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0203/0938 | LOSS: 0.1415 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0204/0938 | LOSS: 0.1413 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0205/0938 | LOSS: 0.1416 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0206/0938 | LOSS: 0.1416 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0207/0938 | LOSS: 0.1419 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0208/0938 | LOSS: 0.1419 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0209/0938 | LOSS: 0.1419 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0210/0938 | LOSS: 0.1414 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0211/0938 | LOSS: 0.1412 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0212/0938 | LOSS: 0.1410 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0213/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0214/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0215/0938 | LOSS: 0.1407 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0216/0938 | LOSS: 0.1408 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0217/0938 | LOSS: 0.1410 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0218/0938 | LOSS: 0.1405 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0219/0938 | LOSS: 0.1401 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0220/0938 | LOSS: 0.1406 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0221/0938 | LOSS: 0.1403 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0222/0938 | LOSS: 0.1398 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0223/0938 | LOSS: 0.1398 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0224/0938 | LOSS: 0.1397 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0225/0938 | LOSS: 0.1396 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0226/0938 | LOSS: 0.1396 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0227/0938 | LOSS: 0.1394 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0228/0938 | LOSS: 0.1398 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0229/0938 | LOSS: 0.1394 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0230/0938 | LOSS: 0.1399 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0231/0938 | LOSS: 0.1412 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0232/0938 | LOSS: 0.1415 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0233/0938 | LOSS: 0.1417 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0234/0938 | LOSS: 0.1413 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0235/0938 | LOSS: 0.1413 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0236/0938 | LOSS: 0.1415 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0237/0938 | LOSS: 0.1415 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0238/0938 | LOSS: 0.1417 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0239/0938 | LOSS: 0.1412 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0240/0938 | LOSS: 0.1416 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0241/0938 | LOSS: 0.1414 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0242/0938 | LOSS: 0.1411 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0243/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0244/0938 | LOSS: 0.1409 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0245/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0246/0938 | LOSS: 0.1405 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0247/0938 | LOSS: 0.1401 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0248/0938 | LOSS: 0.1397 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0249/0938 | LOSS: 0.1393 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0250/0938 | LOSS: 0.1394 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0251/0938 | LOSS: 0.1391 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0252/0938 | LOSS: 0.1388 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0253/0938 | LOSS: 0.1386 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0254/0938 | LOSS: 0.1383 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0255/0938 | LOSS: 0.1383 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0256/0938 | LOSS: 0.1379 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0257/0938 | LOSS: 0.1378 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0258/0938 | LOSS: 0.1381 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0259/0938 | LOSS: 0.1382 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0260/0938 | LOSS: 0.1383 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0261/0938 | LOSS: 0.1383 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0262/0938 | LOSS: 0.1380 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0263/0938 | LOSS: 0.1382 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0264/0938 | LOSS: 0.1381 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0265/0938 | LOSS: 0.1384 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0266/0938 | LOSS: 0.1386 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0267/0938 | LOSS: 0.1386 | ACC 0.9586\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0268/0938 | LOSS: 0.1384 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0269/0938 | LOSS: 0.1383 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0270/0938 | LOSS: 0.1381 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0271/0938 | LOSS: 0.1380 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0272/0938 | LOSS: 0.1387 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0273/0938 | LOSS: 0.1384 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0274/0938 | LOSS: 0.1384 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0275/0938 | LOSS: 0.1385 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0276/0938 | LOSS: 0.1381 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0277/0938 | LOSS: 0.1384 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0278/0938 | LOSS: 0.1381 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0279/0938 | LOSS: 0.1379 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0280/0938 | LOSS: 0.1382 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0281/0938 | LOSS: 0.1381 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0282/0938 | LOSS: 0.1383 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0283/0938 | LOSS: 0.1381 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0284/0938 | LOSS: 0.1383 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0285/0938 | LOSS: 0.1384 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0286/0938 | LOSS: 0.1390 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0287/0938 | LOSS: 0.1390 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0288/0938 | LOSS: 0.1392 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0289/0938 | LOSS: 0.1391 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0290/0938 | LOSS: 0.1391 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0291/0938 | LOSS: 0.1393 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0292/0938 | LOSS: 0.1392 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0293/0938 | LOSS: 0.1397 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0294/0938 | LOSS: 0.1395 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0295/0938 | LOSS: 0.1392 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0296/0938 | LOSS: 0.1389 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0297/0938 | LOSS: 0.1391 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0298/0938 | LOSS: 0.1388 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0299/0938 | LOSS: 0.1391 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0300/0938 | LOSS: 0.1392 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0301/0938 | LOSS: 0.1394 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0302/0938 | LOSS: 0.1396 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0303/0938 | LOSS: 0.1392 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0304/0938 | LOSS: 0.1394 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0305/0938 | LOSS: 0.1397 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0306/0938 | LOSS: 0.1393 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0307/0938 | LOSS: 0.1397 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0308/0938 | LOSS: 0.1398 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0309/0938 | LOSS: 0.1403 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0310/0938 | LOSS: 0.1401 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0311/0938 | LOSS: 0.1399 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0312/0938 | LOSS: 0.1399 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0313/0938 | LOSS: 0.1400 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0314/0938 | LOSS: 0.1402 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0315/0938 | LOSS: 0.1405 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0316/0938 | LOSS: 0.1406 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0317/0938 | LOSS: 0.1404 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0318/0938 | LOSS: 0.1402 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0319/0938 | LOSS: 0.1399 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0320/0938 | LOSS: 0.1396 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0321/0938 | LOSS: 0.1394 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0322/0938 | LOSS: 0.1393 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0323/0938 | LOSS: 0.1394 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0324/0938 | LOSS: 0.1394 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0325/0938 | LOSS: 0.1392 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0326/0938 | LOSS: 0.1395 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0327/0938 | LOSS: 0.1400 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0328/0938 | LOSS: 0.1401 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0329/0938 | LOSS: 0.1398 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0330/0938 | LOSS: 0.1398 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0331/0938 | LOSS: 0.1399 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0332/0938 | LOSS: 0.1402 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0333/0938 | LOSS: 0.1400 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0334/0938 | LOSS: 0.1397 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0335/0938 | LOSS: 0.1395 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0336/0938 | LOSS: 0.1396 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0337/0938 | LOSS: 0.1395 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0338/0938 | LOSS: 0.1391 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0339/0938 | LOSS: 0.1393 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0340/0938 | LOSS: 0.1392 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0341/0938 | LOSS: 0.1390 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0342/0938 | LOSS: 0.1389 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0343/0938 | LOSS: 0.1389 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0344/0938 | LOSS: 0.1392 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0345/0938 | LOSS: 0.1395 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0346/0938 | LOSS: 0.1397 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0347/0938 | LOSS: 0.1396 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0348/0938 | LOSS: 0.1400 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0349/0938 | LOSS: 0.1400 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0350/0938 | LOSS: 0.1401 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0351/0938 | LOSS: 0.1400 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0352/0938 | LOSS: 0.1402 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0353/0938 | LOSS: 0.1403 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0354/0938 | LOSS: 0.1402 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0355/0938 | LOSS: 0.1400 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0356/0938 | LOSS: 0.1403 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0357/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0358/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0359/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0360/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0361/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0362/0938 | LOSS: 0.1404 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0363/0938 | LOSS: 0.1403 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0364/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0365/0938 | LOSS: 0.1412 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0366/0938 | LOSS: 0.1410 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0367/0938 | LOSS: 0.1411 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0368/0938 | LOSS: 0.1411 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0369/0938 | LOSS: 0.1410 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0370/0938 | LOSS: 0.1408 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0371/0938 | LOSS: 0.1409 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0372/0938 | LOSS: 0.1406 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0373/0938 | LOSS: 0.1405 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0374/0938 | LOSS: 0.1404 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0375/0938 | LOSS: 0.1402 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0376/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0377/0938 | LOSS: 0.1406 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0378/0938 | LOSS: 0.1406 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0379/0938 | LOSS: 0.1405 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0380/0938 | LOSS: 0.1403 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0381/0938 | LOSS: 0.1405 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0382/0938 | LOSS: 0.1404 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0383/0938 | LOSS: 0.1407 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0384/0938 | LOSS: 0.1408 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0385/0938 | LOSS: 0.1407 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0386/0938 | LOSS: 0.1406 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0387/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0388/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0389/0938 | LOSS: 0.1409 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0390/0938 | LOSS: 0.1409 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0391/0938 | LOSS: 0.1410 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0392/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0393/0938 | LOSS: 0.1411 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0394/0938 | LOSS: 0.1408 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0395/0938 | LOSS: 0.1408 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0396/0938 | LOSS: 0.1408 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0397/0938 | LOSS: 0.1408 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0398/0938 | LOSS: 0.1408 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0399/0938 | LOSS: 0.1408 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0400/0938 | LOSS: 0.1406 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0401/0938 | LOSS: 0.1405 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0402/0938 | LOSS: 0.1412 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0403/0938 | LOSS: 0.1415 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0404/0938 | LOSS: 0.1415 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0405/0938 | LOSS: 0.1414 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0406/0938 | LOSS: 0.1413 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0407/0938 | LOSS: 0.1413 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0408/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0409/0938 | LOSS: 0.1413 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0410/0938 | LOSS: 0.1412 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0411/0938 | LOSS: 0.1411 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0412/0938 | LOSS: 0.1411 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0413/0938 | LOSS: 0.1409 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0414/0938 | LOSS: 0.1409 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0415/0938 | LOSS: 0.1409 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0416/0938 | LOSS: 0.1410 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0417/0938 | LOSS: 0.1409 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0418/0938 | LOSS: 0.1408 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0419/0938 | LOSS: 0.1407 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0420/0938 | LOSS: 0.1406 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0421/0938 | LOSS: 0.1405 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0422/0938 | LOSS: 0.1407 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0423/0938 | LOSS: 0.1407 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0424/0938 | LOSS: 0.1409 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0425/0938 | LOSS: 0.1409 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0426/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0427/0938 | LOSS: 0.1407 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0428/0938 | LOSS: 0.1406 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0429/0938 | LOSS: 0.1406 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0430/0938 | LOSS: 0.1407 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0431/0938 | LOSS: 0.1407 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0432/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0433/0938 | LOSS: 0.1403 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0434/0938 | LOSS: 0.1405 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0435/0938 | LOSS: 0.1411 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0436/0938 | LOSS: 0.1410 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0437/0938 | LOSS: 0.1420 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0438/0938 | LOSS: 0.1422 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0439/0938 | LOSS: 0.1421 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0440/0938 | LOSS: 0.1421 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0441/0938 | LOSS: 0.1426 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0442/0938 | LOSS: 0.1430 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0443/0938 | LOSS: 0.1432 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0444/0938 | LOSS: 0.1432 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0445/0938 | LOSS: 0.1432 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0446/0938 | LOSS: 0.1435 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0447/0938 | LOSS: 0.1434 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0448/0938 | LOSS: 0.1435 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0449/0938 | LOSS: 0.1435 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0450/0938 | LOSS: 0.1433 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0451/0938 | LOSS: 0.1436 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0452/0938 | LOSS: 0.1436 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0453/0938 | LOSS: 0.1439 | ACC 0.9571\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0454/0938 | LOSS: 0.1436 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0455/0938 | LOSS: 0.1436 | ACC 0.9572\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0456/0938 | LOSS: 0.1434 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0457/0938 | LOSS: 0.1434 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0458/0938 | LOSS: 0.1432 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0459/0938 | LOSS: 0.1431 | ACC 0.9573\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0460/0938 | LOSS: 0.1430 | ACC 0.9574\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0461/0938 | LOSS: 0.1429 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0462/0938 | LOSS: 0.1428 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0463/0938 | LOSS: 0.1426 | ACC 0.9575\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0464/0938 | LOSS: 0.1425 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0465/0938 | LOSS: 0.1425 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0466/0938 | LOSS: 0.1425 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0467/0938 | LOSS: 0.1423 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0468/0938 | LOSS: 0.1422 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0469/0938 | LOSS: 0.1422 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0470/0938 | LOSS: 0.1422 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0471/0938 | LOSS: 0.1420 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0472/0938 | LOSS: 0.1420 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0473/0938 | LOSS: 0.1421 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0474/0938 | LOSS: 0.1419 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0475/0938 | LOSS: 0.1418 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0476/0938 | LOSS: 0.1417 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0477/0938 | LOSS: 0.1415 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0478/0938 | LOSS: 0.1417 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0479/0938 | LOSS: 0.1415 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0480/0938 | LOSS: 0.1413 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0481/0938 | LOSS: 0.1413 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0482/0938 | LOSS: 0.1413 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0483/0938 | LOSS: 0.1411 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0484/0938 | LOSS: 0.1409 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0485/0938 | LOSS: 0.1411 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0486/0938 | LOSS: 0.1410 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0487/0938 | LOSS: 0.1413 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0488/0938 | LOSS: 0.1412 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0489/0938 | LOSS: 0.1412 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0490/0938 | LOSS: 0.1413 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0491/0938 | LOSS: 0.1412 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0492/0938 | LOSS: 0.1411 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0493/0938 | LOSS: 0.1410 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0494/0938 | LOSS: 0.1412 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0495/0938 | LOSS: 0.1410 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0496/0938 | LOSS: 0.1409 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0497/0938 | LOSS: 0.1410 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0498/0938 | LOSS: 0.1410 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0499/0938 | LOSS: 0.1409 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0500/0938 | LOSS: 0.1409 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0501/0938 | LOSS: 0.1408 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0502/0938 | LOSS: 0.1406 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0503/0938 | LOSS: 0.1405 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0504/0938 | LOSS: 0.1403 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0505/0938 | LOSS: 0.1404 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0506/0938 | LOSS: 0.1402 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0507/0938 | LOSS: 0.1402 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0508/0938 | LOSS: 0.1405 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0509/0938 | LOSS: 0.1410 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0510/0938 | LOSS: 0.1412 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0511/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0512/0938 | LOSS: 0.1413 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0513/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0514/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0515/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0516/0938 | LOSS: 0.1408 | ACC 0.9585\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0517/0938 | LOSS: 0.1408 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0518/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0519/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0520/0938 | LOSS: 0.1410 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0521/0938 | LOSS: 0.1412 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0522/0938 | LOSS: 0.1412 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0523/0938 | LOSS: 0.1413 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0524/0938 | LOSS: 0.1414 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0525/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0526/0938 | LOSS: 0.1418 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0527/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0528/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0529/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0530/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0531/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0532/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0533/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0534/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0535/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0536/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0537/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0538/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0539/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0540/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0541/0938 | LOSS: 0.1419 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0542/0938 | LOSS: 0.1418 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0543/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0544/0938 | LOSS: 0.1419 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0545/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0546/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0547/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0548/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0549/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0550/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0551/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0552/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0553/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0554/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0555/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0556/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0557/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0558/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0559/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0560/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0561/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0562/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0563/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0564/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0565/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0566/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0567/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0568/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0569/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0570/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0571/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0572/0938 | LOSS: 0.1418 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0573/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0574/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0575/0938 | LOSS: 0.1418 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0576/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0577/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0578/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0579/0938 | LOSS: 0.1415 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0580/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0581/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0582/0938 | LOSS: 0.1413 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0583/0938 | LOSS: 0.1413 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0584/0938 | LOSS: 0.1412 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0585/0938 | LOSS: 0.1410 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0586/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0587/0938 | LOSS: 0.1410 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0588/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0589/0938 | LOSS: 0.1412 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0590/0938 | LOSS: 0.1411 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0591/0938 | LOSS: 0.1415 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0592/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0593/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0594/0938 | LOSS: 0.1413 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0595/0938 | LOSS: 0.1411 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0596/0938 | LOSS: 0.1410 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0597/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0598/0938 | LOSS: 0.1409 | ACC 0.9584\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0599/0938 | LOSS: 0.1410 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0600/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0601/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0602/0938 | LOSS: 0.1413 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0603/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0604/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0605/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0606/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0607/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0608/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0609/0938 | LOSS: 0.1415 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0610/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0611/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0612/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0613/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0614/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0615/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0616/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0617/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0618/0938 | LOSS: 0.1416 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0619/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0620/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0621/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0622/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0623/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0624/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0625/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0626/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0627/0938 | LOSS: 0.1416 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0628/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0629/0938 | LOSS: 0.1414 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0630/0938 | LOSS: 0.1414 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0631/0938 | LOSS: 0.1413 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0632/0938 | LOSS: 0.1418 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0633/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0634/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0635/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0636/0938 | LOSS: 0.1413 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0637/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0638/0938 | LOSS: 0.1416 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0639/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0640/0938 | LOSS: 0.1414 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0641/0938 | LOSS: 0.1414 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0642/0938 | LOSS: 0.1413 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0643/0938 | LOSS: 0.1411 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0644/0938 | LOSS: 0.1415 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0645/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0646/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0647/0938 | LOSS: 0.1413 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0648/0938 | LOSS: 0.1415 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0649/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0650/0938 | LOSS: 0.1412 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0651/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0652/0938 | LOSS: 0.1412 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0653/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0654/0938 | LOSS: 0.1413 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0655/0938 | LOSS: 0.1415 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0656/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0657/0938 | LOSS: 0.1412 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0658/0938 | LOSS: 0.1411 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0659/0938 | LOSS: 0.1414 | ACC 0.9583\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0660/0938 | LOSS: 0.1414 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0661/0938 | LOSS: 0.1417 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0662/0938 | LOSS: 0.1418 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0663/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0664/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0665/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0666/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0667/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0668/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0669/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0670/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0671/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0672/0938 | LOSS: 0.1418 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0673/0938 | LOSS: 0.1417 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0674/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0675/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0676/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0677/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0678/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0679/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0680/0938 | LOSS: 0.1422 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0681/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0682/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0683/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0684/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0685/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0686/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0687/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0688/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0689/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0690/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0691/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0692/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0693/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0694/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0695/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0696/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0697/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0698/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0699/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0700/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0701/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0702/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0703/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0704/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0705/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0706/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0707/0938 | LOSS: 0.1423 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0708/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0709/0938 | LOSS: 0.1423 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0710/0938 | LOSS: 0.1424 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0711/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0712/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0713/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0714/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0715/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0716/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0717/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0718/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0719/0938 | LOSS: 0.1422 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0720/0938 | LOSS: 0.1423 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0721/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0722/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0723/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0724/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0725/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0726/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0727/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0728/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0729/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0730/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0731/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0732/0938 | LOSS: 0.1422 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0733/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0734/0938 | LOSS: 0.1423 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0735/0938 | LOSS: 0.1423 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0736/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0737/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0738/0938 | LOSS: 0.1419 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0739/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0740/0938 | LOSS: 0.1419 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0741/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0742/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0743/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0744/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0745/0938 | LOSS: 0.1420 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0746/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0747/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0748/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0749/0938 | LOSS: 0.1421 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0750/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0751/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0752/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0753/0938 | LOSS: 0.1427 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0754/0938 | LOSS: 0.1426 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0755/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0756/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0757/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0758/0938 | LOSS: 0.1424 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0759/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0760/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0761/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0762/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0763/0938 | LOSS: 0.1420 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0764/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0765/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0766/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0767/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0768/0938 | LOSS: 0.1418 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0769/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0770/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0771/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0772/0938 | LOSS: 0.1419 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0773/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0774/0938 | LOSS: 0.1419 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0775/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0776/0938 | LOSS: 0.1422 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0777/0938 | LOSS: 0.1422 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0778/0938 | LOSS: 0.1422 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0779/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0780/0938 | LOSS: 0.1419 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0781/0938 | LOSS: 0.1420 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0782/0938 | LOSS: 0.1421 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0783/0938 | LOSS: 0.1422 | ACC 0.9582\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0784/0938 | LOSS: 0.1422 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0785/0938 | LOSS: 0.1422 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0786/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0787/0938 | LOSS: 0.1423 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0788/0938 | LOSS: 0.1424 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0789/0938 | LOSS: 0.1426 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0790/0938 | LOSS: 0.1425 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0791/0938 | LOSS: 0.1425 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0792/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0793/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0794/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0795/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0796/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0797/0938 | LOSS: 0.1421 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0798/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0799/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0800/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0801/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0802/0938 | LOSS: 0.1419 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0803/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0804/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0805/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0806/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0807/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0808/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0809/0938 | LOSS: 0.1420 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0810/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0811/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0812/0938 | LOSS: 0.1421 | ACC 0.9581\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0813/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0814/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0815/0938 | LOSS: 0.1423 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0816/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0817/0938 | LOSS: 0.1422 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0818/0938 | LOSS: 0.1423 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0819/0938 | LOSS: 0.1424 | ACC 0.9580\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0820/0938 | LOSS: 0.1425 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0821/0938 | LOSS: 0.1426 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0822/0938 | LOSS: 0.1428 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0823/0938 | LOSS: 0.1428 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0824/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0825/0938 | LOSS: 0.1430 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0826/0938 | LOSS: 0.1430 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0827/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0828/0938 | LOSS: 0.1430 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0829/0938 | LOSS: 0.1430 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0830/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0831/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0832/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0833/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0834/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0835/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0836/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0837/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0838/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0839/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0840/0938 | LOSS: 0.1432 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0841/0938 | LOSS: 0.1432 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0842/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0843/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0844/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0845/0938 | LOSS: 0.1430 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0846/0938 | LOSS: 0.1430 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0847/0938 | LOSS: 0.1429 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0848/0938 | LOSS: 0.1430 | ACC 0.9579\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0849/0938 | LOSS: 0.1432 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0850/0938 | LOSS: 0.1431 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0851/0938 | LOSS: 0.1434 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0852/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0853/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0854/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0855/0938 | LOSS: 0.1437 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0856/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0857/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0858/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0859/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0860/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0861/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0862/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0863/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0864/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0865/0938 | LOSS: 0.1436 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0866/0938 | LOSS: 0.1436 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0867/0938 | LOSS: 0.1436 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0868/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0869/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0870/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0871/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0872/0938 | LOSS: 0.1438 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0873/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0874/0938 | LOSS: 0.1439 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0875/0938 | LOSS: 0.1438 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0876/0938 | LOSS: 0.1438 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0877/0938 | LOSS: 0.1440 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0878/0938 | LOSS: 0.1441 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0879/0938 | LOSS: 0.1441 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0880/0938 | LOSS: 0.1440 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0881/0938 | LOSS: 0.1440 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0882/0938 | LOSS: 0.1441 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0883/0938 | LOSS: 0.1441 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0884/0938 | LOSS: 0.1441 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0885/0938 | LOSS: 0.1440 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0886/0938 | LOSS: 0.1440 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0887/0938 | LOSS: 0.1439 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0888/0938 | LOSS: 0.1439 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0889/0938 | LOSS: 0.1439 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0890/0938 | LOSS: 0.1438 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0891/0938 | LOSS: 0.1438 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0892/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0893/0938 | LOSS: 0.1439 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0894/0938 | LOSS: 0.1438 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0895/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0896/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0897/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0898/0938 | LOSS: 0.1438 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0899/0938 | LOSS: 0.1438 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0900/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0901/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0902/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0903/0938 | LOSS: 0.1437 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0904/0938 | LOSS: 0.1436 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0905/0938 | LOSS: 0.1434 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0906/0938 | LOSS: 0.1435 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0907/0938 | LOSS: 0.1435 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0908/0938 | LOSS: 0.1435 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0909/0938 | LOSS: 0.1434 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0910/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0911/0938 | LOSS: 0.1434 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0912/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0913/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0914/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0915/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0916/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0917/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0918/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0919/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0920/0938 | LOSS: 0.1434 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0921/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0922/0938 | LOSS: 0.1433 | ACC 0.9578\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0923/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0924/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0925/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0926/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0927/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0928/0938 | LOSS: 0.1436 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0929/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0930/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0931/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0932/0938 | LOSS: 0.1435 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0933/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0934/0938 | LOSS: 0.1434 | ACC 0.9576\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0935/0938 | LOSS: 0.1434 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0936/0938 | LOSS: 0.1433 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0937/0938 | LOSS: 0.1432 | ACC 0.9577\n",
            "TRAIN: EPOCH 0010/0010 | BATCH 0938/0938 | LOSS: 0.1433 | ACC 0.9577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmGP5nC6hy4w",
        "outputId": "8191841b-700d-4b3c-d4b2-5adacacd13eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST: BATCH 0001/0157 | LOSS: 0.0111 | ACC 1.0000\n",
            "TEST: BATCH 0002/0157 | LOSS: 0.0158 | ACC 1.0000\n",
            "TEST: BATCH 0003/0157 | LOSS: 0.0124 | ACC 1.0000\n",
            "TEST: BATCH 0004/0157 | LOSS: 0.0117 | ACC 1.0000\n",
            "TEST: BATCH 0005/0157 | LOSS: 0.0168 | ACC 0.9969\n",
            "TEST: BATCH 0006/0157 | LOSS: 0.0231 | ACC 0.9922\n",
            "TEST: BATCH 0007/0157 | LOSS: 0.0290 | ACC 0.9888\n",
            "TEST: BATCH 0008/0157 | LOSS: 0.0361 | ACC 0.9883\n",
            "TEST: BATCH 0009/0157 | LOSS: 0.0329 | ACC 0.9896\n",
            "TEST: BATCH 0010/0157 | LOSS: 0.0394 | ACC 0.9891\n",
            "TEST: BATCH 0011/0157 | LOSS: 0.0406 | ACC 0.9886\n",
            "TEST: BATCH 0012/0157 | LOSS: 0.0401 | ACC 0.9883\n",
            "TEST: BATCH 0013/0157 | LOSS: 0.0373 | ACC 0.9892\n",
            "TEST: BATCH 0014/0157 | LOSS: 0.0367 | ACC 0.9900\n",
            "TEST: BATCH 0015/0157 | LOSS: 0.0412 | ACC 0.9875\n",
            "TEST: BATCH 0016/0157 | LOSS: 0.0462 | ACC 0.9863\n",
            "TEST: BATCH 0017/0157 | LOSS: 0.0461 | ACC 0.9862\n",
            "TEST: BATCH 0018/0157 | LOSS: 0.0450 | ACC 0.9861\n",
            "TEST: BATCH 0019/0157 | LOSS: 0.0438 | ACC 0.9868\n",
            "TEST: BATCH 0020/0157 | LOSS: 0.0515 | ACC 0.9836\n",
            "TEST: BATCH 0021/0157 | LOSS: 0.0537 | ACC 0.9836\n",
            "TEST: BATCH 0022/0157 | LOSS: 0.0526 | ACC 0.9837\n",
            "TEST: BATCH 0023/0157 | LOSS: 0.0514 | ACC 0.9844\n",
            "TEST: BATCH 0024/0157 | LOSS: 0.0519 | ACC 0.9844\n",
            "TEST: BATCH 0025/0157 | LOSS: 0.0505 | ACC 0.9850\n",
            "TEST: BATCH 0026/0157 | LOSS: 0.0531 | ACC 0.9850\n",
            "TEST: BATCH 0027/0157 | LOSS: 0.0552 | ACC 0.9838\n",
            "TEST: BATCH 0028/0157 | LOSS: 0.0561 | ACC 0.9838\n",
            "TEST: BATCH 0029/0157 | LOSS: 0.0544 | ACC 0.9844\n",
            "TEST: BATCH 0030/0157 | LOSS: 0.0560 | ACC 0.9839\n",
            "TEST: BATCH 0031/0157 | LOSS: 0.0544 | ACC 0.9844\n",
            "TEST: BATCH 0032/0157 | LOSS: 0.0558 | ACC 0.9829\n",
            "TEST: BATCH 0033/0157 | LOSS: 0.0552 | ACC 0.9830\n",
            "TEST: BATCH 0034/0157 | LOSS: 0.0562 | ACC 0.9821\n",
            "TEST: BATCH 0035/0157 | LOSS: 0.0562 | ACC 0.9821\n",
            "TEST: BATCH 0036/0157 | LOSS: 0.0557 | ACC 0.9822\n",
            "TEST: BATCH 0037/0157 | LOSS: 0.0544 | ACC 0.9827\n",
            "TEST: BATCH 0038/0157 | LOSS: 0.0546 | ACC 0.9827\n",
            "TEST: BATCH 0039/0157 | LOSS: 0.0550 | ACC 0.9828\n",
            "TEST: BATCH 0040/0157 | LOSS: 0.0537 | ACC 0.9832\n",
            "TEST: BATCH 0041/0157 | LOSS: 0.0545 | ACC 0.9832\n",
            "TEST: BATCH 0042/0157 | LOSS: 0.0570 | ACC 0.9833\n",
            "TEST: BATCH 0043/0157 | LOSS: 0.0562 | ACC 0.9836\n",
            "TEST: BATCH 0044/0157 | LOSS: 0.0560 | ACC 0.9833\n",
            "TEST: BATCH 0045/0157 | LOSS: 0.0550 | ACC 0.9837\n",
            "TEST: BATCH 0046/0157 | LOSS: 0.0560 | ACC 0.9827\n",
            "TEST: BATCH 0047/0157 | LOSS: 0.0561 | ACC 0.9827\n",
            "TEST: BATCH 0048/0157 | LOSS: 0.0556 | ACC 0.9827\n",
            "TEST: BATCH 0049/0157 | LOSS: 0.0548 | ACC 0.9831\n",
            "TEST: BATCH 0050/0157 | LOSS: 0.0539 | ACC 0.9834\n",
            "TEST: BATCH 0051/0157 | LOSS: 0.0530 | ACC 0.9838\n",
            "TEST: BATCH 0052/0157 | LOSS: 0.0533 | ACC 0.9835\n",
            "TEST: BATCH 0053/0157 | LOSS: 0.0528 | ACC 0.9838\n",
            "TEST: BATCH 0054/0157 | LOSS: 0.0531 | ACC 0.9838\n",
            "TEST: BATCH 0055/0157 | LOSS: 0.0530 | ACC 0.9838\n",
            "TEST: BATCH 0056/0157 | LOSS: 0.0559 | ACC 0.9835\n",
            "TEST: BATCH 0057/0157 | LOSS: 0.0555 | ACC 0.9836\n",
            "TEST: BATCH 0058/0157 | LOSS: 0.0547 | ACC 0.9838\n",
            "TEST: BATCH 0059/0157 | LOSS: 0.0566 | ACC 0.9833\n",
            "TEST: BATCH 0060/0157 | LOSS: 0.0568 | ACC 0.9831\n",
            "TEST: BATCH 0061/0157 | LOSS: 0.0568 | ACC 0.9828\n",
            "TEST: BATCH 0062/0157 | LOSS: 0.0564 | ACC 0.9829\n",
            "TEST: BATCH 0063/0157 | LOSS: 0.0561 | ACC 0.9829\n",
            "TEST: BATCH 0064/0157 | LOSS: 0.0558 | ACC 0.9829\n",
            "TEST: BATCH 0065/0157 | LOSS: 0.0551 | ACC 0.9832\n",
            "TEST: BATCH 0066/0157 | LOSS: 0.0563 | ACC 0.9827\n",
            "TEST: BATCH 0067/0157 | LOSS: 0.0571 | ACC 0.9820\n",
            "TEST: BATCH 0068/0157 | LOSS: 0.0566 | ACC 0.9823\n",
            "TEST: BATCH 0069/0157 | LOSS: 0.0562 | ACC 0.9823\n",
            "TEST: BATCH 0070/0157 | LOSS: 0.0556 | ACC 0.9826\n",
            "TEST: BATCH 0071/0157 | LOSS: 0.0562 | ACC 0.9824\n",
            "TEST: BATCH 0072/0157 | LOSS: 0.0561 | ACC 0.9824\n",
            "TEST: BATCH 0073/0157 | LOSS: 0.0556 | ACC 0.9824\n",
            "TEST: BATCH 0074/0157 | LOSS: 0.0551 | ACC 0.9827\n",
            "TEST: BATCH 0075/0157 | LOSS: 0.0546 | ACC 0.9829\n",
            "TEST: BATCH 0076/0157 | LOSS: 0.0554 | ACC 0.9827\n",
            "TEST: BATCH 0077/0157 | LOSS: 0.0555 | ACC 0.9828\n",
            "TEST: BATCH 0078/0157 | LOSS: 0.0551 | ACC 0.9828\n",
            "TEST: BATCH 0079/0157 | LOSS: 0.0544 | ACC 0.9830\n",
            "TEST: BATCH 0080/0157 | LOSS: 0.0539 | ACC 0.9830\n",
            "TEST: BATCH 0081/0157 | LOSS: 0.0538 | ACC 0.9830\n",
            "TEST: BATCH 0082/0157 | LOSS: 0.0532 | ACC 0.9832\n",
            "TEST: BATCH 0083/0157 | LOSS: 0.0527 | ACC 0.9832\n",
            "TEST: BATCH 0084/0157 | LOSS: 0.0521 | ACC 0.9834\n",
            "TEST: BATCH 0085/0157 | LOSS: 0.0515 | ACC 0.9836\n",
            "TEST: BATCH 0086/0157 | LOSS: 0.0509 | ACC 0.9838\n",
            "TEST: BATCH 0087/0157 | LOSS: 0.0503 | ACC 0.9840\n",
            "TEST: BATCH 0088/0157 | LOSS: 0.0498 | ACC 0.9842\n",
            "TEST: BATCH 0089/0157 | LOSS: 0.0493 | ACC 0.9844\n",
            "TEST: BATCH 0090/0157 | LOSS: 0.0489 | ACC 0.9845\n",
            "TEST: BATCH 0091/0157 | LOSS: 0.0484 | ACC 0.9847\n",
            "TEST: BATCH 0092/0157 | LOSS: 0.0480 | ACC 0.9849\n",
            "TEST: BATCH 0093/0157 | LOSS: 0.0486 | ACC 0.9847\n",
            "TEST: BATCH 0094/0157 | LOSS: 0.0488 | ACC 0.9845\n",
            "TEST: BATCH 0095/0157 | LOSS: 0.0484 | ACC 0.9847\n",
            "TEST: BATCH 0096/0157 | LOSS: 0.0481 | ACC 0.9847\n",
            "TEST: BATCH 0097/0157 | LOSS: 0.0480 | ACC 0.9845\n",
            "TEST: BATCH 0098/0157 | LOSS: 0.0475 | ACC 0.9847\n",
            "TEST: BATCH 0099/0157 | LOSS: 0.0470 | ACC 0.9848\n",
            "TEST: BATCH 0100/0157 | LOSS: 0.0466 | ACC 0.9850\n",
            "TEST: BATCH 0101/0157 | LOSS: 0.0461 | ACC 0.9851\n",
            "TEST: BATCH 0102/0157 | LOSS: 0.0464 | ACC 0.9851\n",
            "TEST: BATCH 0103/0157 | LOSS: 0.0474 | ACC 0.9848\n",
            "TEST: BATCH 0104/0157 | LOSS: 0.0495 | ACC 0.9844\n",
            "TEST: BATCH 0105/0157 | LOSS: 0.0491 | ACC 0.9845\n",
            "TEST: BATCH 0106/0157 | LOSS: 0.0488 | ACC 0.9845\n",
            "TEST: BATCH 0107/0157 | LOSS: 0.0484 | ACC 0.9847\n",
            "TEST: BATCH 0108/0157 | LOSS: 0.0480 | ACC 0.9848\n",
            "TEST: BATCH 0109/0157 | LOSS: 0.0476 | ACC 0.9849\n",
            "TEST: BATCH 0110/0157 | LOSS: 0.0471 | ACC 0.9851\n",
            "TEST: BATCH 0111/0157 | LOSS: 0.0467 | ACC 0.9852\n",
            "TEST: BATCH 0112/0157 | LOSS: 0.0465 | ACC 0.9852\n",
            "TEST: BATCH 0113/0157 | LOSS: 0.0462 | ACC 0.9853\n",
            "TEST: BATCH 0114/0157 | LOSS: 0.0461 | ACC 0.9853\n",
            "TEST: BATCH 0115/0157 | LOSS: 0.0457 | ACC 0.9855\n",
            "TEST: BATCH 0116/0157 | LOSS: 0.0453 | ACC 0.9856\n",
            "TEST: BATCH 0117/0157 | LOSS: 0.0451 | ACC 0.9857\n",
            "TEST: BATCH 0118/0157 | LOSS: 0.0448 | ACC 0.9858\n",
            "TEST: BATCH 0119/0157 | LOSS: 0.0445 | ACC 0.9860\n",
            "TEST: BATCH 0120/0157 | LOSS: 0.0441 | ACC 0.9861\n",
            "TEST: BATCH 0121/0157 | LOSS: 0.0437 | ACC 0.9862\n",
            "TEST: BATCH 0122/0157 | LOSS: 0.0435 | ACC 0.9863\n",
            "TEST: BATCH 0123/0157 | LOSS: 0.0435 | ACC 0.9863\n",
            "TEST: BATCH 0124/0157 | LOSS: 0.0434 | ACC 0.9863\n",
            "TEST: BATCH 0125/0157 | LOSS: 0.0431 | ACC 0.9864\n",
            "TEST: BATCH 0126/0157 | LOSS: 0.0429 | ACC 0.9865\n",
            "TEST: BATCH 0127/0157 | LOSS: 0.0430 | ACC 0.9865\n",
            "TEST: BATCH 0128/0157 | LOSS: 0.0426 | ACC 0.9866\n",
            "TEST: BATCH 0129/0157 | LOSS: 0.0424 | ACC 0.9867\n",
            "TEST: BATCH 0130/0157 | LOSS: 0.0422 | ACC 0.9868\n",
            "TEST: BATCH 0131/0157 | LOSS: 0.0419 | ACC 0.9869\n",
            "TEST: BATCH 0132/0157 | LOSS: 0.0417 | ACC 0.9869\n",
            "TEST: BATCH 0133/0157 | LOSS: 0.0414 | ACC 0.9870\n",
            "TEST: BATCH 0134/0157 | LOSS: 0.0412 | ACC 0.9871\n",
            "TEST: BATCH 0135/0157 | LOSS: 0.0409 | ACC 0.9872\n",
            "TEST: BATCH 0136/0157 | LOSS: 0.0406 | ACC 0.9872\n",
            "TEST: BATCH 0137/0157 | LOSS: 0.0403 | ACC 0.9873\n",
            "TEST: BATCH 0138/0157 | LOSS: 0.0400 | ACC 0.9874\n",
            "TEST: BATCH 0139/0157 | LOSS: 0.0397 | ACC 0.9875\n",
            "TEST: BATCH 0140/0157 | LOSS: 0.0394 | ACC 0.9876\n",
            "TEST: BATCH 0141/0157 | LOSS: 0.0400 | ACC 0.9875\n",
            "TEST: BATCH 0142/0157 | LOSS: 0.0399 | ACC 0.9875\n",
            "TEST: BATCH 0143/0157 | LOSS: 0.0396 | ACC 0.9875\n",
            "TEST: BATCH 0144/0157 | LOSS: 0.0393 | ACC 0.9876\n",
            "TEST: BATCH 0145/0157 | LOSS: 0.0391 | ACC 0.9877\n",
            "TEST: BATCH 0146/0157 | LOSS: 0.0388 | ACC 0.9878\n",
            "TEST: BATCH 0147/0157 | LOSS: 0.0386 | ACC 0.9879\n",
            "TEST: BATCH 0148/0157 | LOSS: 0.0383 | ACC 0.9880\n",
            "TEST: BATCH 0149/0157 | LOSS: 0.0381 | ACC 0.9880\n",
            "TEST: BATCH 0150/0157 | LOSS: 0.0379 | ACC 0.9881\n",
            "TEST: BATCH 0151/0157 | LOSS: 0.0383 | ACC 0.9879\n",
            "TEST: BATCH 0152/0157 | LOSS: 0.0386 | ACC 0.9878\n",
            "TEST: BATCH 0153/0157 | LOSS: 0.0389 | ACC 0.9876\n",
            "TEST: BATCH 0154/0157 | LOSS: 0.0388 | ACC 0.9876\n",
            "TEST: BATCH 0155/0157 | LOSS: 0.0390 | ACC 0.9876\n",
            "TEST: BATCH 0156/0157 | LOSS: 0.0390 | ACC 0.9876\n",
            "TEST: BATCH 0157/0157 | LOSS: 0.0387 | ACC 0.9877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ACvTh0Goi4jT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}